services:
  # PostgreSQL 資料庫 with pgvector
  postgres:
    image: pgvector/pgvector:pg16
    container_name: aichatbot-postgres
    environment:
      POSTGRES_USER: aichatbot
      POSTGRES_PASSWORD: aichatbot_password
      POSTGRES_DB: aichatbot_admin
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d  # 初始化腳本
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U aichatbot"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Redis (選用，用於 Celery 任務隊列)
  redis:
    image: redis:7-alpine
    container_name: aichatbot-redis
    ports:
      - "6381:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  # pgAdmin (選用，資料庫管理介面)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: aichatbot-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@aichatbot.com
      PGADMIN_DEFAULT_PASSWORD: admin
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      - postgres

  # Embedding API Service
  embedding-api:
    build: ./embedding-service
    container_name: aichatbot-embedding-api
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      REDIS_HOST: redis
      REDIS_PORT: 6379
    ports:
      - "5001:5000"
    depends_on:
      - redis
    restart: unless-stopped

  # 知識庫管理後台 - API
  knowledge-admin-api:
    build: ./knowledge-admin/backend
    container_name: aichatbot-knowledge-admin-api
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: aichatbot_admin
      DB_USER: aichatbot
      DB_PASSWORD: aichatbot_password
      EMBEDDING_API_URL: http://embedding-api:5000/api/v1/embeddings
      PROJECT_ROOT: /app
      RAG_API_URL: http://rag-orchestrator:8100
      OPENAI_API_KEY: ${OPENAI_API_KEY}
    ports:
      - "8000:8000"
    volumes:
      # 開發模式：動態掛載後端程式碼
      - ./knowledge-admin/backend/app.py:/app/app.py
      - ./knowledge-admin/backend/routes_test_scenarios.py:/app/routes_test_scenarios.py
      # 測試資料與輸出
      - ./test_scenarios_smoke.xlsx:/app/test_scenarios_smoke.xlsx:ro
      - ./test_scenarios_full.xlsx:/app/test_scenarios_full.xlsx:ro
      - ./output:/app/output
      - ./scripts:/app/scripts:ro
    depends_on:
      - postgres
      - embedding-api
      - rag-orchestrator
    restart: unless-stopped

  # 知識庫管理後台 - 前端（開發模式）
  knowledge-admin-web:
    build:
      context: ./knowledge-admin/frontend
      target: builder  # 使用 builder stage（包含 Node.js）
    container_name: aichatbot-knowledge-admin-web
    command: npm run dev
    ports:
      - "8087:5173"  # Vite 開發伺服器埠
    volumes:
      # 掛載原始碼以支援熱重載
      - ./knowledge-admin/frontend/src:/app/src
      - ./knowledge-admin/frontend/public:/app/public
      - ./knowledge-admin/frontend/index.html:/app/index.html
      - ./knowledge-admin/frontend/vite.config.js:/app/vite.config.js
      - ./knowledge-admin/frontend/package.json:/app/package.json
    environment:
      - NODE_ENV=development
    depends_on:
      - knowledge-admin-api
    restart: unless-stopped

  # 知識庫管理後台 - 前端（正式環境）
  # 使用方式：docker-compose up knowledge-admin-web-prod
  knowledge-admin-web-prod:
    build: ./knowledge-admin/frontend
    container_name: aichatbot-knowledge-admin-web-prod
    ports:
      - "8081:80"
    volumes:
      - ./knowledge-admin/frontend/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - knowledge-admin-api
    restart: unless-stopped
    profiles:
      - production  # 需明確指定 profile 才會啟動

  # RAG Orchestrator (Phase 2)
  rag-orchestrator:
    build: ./rag-orchestrator
    container_name: aichatbot-rag-orchestrator
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL: gpt-3.5-turbo  # 預設 LLM 模型（速度快 2-3倍，成本低 70%）
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: aichatbot_admin
      DB_USER: aichatbot
      DB_PASSWORD: aichatbot_password
      EMBEDDING_API_URL: http://embedding-api:5000/api/v1/embeddings
      KNOWLEDGE_GEN_MODEL: ${KNOWLEDGE_GEN_MODEL:-gpt-3.5-turbo}  # AI 知識生成專用模型
    ports:
      - "8100:8100"
    volumes:
      # 開發模式：動態掛載程式碼以支援熱重載
      - ./rag-orchestrator/routers:/app/routers
      - ./rag-orchestrator/services:/app/services
    depends_on:
      - postgres
      - embedding-api
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  pgadmin_data:
