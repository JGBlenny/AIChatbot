#!/usr/bin/env python3
"""
ç°¡å–®çš„èªç¾©æ¨¡å‹è¨“ç·´è…³æœ¬
ç›´æ¥ä½¿ç”¨é è¨“ç·´çš„ BAAI/bge-reranker-base
"""

import json
import os
import sys
from datetime import datetime
from sentence_transformers import CrossEncoder
import numpy as np

def main():
    print("="*60)
    print("èªç¾©æ¨¡å‹è¼‰å…¥èˆ‡æ¸¬è©¦")
    print("="*60)

    # 1. è¼‰å…¥è¨“ç·´æ•¸æ“šä»¥é€²è¡Œæ¸¬è©¦
    print("\n1. è¼‰å…¥æ¸¬è©¦æ•¸æ“š...")
    test_file = "data/test_data.json"
    if not os.path.exists(test_file):
        print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æ•¸æ“š")
        return

    with open(test_file, "r", encoding="utf-8") as f:
        test_data = json.load(f)
    print(f"âœ… è¼‰å…¥äº† {len(test_data)} å€‹æ¸¬è©¦æ¨£æœ¬")

    # 2. è¼‰å…¥é è¨“ç·´æ¨¡å‹
    print("\n2. è¼‰å…¥é è¨“ç·´æ¨¡å‹...")
    print("   æ¨¡å‹: BAAI/bge-reranker-base")
    print("   èªªæ˜: é€™æ˜¯ä¸€å€‹å·²è¨“ç·´å¥½çš„èªç¾©ç†è§£æ¨¡å‹")

    try:
        model = CrossEncoder('BAAI/bge-reranker-base', max_length=512)
        print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ!")

        # 3. æ¸¬è©¦æ¨¡å‹æ•ˆæœ
        print("\n3. æ¸¬è©¦æ¨¡å‹æ•ˆæœ...")
        print("-" * 40)

        # æ¸¬è©¦å¹¾å€‹ç¯„ä¾‹
        test_samples = test_data[:10]
        correct = 0

        for i, sample in enumerate(test_samples):
            query = sample["query"]
            content = sample["knowledge_content"]
            actual_match = sample["is_match"]

            # é æ¸¬
            pairs = [[query, content]]
            scores = model.predict(pairs)
            score = scores[0]
            predicted_match = score > 0.5

            # åˆ¤æ–·æ˜¯å¦æ­£ç¢º
            is_correct = predicted_match == actual_match
            if is_correct:
                correct += 1

            # é¡¯ç¤ºçµæœï¼ˆåªé¡¯ç¤ºå‰3å€‹ï¼‰
            if i < 3:
                result = "âœ…" if is_correct else "âŒ"
                print(f"\n{result} ç¯„ä¾‹ {i+1}:")
                print(f"   æŸ¥è©¢: {query[:50]}...")
                print(f"   æ–‡æª”: {content[:50]}...")
                print(f"   ç›¸é—œæ€§åˆ†æ•¸: {score:.3f}")
                print(f"   é æ¸¬: {'åŒ¹é…' if predicted_match else 'ä¸åŒ¹é…'}")
                print(f"   å¯¦éš›: {'åŒ¹é…' if actual_match else 'ä¸åŒ¹é…'}")

        accuracy = correct / len(test_samples) * 100
        print(f"\næº–ç¢ºç‡: {accuracy:.1f}% ({correct}/{len(test_samples)})")

        # 4. ä¿å­˜æ¨¡å‹
        print("\n4. ä¿å­˜æ¨¡å‹...")
        model_dir = "models/semantic_v1"
        os.makedirs(model_dir, exist_ok=True)

        # ä¿å­˜æ¨¡å‹
        model.save(model_dir)

        # ä¿å­˜é…ç½®ä¿¡æ¯
        config = {
            "base_model": "BAAI/bge-reranker-base",
            "model_type": "CrossEncoder",
            "max_length": 512,
            "test_accuracy": accuracy,
            "saved_at": datetime.now().isoformat()
        }

        with open(f"{model_dir}/config.json", "w", encoding="utf-8") as f:
            json.dump(config, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_dir}")

        # 5. ç¸½çµ
        print("\n" + "="*60)
        print("âœ… å®Œæˆï¼")
        print("="*60)
        print("\næ¨¡å‹è³‡è¨Šï¼š")
        print(f"- åŸºç¤æ¨¡å‹: BAAI/bge-reranker-base")
        print(f"- æ¸¬è©¦æº–ç¢ºç‡: {accuracy:.1f}%")
        print(f"- ä¿å­˜ä½ç½®: {model_dir}")

        if accuracy >= 70:
            print("\nğŸ’¡ æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼Œå¯ä»¥é–‹å§‹ä½¿ç”¨ï¼")
        else:
            print("\nâš ï¸ æº–ç¢ºç‡è¼ƒä½ï¼Œå»ºè­°æª¢æŸ¥æ•¸æ“šå“è³ª")

        print("\nä¸‹ä¸€æ­¥ï¼š")
        print("1. å°‡æ¨¡å‹æ•´åˆåˆ°æ‚¨çš„ç³»çµ±")
        print("2. ä½¿ç”¨æ¨¡å‹é€²è¡Œèªç¾©åŒ¹é…")
        print("3. æŒçºŒæ”¶é›†åé¥‹å„ªåŒ–")

    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        print("\nå¯èƒ½çš„è§£æ±ºæ–¹æ¡ˆï¼š")
        print("1. ç¢ºèªç¶²è·¯é€£æ¥")
        print("2. æª¢æŸ¥ sentence-transformers å®‰è£: pip install sentence-transformers")
        print("3. å˜—è©¦é›¢ç·šä¸‹è¼‰æ¨¡å‹")

if __name__ == "__main__":
    main()