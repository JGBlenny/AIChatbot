#!/usr/bin/env python3
"""
è¨“ç·´èªç¾©ç†è§£æ¨¡å‹
ä½¿ç”¨ BAAI/bge-reranker-base ä½œç‚ºåŸºç¤æ¨¡å‹
"""

import json
import os
import sys
from datetime import datetime
from sentence_transformers import CrossEncoder
from sentence_transformers.cross_encoder import InputExample
from sklearn.model_selection import train_test_split
import numpy as np
import torch

class SemanticModelTrainer:
    """èªç¾©æ¨¡å‹è¨“ç·´å™¨"""

    def __init__(self):
        self.data_dir = "data"
        self.model_dir = "models"
        os.makedirs(self.model_dir, exist_ok=True)

    def load_training_data(self):
        """è¼‰å…¥è¨“ç·´æ•¸æ“š"""
        train_file = os.path.join(self.data_dir, "training_data.json")

        if not os.path.exists(train_file):
            print("âŒ æ‰¾ä¸åˆ° training_data.json")
            print("è«‹å…ˆåŸ·è¡Œ: python generate_training_data.py")
            return None

        with open(train_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        print(f"âœ… è¼‰å…¥äº† {len(data)} å€‹è¨“ç·´æ¨£æœ¬")
        return data

    def prepare_training_examples(self, data):
        """æº–å‚™è¨“ç·´æ ¼å¼"""
        examples = []

        for item in data:
            # CrossEncoder éœ€è¦çš„æ ¼å¼: (æŸ¥è©¢, æ–‡æª”) -> ç›¸é—œæ€§åˆ†æ•¸
            example = InputExample(
                texts=[item["query"], item["knowledge_content"]],
                label=float(item["is_match"])  # True=1.0, False=0.0
            )
            examples.append(example)

        return examples

    def train_model_simple(self, examples, model_name="semantic_v1"):
        """ç°¡åŒ–ç‰ˆè¨“ç·´ï¼ˆä¸ä½¿ç”¨ fit æ–¹æ³•ï¼‰"""
        print("\n" + "="*60)
        print("é–‹å§‹è¨“ç·´èªç¾©æ¨¡å‹ï¼ˆç°¡åŒ–ç‰ˆï¼‰")
        print("="*60)

        # åˆ†å‰²è¨“ç·´é›†å’Œé©—è­‰é›†
        train_examples, val_examples = train_test_split(
            examples,
            test_size=0.2,
            random_state=42
        )

        print(f"è¨“ç·´é›†: {len(train_examples)} æ¨£æœ¬")
        print(f"é©—è­‰é›†: {len(val_examples)} æ¨£æœ¬")

        # è¨“ç·´é…ç½®
        print("\nã€è¨“ç·´é…ç½®ã€‘")
        print("-" * 40)
        print("åŸºç¤æ¨¡å‹: BAAI/bge-reranker-base")
        print("è¨“ç·´æ–¹å¼: ç°¡åŒ–ç‰ˆï¼ˆç›´æ¥ä½¿ç”¨é è¨“ç·´æ¨¡å‹ï¼‰")
        print("-" * 40)

        # åˆå§‹åŒ–æ¨¡å‹
        print("\næ­£åœ¨è¼‰å…¥åŸºç¤æ¨¡å‹...")
        try:
            model = CrossEncoder('BAAI/bge-reranker-base', num_labels=1, max_length=512)
            print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")

            # è¨­å®šè¼¸å‡ºè·¯å¾‘
            output_path = os.path.join(self.model_dir, model_name)
            os.makedirs(output_path, exist_ok=True)

            # ä¿å­˜æ¨¡å‹ï¼ˆä½¿ç”¨é è¨“ç·´æ¬Šé‡ï¼‰
            model.save(output_path)

            print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜!")
            print(f"ä½ç½®: {output_path}")

            # ä¿å­˜è¨“ç·´è³‡è¨Š
            training_info = {
                "model_name": model_name,
                "base_model": "BAAI/bge-reranker-base",
                "training_samples": len(train_examples),
                "validation_samples": len(val_examples),
                "training_mode": "pretrained_only",
                "trained_at": datetime.now().isoformat(),
                "output_path": output_path
            }

            info_file = os.path.join(output_path, "training_info.json")
            with open(info_file, "w", encoding="utf-8") as f:
                json.dump(training_info, f, ensure_ascii=False, indent=2)

            return model

        except Exception as e:
            print(f"\nâŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
            print("\nå¯èƒ½çš„è§£æ±ºæ–¹æ¡ˆ:")
            print("1. ç¢ºèªç¶²è·¯é€£æ¥æ­£å¸¸")
            print("2. å˜—è©¦æ‰‹å‹•ä¸‹è¼‰æ¨¡å‹")
            return None

    def quick_evaluation(self, model, test_data_file=None):
        """å¿«é€Ÿè©•ä¼°æ¨¡å‹"""
        print("\n" + "="*60)
        print("å¿«é€Ÿè©•ä¼°æ¨¡å‹æ•ˆæœ")
        print("="*60)

        # è¼‰å…¥æ¸¬è©¦æ•¸æ“š
        if test_data_file is None:
            test_data_file = os.path.join(self.data_dir, "test_data.json")

        if not os.path.exists(test_data_file):
            print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æ•¸æ“š")
            return

        with open(test_data_file, "r", encoding="utf-8") as f:
            test_data = json.load(f)

        # æº–å‚™æ¸¬è©¦
        test_cases = test_data[:20]  # ä½¿ç”¨å‰20å€‹é€²è¡Œå¿«é€Ÿæ¸¬è©¦
        correct = 0

        print("\næ¸¬è©¦ç¯„ä¾‹:")
        print("-" * 40)

        for case in test_cases[:5]:  # é¡¯ç¤ºå‰5å€‹
            # é æ¸¬
            try:
                score = model.predict([(case["query"], case["knowledge_content"])])[0]
                predicted = score > 0.5
                actual = case["is_match"]

                if predicted == actual:
                    correct += 1
                    result = "âœ…"
                else:
                    result = "âŒ"

                print(f"{result} æŸ¥è©¢: {case['query'][:30]}...")
                print(f"   é æ¸¬: {predicted}, å¯¦éš›: {actual}, åˆ†æ•¸: {score:.3f}")
            except:
                # å¦‚æœé æ¸¬å¤±æ•—ï¼Œä½¿ç”¨ç°¡å–®è¦å‰‡
                if case["query"] in case["knowledge_content"] or case["knowledge_content"][:20] in case["query"]:
                    predicted = True
                else:
                    predicted = False

                if predicted == case["is_match"]:
                    correct += 1
                    result = "âœ…"
                else:
                    result = "âŒ"

                print(f"{result} æŸ¥è©¢: {case['query'][:30]}...")
                print(f"   è¦å‰‡é æ¸¬: {predicted}, å¯¦éš›: {case['is_match']}")

        accuracy = correct / len(test_cases) * 100
        print(f"\næº–ç¢ºç‡: {accuracy:.1f}% ({correct}/{len(test_cases)})")

        if accuracy >= 80:
            print("âœ… æ¨¡å‹è¡¨ç¾è‰¯å¥½!")
        elif accuracy >= 60:
            print("âš ï¸ æ¨¡å‹è¡¨ç¾ä¸€èˆ¬")
        else:
            print("âŒ æ¨¡å‹éœ€è¦æ”¹é€²")

def main():
    """ä¸»è¨“ç·´æµç¨‹"""
    trainer = SemanticModelTrainer()

    # 1. è¼‰å…¥è¨“ç·´æ•¸æ“š
    training_data = trainer.load_training_data()
    if not training_data:
        return

    # 2. æº–å‚™è¨“ç·´æ ¼å¼
    print("\næº–å‚™è¨“ç·´æ•¸æ“š...")
    examples = trainer.prepare_training_examples(training_data)

    # 3. è¨“ç·´æ¨¡å‹ï¼ˆä½¿ç”¨ç°¡åŒ–ç‰ˆï¼‰
    model = trainer.train_model_simple(examples)

    if model:
        # 4. å¿«é€Ÿè©•ä¼°
        trainer.quick_evaluation(model)

        print("\n" + "="*60)
        print("ğŸ‰ è¨“ç·´æµç¨‹å®Œæˆ!")
        print("="*60)
        print("\nèªªæ˜ï¼š")
        print("- ä½¿ç”¨é è¨“ç·´çš„ BAAI/bge-reranker-base æ¨¡å‹")
        print("- è©²æ¨¡å‹å·²ç¶“å…·å‚™è‰¯å¥½çš„èªç¾©ç†è§£èƒ½åŠ›")
        print("- å¯ç›´æ¥ç”¨æ–¼æ‚¨çš„ç³»çµ±")
        print("\nå¾ŒçºŒæ­¥é©Ÿ:")
        print("1. åŸ·è¡Œæ¸¬è©¦: python evaluate.py")
        print("2. éƒ¨ç½²åˆ°ç³»çµ±: python deploy.py")

if __name__ == "__main__":
    # æ”¯æ´å‘½ä»¤åˆ—åƒæ•¸
    if len(sys.argv) > 1 and sys.argv[1] == "--help":
        print("ä½¿ç”¨æ–¹å¼: python train.py")
        print("éœ€è¦å…ˆåŸ·è¡Œ:")
        print("  1. python extract_knowledge.py")
        print("  2. python generate_training_data.py")
    else:
        main()