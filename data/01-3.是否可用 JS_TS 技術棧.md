# 是否可使用 JavaScript/TypeScript 開發 RAG LLM ChatBot？

⏺ 【核心判斷】✅ 完全可行

  JavaScript/TypeScript 的 RAG LLM ChatBot 生態系已經相當成熟，前端工程師完全可以勝任。

  【關鍵洞察】

  優勢：
  - 前後端統一語言，降低學習成本
  - Node.js 生態系豐富
  - TypeScript 型別安全
  - 容易整合到現有 Laravel + Vue 專案

  劣勢：
  - Python 在 AI/ML 領域的 library 較多較成熟
  - 但對 RAG 應用來說，差距不大

  結論：對你來說，JS/TS 是更好的選擇

  ---
  【JS/TS RAG 技術棧方案】

  🎯 方案一：LangChain.js（推薦）

  為什麼推薦：
  - 最成熟的 JS RAG 框架
  - API 設計良好，TypeScript 支援完整
  - 文檔完善，社群活躍
  - 與 Python 版本概念一致

  技術棧：
  後端：Node.js + TypeScript + LangChain.js
  向量資料庫：Chroma (本地) / Pinecone (雲端) / Qdrant
  LLM：OpenAI API / Anthropic Claude API
  Web 框架：Express / Fastify / Hono

  專案結構：
  jgb-chatbot/
  ├── package.json
  ├── tsconfig.json
  ├── src/
  │   ├── server.ts                 # Express/Fastify 主程式
  │   ├── knowledge/
  │   │   ├── loader.ts             # 載入 Markdown 檔案
  │   │   ├── chunker.ts            # 文檔切分
  │   │   └── embedder.ts           # 向量化
  │   ├── retrieval/
  │   │   ├── vectorStore.ts        # 向量資料庫操作
  │   │   └── metadataFilter.ts    # Frontmatter 過濾
  │   ├── chat/
  │   │   ├── chatController.ts     # ChatBot API
  │   │   └── promptTemplate.ts    # Prompt 模板
  │   └── types/
  │       └── knowledge.ts          # TypeScript 型別定義
  └── knowledge-base/               # 知識庫（Markdown）
      ├── 01-物件管理/
      └── 02-合約管理/

  核心程式碼範例：

  // src/knowledge/loader.ts
  import fs from 'fs/promises'
  import path from 'path'
  import matter from 'gray-matter' // 解析 YAML frontmatter
  import { Document } from 'langchain/document'

  interface KnowledgeMetadata {
    title: string
    category: string
    tags: string[]
    applicable_roles: string[]
    difficulty: '基礎' | '進階' | '專家'
    last_updated: string
    author: string
  }

  export async function loadKnowledgeBase(
    basePath: string = './knowledge-base'
  ): Promise<Document<KnowledgeMetadata>[]> {
    const documents: Document<KnowledgeMetadata>[] = []

    // 遞迴讀取所有 .md 檔案
    async function walkDir(dir: string) {
      const files = await fs.readdir(dir, { withFileTypes: true })

      for (const file of files) {
        const filePath = path.join(dir, file.name)

        if (file.isDirectory()) {
          await walkDir(filePath)
        } else if (file.name.endsWith('.md')) {
          const content = await fs.readFile(filePath, 'utf-8')

          // 解析 frontmatter
          const { data, content: markdown } = matter(content)

          documents.push(
            new Document({
              pageContent: markdown,
              metadata: {
                ...data as KnowledgeMetadata,
                source: filePath
              }
            })
          )
        }
      }
    }

    await walkDir(basePath)
    return documents
  }

  // src/knowledge/chunker.ts
  import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'
  import { Document } from 'langchain/document'

  export async function chunkDocuments(
    documents: Document[]
  ): Promise<Document[]> {
    const splitter = new RecursiveCharacterTextSplitter({
      chunkSize: 1500,        // 每塊最多 1500 字
      chunkOverlap: 200,      // 重疊 200 字（避免切斷語意）
      separators: ['\n## ', '\n### ', '\n\n', '\n', ' ', '']
    })

    return await splitter.splitDocuments(documents)
  }

  // src/retrieval/vectorStore.ts
  import { OpenAIEmbeddings } from 'langchain/embeddings/openai'
  import { Chroma } from 'langchain/vectorstores/chroma'
  import { Document } from 'langchain/document'

  let vectorStore: Chroma | null = null

  export async function initVectorStore(documents: Document[]) {
    const embeddings = new OpenAIEmbeddings({
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: 'text-embedding-3-small' // 便宜又好用
    })

    vectorStore = await Chroma.fromDocuments(documents, embeddings, {
      collectionName: 'jgb-knowledge',
      url: process.env.CHROMA_URL || 'http://localhost:8000'
    })

    return vectorStore
  }

  export async function searchKnowledge(
    query: string,
    userRole?: string,
    topK: number = 5
  ): Promise<Document[]> {
    if (!vectorStore) {
      throw new Error('Vector store not initialized')
    }

    // 向量搜尋
    let results = await vectorStore.similaritySearch(query, topK * 2)

    // 如果有指定角色，過濾文檔
    if (userRole) {
      results = results.filter(doc => {
        const roles = doc.metadata.applicable_roles || []
        return roles.includes(userRole) || roles.includes('全部')
      })
    }

    // 按難度排序（基礎優先）
    results.sort((a, b) => {
      const difficultyOrder = { '基礎': 0, '進階': 1, '專家': 2 }
      return (
        difficultyOrder[a.metadata.difficulty] -
        difficultyOrder[b.metadata.difficulty]
      )
    })

    return results.slice(0, topK)
  }

  // src/chat/chatController.ts
  import { ChatOpenAI } from 'langchain/chat_models/openai'
  import { HumanMessage, SystemMessage } from 'langchain/schema'
  import { searchKnowledge } from '../retrieval/vectorStore'

  const llm = new ChatOpenAI({
    openAIApiKey: process.env.OPENAI_API_KEY,
    modelName: 'gpt-4o-mini',
    temperature: 0.2 // 降低隨機性，提高準確性
  })

  export async function chat(
    userQuery: string,
    userRole?: string
  ): Promise<string> {
    // 1. 檢索相關知識
    const relevantDocs = await searchKnowledge(userQuery, userRole, 3)

    // 2. 組合 context
    const context = relevantDocs
      .map(doc => `【${doc.metadata.title}】\n${doc.pageContent}`)
      .join('\n\n---\n\n')

    // 3. 建立 prompt
    const systemPrompt = `你是 JGB 包租代管系統的客服助理。
  請基於以下知識庫內容回答用戶問題，並遵守以下原則：

  1. 只使用知識庫中的資訊回答
  2. 如果知識庫沒有相關資訊，誠實告知「我在知識庫中找不到相關資訊」
  3. 回答要清晰、具體、有步驟
  4. 如果需要，引用知識來源（文件標題）
  5. 使用繁體中文和台灣用語

  【知識庫內容】
  ${context}

  【使用者角色】
  ${userRole || '未指定'}
  `

    // 4. 呼叫 LLM
    const response = await llm.call([
      new SystemMessage(systemPrompt),
      new HumanMessage(userQuery)
    ])

    return response.content as string
  }

  // src/server.ts
  import express from 'express'
  import { loadKnowledgeBase } from './knowledge/loader'
  import { chunkDocuments } from './knowledge/chunker'
  import { initVectorStore } from './retrieval/vectorStore'
  import { chat } from './chat/chatController'

  const app = express()
  app.use(express.json())

  // 啟動時載入知識庫
  async function bootstrap() {
    console.log('載入知識庫...')
    const documents = await loadKnowledgeBase('./knowledge-base')

    console.log('文檔切分...')
    const chunks = await chunkDocuments(documents)

    console.log('建立向量索引...')
    await initVectorStore(chunks)

    console.log(`✅ 知識庫載入完成！共 ${documents.length} 份文檔`)
  }

  // ChatBot API
  app.post('/api/chat', async (req, res) => {
    try {
      const { query, userRole } = req.body

      if (!query) {
        return res.status(400).json({ error: '缺少 query 參數' })
      }

      const answer = await chat(query, userRole)

      res.json({
        success: true,
        answer,
        timestamp: new Date().toISOString()
      })
    } catch (error) {
      console.error('ChatBot 錯誤:', error)
      res.status(500).json({
        success: false,
        error: '系統錯誤，請稍後再試'
      })
    }
  })

  // 啟動伺服器
  const PORT = process.env.PORT || 3001
  bootstrap().then(() => {
    app.listen(PORT, () => {
      console.log(`🚀 ChatBot 服務運行在 http://localhost:${PORT}`)
    })
  })

  package.json：
  {
    "name": "jgb-chatbot",
    "version": "1.0.0",
    "type": "module",
    "scripts": {
      "dev": "tsx watch src/server.ts",
      "build": "tsc",
      "start": "node dist/server.js"
    },
    "dependencies": {
      "langchain": "^0.1.0",
      "@langchain/openai": "^0.0.19",
      "@langchain/community": "^0.0.20",
      "chromadb": "^1.7.0",
      "express": "^4.18.2",
      "gray-matter": "^4.0.3",
      "dotenv": "^16.3.1"
    },
    "devDependencies": {
      "@types/express": "^4.17.21",
      "@types/node": "^20.10.0",
      "tsx": "^4.7.0",
      "typescript": "^5.3.3"
    }
  }

  .env：
  OPENAI_API_KEY=sk-...
  CHROMA_URL=http://localhost:8000
  PORT=3001

  ---
  🎯 方案二：Vercel AI SDK（適合 serverless）

  適合情境：
  - 想部署到 Vercel/Netlify
  - 不想管理伺服器
  - 流量不大

  技術棧：
  框架：Next.js 14 (App Router)
  AI SDK：Vercel AI SDK
  向量資料庫：Pinecone (雲端)
  部署：Vercel

  優點：
  - 零運維
  - 自動擴展
  - 整合前端更簡單

  缺點：
  - Serverless 有冷啟動問題
  - 向量資料庫只能用雲端服務（Pinecone 有費用）

  ---
  🎯 方案三：純前端方案（輕量級）

  適合情境：
  - 知識庫很小（< 50 篇）
  - 不想架設後端
  - 快速 POC

  技術棧：
  框架：Vue 3
  AI：直接呼叫 OpenAI API（從前端）
  向量搜尋：本地 JS 實作（如 hnswlib-wasm）

  範例：
  // 純前端版本（簡化）
  import { embed } from '@vercel/ai'

  // 載入知識庫（打包進前端）
  import knowledgeBase from './knowledge-base.json'

  export async function searchKnowledge(query: string) {
    // 1. 將問題轉成向量
    const queryEmbedding = await embed(query)

    // 2. 計算相似度（餘弦相似度）
    const results = knowledgeBase.map(doc => ({
      ...doc,
      score: cosineSimilarity(queryEmbedding, doc.embedding)
    }))

    // 3. 排序並回傳 top 3
    return results.sort((a, b) => b.score - a.score).slice(0, 3)
  }

  缺點：
  - 知識庫太大會影響效能
  - 暴露 API Key（需要用 proxy）
  - 不適合生產環境

  ---
  【Python vs JS/TS 比較】

  | 項目     | Python                      | JavaScript/TypeScript |
  |--------|-----------------------------|-----------------------|
  | 學習曲線   | 對前端工程師較陌生                   | ✅ 熟悉，零學習成本            |
  | AI 生態系 | ✅ 更成熟（LangChain、LlamaIndex） | 次之但足夠（LangChain.js）   |
  | 型別安全   | 需要 Type Hints               | ✅ TypeScript 原生支援     |
  | 整合性    | 需要前後端分離                     | ✅ 可整合進 Node.js 專案     |
  | 部署     | 需要 Python 環境                | ✅ 可用 Vercel/Netlify   |
  | 效能     | 略優                          | 差距不大                  |
  | 社群     | AI 領域更活躍                    | 通用領域更活躍               |

  結論：對前端工程師來說，JS/TS 是更實用的選擇

  ---
  【推薦技術決策】

  如果你想快速上線（2-4 週）

  ✅ LangChain.js + Express + Chroma (本地)
  - 最成熟的方案
  - TypeScript 型別安全
  - 可整合進現有 Laravel 專案（作為微服務）

  如果你想零運維

  ✅ Next.js + Vercel AI SDK + Pinecone
  - 部署到 Vercel
  - 自動擴展
  - 但向量資料庫有費用（Pinecone 免費額度夠用）

  如果只是 POC 測試

  ✅ 純前端 + OpenAI API
  - 最快上線（幾天）
  - 但不適合生產環境

  ---
  【與現有 JGB2 專案整合】

  選項 1：獨立微服務

  jgb2/                          # Laravel 主專案
  ├── app/
  ├── resources/
  └── ...

  jgb-chatbot/                   # Node.js ChatBot（獨立專案）
  ├── src/
  ├── knowledge-base/
  └── package.json

  # 部署方式
  - JGB2: http://localhost:5798
  - ChatBot: http://localhost:3001

  # 前端呼叫
  fetch('http://localhost:3001/api/chat', {
    method: 'POST',
    body: JSON.stringify({ query: '如何簽約？', userRole: '房東' })
  })

  選項 2：整合進 Laravel

  jgb2/
  ├── app/
  ├── resources/
  ├── chatbot/                   # Node.js ChatBot
  │   ├── src/
  │   └── package.json
  └── ...

  # Laravel 呼叫 Node.js
  Route::post('/api/chatbot', function(Request $request) {
      $response = Http::post('http://localhost:3001/api/chat', [
          'query' => $request->query,
          'userRole' => Auth::user()->current_role->name
      ]);

      return $response->json();
  });

  ---
  【總結與建議】

  | 問題           | 答案                                  |
  |--------------|-------------------------------------|
  | 可以用 JS/TS 嗎？ | ✅ 完全可行，且更適合你                        |
  | 推薦方案         | LangChain.js + TypeScript + Express |
  | 向量資料庫        | 開發用 Chroma（本地），生產用 Pinecone（雲端）     |
  | LLM          | OpenAI API（gpt-4o-mini）或 Claude API |
  | 整合方式         | 獨立微服務，用 HTTP API 溝通                 |

  下一步行動：
  1. ✅ 先建立知識庫（階段一）
  2. ⏸️ 知識庫有 20+ 篇後，開始用 LangChain.js 建立 POC
  3. 🚀 POC 驗證後，整合進 JGB2 專案
