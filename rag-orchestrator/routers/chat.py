"""
èŠå¤© API è·¯ç”±
è™•ç†ä½¿ç”¨è€…å•é¡Œï¼Œæ•´åˆæ„åœ–åˆ†é¡ã€RAG æª¢ç´¢å’Œä¿¡å¿ƒåº¦è©•ä¼°

Phase 1: æ–°å¢å¤šæ¥­è€…æ”¯æ´ï¼ˆMulti-Vendor Chat APIï¼‰
"""
from __future__ import annotations  # å…è¨±é¡å‹æç¤ºçš„å‰å‘å¼•ç”¨

from fastapi import APIRouter, HTTPException, Request
from pydantic import BaseModel, Field
from typing import Optional, List, Dict
from datetime import datetime
import time
import json
import os
import psycopg2
import psycopg2.extras
from services.db_utils import get_db_config
from services.embedding_utils import get_embedding_client

router = APIRouter()

# Phase 1: å¤šæ¥­è€…æœå‹™å¯¦ä¾‹ï¼ˆæ‡¶åŠ è¼‰ï¼‰
_vendor_knowledge_retriever = None
_vendor_param_resolver = None
_vendor_sop_retriever = None


def get_vendor_knowledge_retriever():
    """ç²å–æ¥­è€…çŸ¥è­˜æª¢ç´¢å™¨"""
    global _vendor_knowledge_retriever
    if _vendor_knowledge_retriever is None:
        from services.vendor_knowledge_retriever import VendorKnowledgeRetriever
        _vendor_knowledge_retriever = VendorKnowledgeRetriever()
    return _vendor_knowledge_retriever


def get_vendor_param_resolver():
    """ç²å–æ¥­è€…åƒæ•¸è§£æå™¨"""
    global _vendor_param_resolver
    if _vendor_param_resolver is None:
        from services.vendor_parameter_resolver import VendorParameterResolver
        _vendor_param_resolver = VendorParameterResolver()
    return _vendor_param_resolver


def get_vendor_sop_retriever():
    """ç²å–æ¥­è€… SOP æª¢ç´¢å™¨"""
    global _vendor_sop_retriever
    if _vendor_sop_retriever is None:
        from services.vendor_sop_retriever import VendorSOPRetriever
        _vendor_sop_retriever = VendorSOPRetriever()
    return _vendor_sop_retriever


def cache_response_and_return(cache_service, vendor_id: int, question: str, response, user_role: str = "customer"):
    """
    ç·©å­˜éŸ¿æ‡‰ä¸¦è¿”å›ï¼ˆè¼”åŠ©å‡½æ•¸ï¼‰

    Args:
        cache_service: ç·©å­˜æœå‹™å¯¦ä¾‹
        vendor_id: æ¥­è€… ID
        question: ç”¨æˆ¶å•é¡Œ
        response: VendorChatResponse å¯¦ä¾‹
        user_role: ç”¨æˆ¶è§’è‰²

    Returns:
        åŸå§‹ response
    """
    try:
        # å°‡éŸ¿æ‡‰è½‰æ›ç‚ºå­—å…¸ä¸¦ç·©å­˜
        response_dict = response.dict()
        cache_service.cache_answer(
            vendor_id=vendor_id,
            question=question,
            answer_data=response_dict,
            user_role=user_role
        )
    except Exception as e:
        # ç·©å­˜å¤±æ•—ä¸æ‡‰å½±éŸ¿æ­£å¸¸éŸ¿æ‡‰
        print(f"âš ï¸  ç·©å­˜å­˜å„²å¤±æ•—: {e}")

    return response


# ==================== è¼”åŠ©å‡½æ•¸ï¼šç­”æ¡ˆæ¸…ç†èˆ‡æ¨¡æ¿æ›¿æ› ====================

def _clean_answer(answer: str, vendor_id: int, resolver) -> str:
    """
    æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰

    è™•ç†å…©ç¨®æƒ…æ³ï¼š
    1. æ¨¡æ¿è®Šæ•¸æ ¼å¼ï¼š{{service_hotline}} â†’ 02-2345-6789
    2. ç•°å¸¸æ ¼å¼ï¼š@vendorA, @vendor_name ç­‰ â†’ ç§»é™¤

    Args:
        answer: åŸå§‹ç­”æ¡ˆ
        vendor_id: æ¥­è€… ID
        resolver: åƒæ•¸è§£æå™¨

    Returns:
        æ¸…ç†å¾Œçš„ç­”æ¡ˆ
    """
    import re

    # 1. æ›¿æ›æ˜ç¢ºçš„æ¨¡æ¿è®Šæ•¸ {{xxx}}
    cleaned = resolver.resolve_template(answer, vendor_id, raise_on_missing=False)

    # 2. æ¸…ç†ç•°å¸¸æ ¼å¼ï¼ˆå·²åœç”¨ï¼Œå› ç‚ºæœƒèª¤åˆªçœŸå¯¦ LINE IDï¼‰
    # æ³¨æ„ï¼š@vendorA å¯èƒ½æ˜¯çœŸå¯¦çš„ LINE IDï¼Œä¸æ‡‰è©²ç§»é™¤
    # cleaned = re.sub(r'@vendor[A-Za-z0-9_]*', '', cleaned)  # â† å·²åœç”¨

    # 3. å¦‚æœä»æœ‰æœªæ›¿æ›çš„æ¨¡æ¿è®Šæ•¸ï¼Œè¨˜éŒ„è­¦å‘Š
    if '{{' in cleaned:
        remaining_vars = re.findall(r'\{\{(\w+)\}\}', cleaned)
        print(f"âš ï¸  è­¦å‘Šï¼šç­”æ¡ˆä¸­ä»æœ‰æœªæ›¿æ›çš„æ¨¡æ¿è®Šæ•¸: {remaining_vars}")

    return cleaned


# ==================== è¼”åŠ©å‡½æ•¸ï¼šæ¥­è€…é©—è­‰èˆ‡ç·©å­˜ ====================

def _validate_vendor(vendor_id: int, resolver) -> dict:
    """é©—è­‰æ¥­è€…ç‹€æ…‹"""
    vendor_info = resolver.get_vendor_info(vendor_id)

    if not vendor_info:
        raise HTTPException(
            status_code=404,
            detail=f"æ¥­è€…ä¸å­˜åœ¨: {vendor_id}"
        )

    if not vendor_info['is_active']:
        raise HTTPException(
            status_code=403,
            detail=f"æ¥­è€…æœªå•Ÿç”¨: {vendor_id}"
        )

    return vendor_info


def _check_cache(cache_service, vendor_id: int, question: str, user_role: str):
    """æª¢æŸ¥ç·©å­˜ï¼Œå¦‚æœå‘½ä¸­å‰‡è¿”å›ç·©å­˜çš„ç­”æ¡ˆ"""
    cached_answer = cache_service.get_cached_answer(
        vendor_id=vendor_id,
        question=question,
        user_role=user_role
    )

    if cached_answer:
        print(f"âš¡ ç·©å­˜å‘½ä¸­ï¼ç›´æ¥è¿”å›ç­”æ¡ˆï¼ˆè·³é RAG è™•ç†ï¼‰")
        return VendorChatResponse(**cached_answer)

    return None


#==================== è¼”åŠ©å‡½æ•¸ï¼šUnclear æ„åœ–è™•ç† ====================

async def _handle_unclear_with_rag_fallback(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    resolver,
    vendor_info: dict,
    cache_service
):
    """è™•ç† unclear æ„åœ–ï¼šRAG fallback + æ¸¬è©¦å ´æ™¯è¨˜éŒ„ + æ„åœ–å»ºè­°"""
    rag_engine = req.app.state.rag_engine

    # RAG æª¢ç´¢ï¼ˆä½¿ç”¨è¼ƒä½é–¾å€¼ï¼‰
    fallback_similarity_threshold = float(os.getenv("FALLBACK_SIMILARITY_THRESHOLD", "0.55"))
    rag_top_k = int(os.getenv("RAG_TOP_K", "5"))
    rag_results = await rag_engine.search(
        query=request.message,
        limit=rag_top_k,
        similarity_threshold=fallback_similarity_threshold,
        vendor_id=request.vendor_id
    )

    # å¦‚æœ RAG æ‰¾åˆ°çµæœï¼Œå„ªåŒ–ä¸¦è¿”å›ç­”æ¡ˆ
    if rag_results:
        return await _build_rag_response(
            request, req, intent_result, rag_results,
            resolver, vendor_info, cache_service,
            confidence_level='medium',
            intent_name="unclear"
        )

    # å¦‚æœ RAG ä¹Ÿæ²’æ‰¾åˆ°ï¼Œè¨˜éŒ„å•é¡Œä¸¦è¿”å›å…œåº•å›æ‡‰
    await _record_unclear_question(request, req)

    params = resolver.get_vendor_parameters(request.vendor_id)
    service_hotline = params.get('service_hotline', {}).get('value', 'å®¢æœ')

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰
    fallback_answer = f"æˆ‘ç›®å‰æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ‚¨å•é¡Œçš„è³‡è¨Šï¼Œä½†æˆ‘å¯ä»¥å”åŠ©æ‚¨è½‰çµ¦å®¢æœè™•ç†ã€‚å¦‚éœ€ç«‹å³å”åŠ©ï¼Œè«‹æ’¥æ‰“å®¢æœå°ˆç·š {service_hotline}ã€‚è«‹å•æ‚¨æ–¹ä¾¿æä¾›æ›´è©³ç´°çš„å…§å®¹å—ï¼Ÿ"
    final_answer = _clean_answer(fallback_answer, request.vendor_id, resolver)

    return VendorChatResponse(
        answer=final_answer,
        intent_name="unclear",
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=None,
        source_count=0,
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat()
    )


async def _record_unclear_question(request: VendorChatRequest, req: Request):
    """
    è¨˜éŒ„ unclear å•é¡Œåˆ°æ¸¬è©¦å ´æ™¯åº« + æ„åœ–å»ºè­°

    åŠŸèƒ½å¢å¼·ï¼ˆèªç¾©å»é‡ï¼‰ï¼š
    - ç›¸é—œåº¦éæ¿¾ï¼šrelevance_score >= 0.7
    - èªç¾©å»é‡ï¼šä½¿ç”¨ embedding æª¢æ¸¬ç›¸ä¼¼å•é¡Œï¼ˆsimilarity >= 0.80ï¼‰
    - ç·¨è¼¯è·é›¢ï¼šLevenshtein Distance <= 2ï¼ˆæ•¸æ“šåº«å±¤ï¼‰
    """
    # 1. ä½¿ç”¨æ„åœ–å»ºè­°å¼•æ“åˆ†æå•é¡Œç›¸é—œæ€§
    suggestion_engine = req.app.state.suggestion_engine
    analysis = suggestion_engine.analyze_unclear_question(
        question=request.message,
        vendor_id=request.vendor_id,
        user_id=request.user_id,
        conversation_context=None
    )

    # ç²å–ç›¸é—œåº¦è©•ä¼°çµæœ
    is_relevant = analysis.get('is_relevant', False)
    relevance_score = analysis.get('relevance_score', 0.0)
    should_record = analysis.get('should_record', False)

    # åªè¨˜éŒ„ç›¸é—œåº¦é«˜çš„å•é¡Œ (relevance_score >= 0.7)
    if not should_record:
        print(f"â­ï¸  è·³éè¨˜éŒ„ï¼šå•é¡Œç›¸é—œåº¦ä¸è¶³ (score: {relevance_score:.2f}, relevant: {is_relevant})")
        print(f"   å•é¡Œ: {request.message}")
        return

    # 2. ç”Ÿæˆå•é¡Œçš„ embeddingï¼ˆç”¨æ–¼èªç¾©å»é‡ï¼‰
    embedding_client = get_embedding_client()
    question_embedding = await embedding_client.get_embedding(request.message, verbose=False)

    if not question_embedding:
        print(f"âš ï¸  ç„¡æ³•ç”Ÿæˆå•é¡Œå‘é‡ï¼Œå›é€€åˆ°ç²¾ç¢ºåŒ¹é…æ¨¡å¼")
        # å¾ŒçºŒä»æœƒé€²è¡Œç²¾ç¢ºåŒ¹é…æª¢æŸ¥

    # 3. è¨˜éŒ„åˆ°æ¸¬è©¦å ´æ™¯åº«ï¼ˆç›¸é—œåº¦éæ¿¾ + èªç¾©å»é‡ï¼‰
    try:
        test_scenario_conn = psycopg2.connect(**get_db_config())
        test_scenario_cursor = test_scenario_conn.cursor(cursor_factory=psycopg2.extras.DictCursor)

        # 3a. ç²¾ç¢ºåŒ¹é…æª¢æŸ¥ï¼ˆå®Œå…¨ç›¸åŒçš„å•é¡Œï¼‰
        test_scenario_cursor.execute("""
            SELECT id, status FROM test_scenarios
            WHERE test_question = %s
              AND status IN ('pending_review', 'draft', 'approved')
              AND is_active = true
        """, (request.message,))
        exact_match = test_scenario_cursor.fetchone()

        if exact_match:
            scenario_id, existing_status = exact_match
            print(f"â­ï¸  è·³éè¨˜éŒ„ï¼šå®Œå…¨ç›¸åŒå•é¡Œå·²å­˜åœ¨ (Scenario ID: {scenario_id}, ç‹€æ…‹: {existing_status})")
            print(f"   å•é¡Œ: {request.message}")
            test_scenario_cursor.close()
            test_scenario_conn.close()
            return

        # 3b. èªç¾©ç›¸ä¼¼åº¦æª¢æŸ¥ï¼ˆä½¿ç”¨ embedding å‘é‡æœç´¢ï¼‰
        if question_embedding:
            vector_str = '[' + ','.join(map(str, question_embedding)) + ']'

            test_scenario_cursor.execute("""
                SELECT
                    id,
                    test_question,
                    status,
                    (1 - (question_embedding <=> %s::vector)) AS similarity
                FROM test_scenarios
                WHERE question_embedding IS NOT NULL
                  AND status IN ('pending_review', 'draft', 'approved')
                  AND is_active = true
                  AND test_question != %s
                  AND (1 - (question_embedding <=> %s::vector)) >= 0.80
                ORDER BY similarity DESC
                LIMIT 1
            """, (vector_str, request.message, vector_str))

            similar_match = test_scenario_cursor.fetchone()

            if similar_match:
                scenario_id = similar_match['id']
                similar_question = similar_match['test_question']
                similarity = similar_match['similarity']
                existing_status = similar_match['status']

                print(f"â­ï¸  è·³éè¨˜éŒ„ï¼šç›¸ä¼¼å•é¡Œå·²å­˜åœ¨ (Scenario ID: {scenario_id}, ç‹€æ…‹: {existing_status})")
                print(f"   åŸå•é¡Œ: {request.message}")
                print(f"   ç›¸ä¼¼å•é¡Œ: {similar_question}")
                print(f"   ç›¸ä¼¼åº¦: {similarity:.3f}")

                test_scenario_cursor.close()
                test_scenario_conn.close()
                return

        # 4. æ’å…¥æ–°çš„æ¸¬è©¦å ´æ™¯è¨˜éŒ„ï¼ˆå« embeddingï¼‰
        if question_embedding:
            vector_str = '[' + ','.join(map(str, question_embedding)) + ']'
            test_scenario_cursor.execute("""
                INSERT INTO test_scenarios (
                    test_question, status, source,
                    difficulty, priority, notes, test_purpose, created_by,
                    question_embedding
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s::vector)
                RETURNING id
            """, (
                request.message, 'pending_review', 'user_question',
                'hard', 80,
                f"ç”¨æˆ¶å•é¡Œæ„åœ–ä¸æ˜ç¢ºï¼ˆVendor {request.vendor_id}ï¼‰ï¼Œç›¸é—œåº¦: {relevance_score:.2f}",
                "è¿½è¹¤æ„åœ–è­˜åˆ¥ç¼ºå£ï¼Œæ”¹å–„åˆ†é¡å™¨",
                request.user_id or 'system',
                vector_str
            ))
        else:
            # ç„¡ embedding æ™‚ä»æ’å…¥è¨˜éŒ„ï¼ˆä½†ç„¡æ³•åšèªç¾©å»é‡ï¼‰
            test_scenario_cursor.execute("""
                INSERT INTO test_scenarios (
                    test_question, status, source,
                    difficulty, priority, notes, test_purpose, created_by
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                request.message, 'pending_review', 'user_question',
                'hard', 80,
                f"ç”¨æˆ¶å•é¡Œæ„åœ–ä¸æ˜ç¢ºï¼ˆVendor {request.vendor_id}ï¼‰ï¼Œç›¸é—œåº¦: {relevance_score:.2f}",
                "è¿½è¹¤æ„åœ–è­˜åˆ¥ç¼ºå£ï¼Œæ”¹å–„åˆ†é¡å™¨",
                request.user_id or 'system'
            ))

        scenario_id = test_scenario_cursor.fetchone()[0]
        test_scenario_conn.commit()

        embedding_status = "âœ… å«å‘é‡" if question_embedding else "âš ï¸  ç„¡å‘é‡"
        print(f"âœ… è¨˜éŒ„unclearå•é¡Œåˆ°æ¸¬è©¦å ´æ™¯åº« (Scenario ID: {scenario_id}, ç›¸é—œåº¦: {relevance_score:.2f}, {embedding_status})")

        test_scenario_cursor.close()
        test_scenario_conn.close()
    except Exception as e:
        print(f"âš ï¸ è¨˜éŒ„æ¸¬è©¦å ´æ™¯å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

    # 5. è¨˜éŒ„æ„åœ–å»ºè­°
    suggested_intent_id = suggestion_engine.record_suggestion(
        question=request.message,
        analysis=analysis,
        user_id=request.user_id
    )
    if suggested_intent_id:
        print(f"âœ… ç™¼ç¾æ–°æ„åœ–å»ºè­°: {analysis['suggested_intent']['name']} (ID: {suggested_intent_id})")


# ==================== è¼”åŠ©å‡½æ•¸ï¼šSOP æª¢ç´¢ ====================

async def _retrieve_sop(request: VendorChatRequest, intent_result: dict) -> list:
    """æª¢ç´¢ SOPï¼ˆSOP å„ªå…ˆæ–¼çŸ¥è­˜åº«ï¼‰- ä½¿ç”¨ Hybrid æ¨¡å¼ï¼ˆIntent + ç›¸ä¼¼åº¦ï¼‰"""
    from routers.chat_shared import retrieve_sop_hybrid

    # ä½¿ç”¨å…±ç”¨æ¨¡çµ„çš„ hybrid ç‰ˆæœ¬ï¼ˆintent + å‘é‡ç›¸ä¼¼åº¦éæ¿¾ï¼‰
    all_intent_ids = intent_result.get('intent_ids', [])
    sop_similarity_threshold = float(os.getenv("SOP_SIMILARITY_THRESHOLD", "0.75"))
    sop_items = await retrieve_sop_hybrid(
        vendor_id=request.vendor_id,
        intent_ids=all_intent_ids,
        query=request.message,  # â† å‚³å…¥å•é¡Œæ–‡æœ¬ç”¨æ–¼ç›¸ä¼¼åº¦è¨ˆç®—
        top_k=request.top_k,
        similarity_threshold=sop_similarity_threshold
    )

    return sop_items


async def _build_sop_response(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    sop_items: list,
    resolver,
    vendor_info: dict,
    cache_service
):
    """ä½¿ç”¨ SOP æ§‹å»ºå›æ‡‰ - ä½¿ç”¨å…±ç”¨æ¨¡çµ„"""
    from routers.chat_shared import convert_sop_to_search_results, create_sop_optimization_params

    llm_optimizer = req.app.state.llm_answer_optimizer

    # ç²å–æ¥­è€…åƒæ•¸ï¼ˆä¿ç•™å®Œæ•´è³‡è¨ŠåŒ…å« display_name, unit ç­‰ï¼‰
    vendor_params = resolver.get_vendor_parameters(request.vendor_id)

    # ä½¿ç”¨å…±ç”¨å‡½æ•¸è½‰æ› SOP ç‚º search_results æ ¼å¼ï¼ˆè‡ªå‹•è¨­å®š similarity=1.0ï¼‰
    search_results = convert_sop_to_search_results(sop_items)

    # ä½¿ç”¨å…±ç”¨å‡½æ•¸å»ºç«‹å„ªåŒ–åƒæ•¸ï¼ˆè‡ªå‹•è¨­å®š confidence=high, score=0.95ï¼‰
    optimization_params = create_sop_optimization_params(
        question=request.message,
        search_results=search_results,
        intent_result=intent_result,
        vendor_params=vendor_params,
        vendor_info=vendor_info,
        enable_synthesis_override=False if request.disable_answer_synthesis else None
    )

    # LLM å„ªåŒ–
    optimization_result = llm_optimizer.optimize_answer(**optimization_params)

    # æ§‹å»ºä¾†æºåˆ—è¡¨
    sources = []
    if request.include_sources:
        sources = [KnowledgeSource(
            id=sop['id'],
            question_summary=sop['item_name'],
            answer=sop['content'],
            scope='vendor_sop',
            is_template=False
        ) for sop in sop_items]

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰
    final_answer = _clean_answer(optimization_result['optimized_answer'], request.vendor_id, resolver)

    response = VendorChatResponse(
        answer=final_answer,
        intent_name=intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=sources if request.include_sources else None,
        source_count=len(sop_items),
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat()
    )

    return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.user_role)


# ==================== è¼”åŠ©å‡½æ•¸ï¼šRAG å›æ‡‰æ§‹å»º ====================

async def _build_rag_response(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    rag_results: list,
    resolver,
    vendor_info: dict,
    cache_service,
    confidence_level: str = 'medium',
    intent_name: str = None
):
    """ä½¿ç”¨ RAG çµæœæ§‹å»ºå„ªåŒ–å›æ‡‰"""
    llm_optimizer = req.app.state.llm_answer_optimizer

    # ç²å–æ¥­è€…åƒæ•¸ï¼ˆä¿ç•™å®Œæ•´è³‡è¨ŠåŒ…å« display_name, unit ç­‰ï¼‰
    vendor_params = resolver.get_vendor_parameters(request.vendor_id)

    # æ ¹æ“š confidence_level è¨­å®š confidence_score
    confidence_score_map = {
        'high': 0.85,
        'medium': 0.70,
        'low': 0.55
    }
    confidence_score = confidence_score_map.get(confidence_level, 0.70)

    # LLM å„ªåŒ–ï¼ˆæ·»åŠ  confidence_score ä»¥ç¢ºä¿åƒæ•¸æ³¨å…¥ï¼‰
    optimization_result = llm_optimizer.optimize_answer(
        question=request.message,
        search_results=rag_results,
        confidence_level=confidence_level,
        confidence_score=confidence_score,  # æ ¹æ“š confidence_level è¨­å®šåˆ†æ•¸
        intent_info=intent_result,
        vendor_params=vendor_params,
        vendor_name=vendor_info['name'],
        vendor_info=vendor_info,  # å‚³å…¥å®Œæ•´æ¥­è€…è³‡è¨Š
        enable_synthesis_override=False if request.disable_answer_synthesis else None
    )

    # æ§‹å»ºä¾†æºåˆ—è¡¨
    sources = []
    if request.include_sources:
        sources = [KnowledgeSource(
            id=r['id'],
            question_summary=r['question_summary'],
            answer=r['content'],
            scope='global',
            is_template=False
        ) for r in rag_results]

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰
    final_answer = _clean_answer(optimization_result['optimized_answer'], request.vendor_id, resolver)

    response = VendorChatResponse(
        answer=final_answer,
        intent_name=intent_name or intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=sources if request.include_sources else None,
        source_count=len(rag_results),
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat()
    )

    return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.user_role)


# ==================== è¼”åŠ©å‡½æ•¸ï¼šçŸ¥è­˜åº«æª¢ç´¢ ====================

async def _retrieve_knowledge(
    request: VendorChatRequest,
    intent_id: int,
    intent_result: dict
):
    """æª¢ç´¢çŸ¥è­˜åº«ï¼ˆæ··åˆæ¨¡å¼ï¼šintent + å‘é‡ç›¸ä¼¼åº¦ï¼‰"""
    retriever = get_vendor_knowledge_retriever()
    all_intent_ids = intent_result.get('intent_ids', [intent_id])
    kb_similarity_threshold = float(os.getenv("KB_SIMILARITY_THRESHOLD", "0.65"))

    knowledge_list = await retriever.retrieve_knowledge_hybrid(
        query=request.message,
        intent_id=intent_id,
        vendor_id=request.vendor_id,
        top_k=request.top_k,
        similarity_threshold=kb_similarity_threshold,
        resolve_templates=False,
        all_intent_ids=all_intent_ids,
        user_role=request.user_role
    )

    return knowledge_list


async def _handle_no_knowledge_found(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    resolver,
    cache_service,
    vendor_info: dict
):
    """è™•ç†æ‰¾ä¸åˆ°çŸ¥è­˜çš„æƒ…æ³ï¼šåƒæ•¸ç­”æ¡ˆ > RAG fallback + æ¸¬è©¦å ´æ™¯è¨˜éŒ„"""
    # Step 1: å„ªå…ˆæª¢æŸ¥æ˜¯å¦ç‚ºåƒæ•¸å‹å•é¡Œï¼ˆæ²’æœ‰çŸ¥è­˜åº«æ™‚çš„å‚™é¸æ–¹æ¡ˆï¼‰
    from routers.chat_shared import check_param_question
    param_category, param_answer = await check_param_question(
        vendor_config_service=req.app.state.vendor_config_service,
        question=request.message,
        vendor_id=request.vendor_id
    )

    if param_answer:
        print(f"   â„¹ï¸  çŸ¥è­˜åº«ç„¡çµæœï¼Œä½¿ç”¨åƒæ•¸å‹ç­”æ¡ˆï¼ˆcategory={param_category}ï¼‰")
        response = VendorChatResponse(
            answer=param_answer['answer'],
            intent_name="åƒæ•¸æŸ¥è©¢",
            intent_type="config_param",
            confidence=1.0,
            sources=[],
            source_count=0,
            vendor_id=request.vendor_id,
            mode=request.mode,
            timestamp=datetime.utcnow().isoformat() + "Z",
            video_url=None
        )
        return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.user_role)

    # Step 2: RAG fallback
    rag_engine = req.app.state.rag_engine
    fallback_similarity_threshold = float(os.getenv("FALLBACK_SIMILARITY_THRESHOLD", "0.55"))
    rag_top_k = int(os.getenv("RAG_TOP_K", str(request.top_k)))
    rag_results = await rag_engine.search(
        query=request.message,
        limit=rag_top_k,
        similarity_threshold=fallback_similarity_threshold,
        vendor_id=request.vendor_id
    )

    # å¦‚æœ RAG æ‰¾åˆ°çµæœï¼Œè¿”å›å„ªåŒ–ç­”æ¡ˆ
    if rag_results:
        print(f"   âœ… RAG fallback æ‰¾åˆ° {len(rag_results)} å€‹ç›¸é—œçŸ¥è­˜")
        return await _build_rag_response(
            request, req, intent_result, rag_results,
            resolver, vendor_info, cache_service,
            confidence_level='high'
        )

    # Step 3: å¦‚æœ RAG ä¹Ÿæ‰¾ä¸åˆ°ï¼Œè¨˜éŒ„æ¸¬è©¦å ´æ™¯ä¸¦è¿”å›å…œåº•å›æ‡‰
    print(f"   âŒ RAG fallback ä¹Ÿæ²’æœ‰æ‰¾åˆ°ç›¸é—œçŸ¥è­˜")
    await _record_no_knowledge_scenario(request, intent_result, req)

    params = resolver.get_vendor_parameters(request.vendor_id)
    service_hotline = params.get('service_hotline', {}).get('value', 'å®¢æœ')

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰
    fallback_answer = f"æˆ‘ç›®å‰æ²’æœ‰æ‰¾åˆ°é—œæ–¼ã€Œ{intent_result['intent_name']}ã€çš„ç›¸é—œè³‡è¨Šï¼Œä½†æˆ‘å¯ä»¥å”åŠ©æ‚¨è½‰çµ¦å®¢æœè™•ç†ã€‚å¦‚éœ€ç«‹å³å”åŠ©ï¼Œè«‹æ’¥æ‰“å®¢æœå°ˆç·š {service_hotline}ã€‚è«‹å•æ‚¨æ–¹ä¾¿æä¾›æ›´è©³ç´°çš„å…§å®¹å—ï¼Ÿ"
    final_answer = _clean_answer(fallback_answer, request.vendor_id, resolver)

    return VendorChatResponse(
        answer=final_answer,
        intent_name=intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=None,
        source_count=0,
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat()
    )


async def _record_no_knowledge_scenario(request: VendorChatRequest, intent_result: dict, req: Request):
    """è¨˜éŒ„æ‰¾ä¸åˆ°çŸ¥è­˜çš„å ´æ™¯åˆ°æ¸¬è©¦åº« + æ„åœ–å»ºè­°"""
    # 1. è¨˜éŒ„åˆ°æ¸¬è©¦å ´æ™¯åº«
    try:
        test_scenario_conn = psycopg2.connect(**get_db_config())
        test_scenario_cursor = test_scenario_conn.cursor()

        test_scenario_cursor.execute(
            "SELECT id FROM test_scenarios WHERE test_question = %s AND status = 'pending_review'",
            (request.message,)
        )
        existing_scenario = test_scenario_cursor.fetchone()

        if not existing_scenario:
            test_scenario_cursor.execute("""
                INSERT INTO test_scenarios (
                    test_question, status, source,
                    difficulty, priority, notes, test_purpose, created_by
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                request.message,
                'pending_review', 'user_question', 'medium', 70,
                f"ç”¨æˆ¶çœŸå¯¦å•é¡Œï¼ˆVendor {request.vendor_id}ï¼‰ï¼Œæ„åœ–: {intent_result.get('intent_name', 'unknown')}ï¼Œç³»çµ±ç„¡æ³•æä¾›ç­”æ¡ˆ",
                "é©—è­‰çŸ¥è­˜åº«è¦†è“‹ç‡ï¼Œè¿½è¹¤ç”¨æˆ¶çœŸå¯¦éœ€æ±‚",
                request.user_id or 'system'
            ))
            scenario_id = test_scenario_cursor.fetchone()[0]
            test_scenario_conn.commit()
            print(f"âœ… è¨˜éŒ„åˆ°æ¸¬è©¦å ´æ™¯åº« (Scenario ID: {scenario_id})")

        test_scenario_cursor.close()
        test_scenario_conn.close()
    except Exception as e:
        print(f"âš ï¸ è¨˜éŒ„æ¸¬è©¦å ´æ™¯å¤±æ•—: {e}")

    # 2. ä½¿ç”¨æ„åœ–å»ºè­°å¼•æ“
    suggestion_engine = req.app.state.suggestion_engine
    analysis = suggestion_engine.analyze_unclear_question(
        question=request.message,
        vendor_id=request.vendor_id,
        user_id=request.user_id,
        conversation_context=None
    )

    if analysis.get('should_record'):
        suggested_intent_id = suggestion_engine.record_suggestion(
            question=request.message,
            analysis=analysis,
            user_id=request.user_id
        )
        if suggested_intent_id:
            print(f"âœ… ç™¼ç¾çŸ¥è­˜ç¼ºå£å»ºè­° (Vendor {request.vendor_id}): {analysis['suggested_intent']['name']} (å»ºè­°ID: {suggested_intent_id})")


async def _build_knowledge_response(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    knowledge_list: list,
    resolver,
    vendor_info: dict,
    cache_service
):
    """ä½¿ç”¨çŸ¥è­˜åº«çµæœæ§‹å»ºå„ªåŒ–å›æ‡‰"""
    llm_optimizer = req.app.state.llm_answer_optimizer
    confidence_evaluator = req.app.state.confidence_evaluator

    # ç²å–æ¥­è€…åƒæ•¸ï¼ˆä¿ç•™å®Œæ•´è³‡è¨ŠåŒ…å« display_name, unit ç­‰ï¼‰
    vendor_params = resolver.get_vendor_parameters(request.vendor_id)

    # æº–å‚™æœå°‹çµæœæ ¼å¼ï¼ˆä½¿ç”¨å¯¦éš›çš„ç›¸ä¼¼åº¦æˆ–é è¨­å€¼ï¼‰
    search_results = [{
        'id': k['id'],
        'question_summary': k['question_summary'],
        'content': k['answer'],
        'similarity': k.get('similarity', 0.9),  # ä½¿ç”¨å¯¦éš›ç›¸ä¼¼åº¦ï¼Œæ²’æœ‰å‰‡ç”¨é è¨­å€¼
        'keywords': k.get('keywords', [])        # æ·»åŠ  keywords ä¾›ä¿¡å¿ƒåº¦è©•ä¼°
    } for k in knowledge_list]

    # ä½¿ç”¨ ConfidenceEvaluator è©•ä¼°ä¿¡å¿ƒåº¦ï¼ˆèˆ‡ /v1/chat/stream çµ±ä¸€ï¼‰
    evaluation = confidence_evaluator.evaluate(
        search_results=search_results,
        question_keywords=intent_result.get('keywords', [])
    )

    confidence_level = evaluation['confidence_level']
    confidence_score = evaluation['confidence_score']

    print(f"ğŸ“Š [çŸ¥è­˜åº«ä¿¡å¿ƒåº¦è©•ä¼°] level={confidence_level}, score={confidence_score:.3f}, decision={evaluation['decision']}")

    # LLM å„ªåŒ–ï¼ˆä½¿ç”¨è©•ä¼°å¾Œçš„ä¿¡å¿ƒåº¦ï¼‰
    optimization_result = llm_optimizer.optimize_answer(
        question=request.message,
        search_results=search_results,
        confidence_level=confidence_level,
        confidence_score=confidence_score,  # ä½¿ç”¨ ConfidenceEvaluator è¨ˆç®—çš„åˆ†æ•¸
        intent_info=intent_result,
        vendor_params=vendor_params,
        vendor_name=vendor_info['name'],
        vendor_info=vendor_info,  # å‚³å…¥å®Œæ•´æ¥­è€…è³‡è¨Š
        enable_synthesis_override=False if request.disable_answer_synthesis else None
    )

    # æ§‹å»ºä¾†æºåˆ—è¡¨
    sources = []
    if request.include_sources:
        sources = [KnowledgeSource(
            id=k['id'],
            question_summary=k['question_summary'],
            answer=k['answer'],
            scope=k['scope'],
            is_template=k['is_template']
        ) for k in knowledge_list]

    # æå–å½±ç‰‡è³‡è¨Šï¼ˆå¾ç¬¬ä¸€å€‹çŸ¥è­˜é …ç›®ï¼‰
    video_url = None
    video_file_size = None
    video_duration = None
    video_format = None
    if knowledge_list:
        first_knowledge = knowledge_list[0]
        video_url = first_knowledge.get('video_url')
        video_file_size = first_knowledge.get('video_file_size')
        video_duration = first_knowledge.get('video_duration')
        video_format = first_knowledge.get('video_format')

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰
    final_answer = _clean_answer(optimization_result['optimized_answer'], request.vendor_id, resolver)

    response = VendorChatResponse(
        answer=final_answer,
        intent_name=intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=sources if request.include_sources else None,
        source_count=len(knowledge_list),
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat(),
        video_url=video_url,
        video_file_size=video_file_size,
        video_duration=video_duration,
        video_format=video_format
    )

    return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.user_role)


# ========================================
# /api/v1/chat ç«¯é»å·²æ–¼ 2025-10-21 ç§»é™¤
# ========================================
#
# ç§»é™¤åŸå› ï¼šåŠŸèƒ½å·²ç”±æ›´å¼·å¤§çš„ç«¯é»æ›¿ä»£
#
# æ›¿ä»£æ–¹æ¡ˆï¼š
# 1. /api/v1/message - å¤šæ¥­è€…é€šç”¨ç«¯é»
#    - æ”¯æŒ SOP æ•´åˆ
#    - æ”¯æŒæ¥­è€…åƒæ•¸é…ç½®
#    - æ”¯æŒå¤š Intent æª¢ç´¢
#
# 2. /api/v1/chat/stream - æµå¼èŠå¤©ç«¯é»
#    - æä¾›å³æ™‚åé¥‹
#    - æ›´å¥½çš„ç”¨æˆ¶é«”é©—
#
# è©³è¦‹ï¼š
# - docs/api/CHAT_ENDPOINT_REMOVAL_AUDIT.md (ç›¤æŸ¥å ±å‘Š)
# - docs/api/CHAT_API_MIGRATION_GUIDE.md (é·ç§»æŒ‡å—)
#
# å·²ç§»é™¤çš„é …ç›®ï¼š
# - class ChatRequest
# - class ChatResponse
# - POST /chat ç«¯é»å‡½æ•¸
#
# ========================================


@router.get("/conversations")
async def get_conversations(
    req: Request,
    limit: int = 20,
    offset: int = 0,
    user_id: Optional[str] = None,
    intent_type: Optional[str] = None
):
    """
    å–å¾—å°è©±è¨˜éŒ„åˆ—è¡¨
    """
    try:
        async with req.app.state.db_pool.acquire() as conn:
            query = """
                SELECT
                    id,
                    user_id,
                    question,
                    intent_type,
                    confidence_score,
                    final_answer,
                    user_rating,
                    escalated_to_human,
                    created_at
                FROM conversation_logs
                WHERE ($1::text IS NULL OR user_id = $1)
                  AND ($2::text IS NULL OR intent_type = $2)
                ORDER BY created_at DESC
                LIMIT $3 OFFSET $4
            """

            results = await conn.fetch(query, user_id, intent_type, limit, offset)

        return {
            "conversations": [dict(row) for row in results],
            "limit": limit,
            "offset": offset
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"å–å¾—å°è©±è¨˜éŒ„å¤±æ•—: {str(e)}"
        )


@router.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: int, req: Request):
    """
    å–å¾—ç‰¹å®šå°è©±çš„è©³ç´°è³‡è¨Š
    """
    try:
        async with req.app.state.db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT *
                FROM conversation_logs
                WHERE id = $1
            """, conversation_id)

            if not row:
                raise HTTPException(status_code=404, detail="å°è©±è¨˜éŒ„ä¸å­˜åœ¨")

            return dict(row)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"å–å¾—å°è©±è©³æƒ…å¤±æ•—: {str(e)}"
        )


class FeedbackRequest(BaseModel):
    """åé¥‹è«‹æ±‚"""
    rating: int = Field(..., ge=1, le=5, description="è©•åˆ† 1-5")
    feedback: Optional[str] = Field(None, max_length=1000, description="åé¥‹å…§å®¹")


@router.post("/conversations/{conversation_id}/feedback")
async def submit_feedback(
    conversation_id: int,
    feedback: FeedbackRequest,
    req: Request
):
    """
    æäº¤å°è©±åé¥‹
    """
    try:
        async with req.app.state.db_pool.acquire() as conn:
            result = await conn.execute("""
                UPDATE conversation_logs
                SET user_rating = $1,
                    user_feedback = $2
                WHERE id = $3
            """, feedback.rating, feedback.feedback, conversation_id)

            if result == "UPDATE 0":
                raise HTTPException(status_code=404, detail="å°è©±è¨˜éŒ„ä¸å­˜åœ¨")

            return {
                "message": "åé¥‹æäº¤æˆåŠŸ",
                "conversation_id": conversation_id
            }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"æäº¤åé¥‹å¤±æ•—: {str(e)}"
        )


# ========================================
# Phase 1: å¤šæ¥­è€…èŠå¤© API
# ========================================

class VendorChatRequest(BaseModel):
    """å¤šæ¥­è€…èŠå¤©è«‹æ±‚"""
    message: str = Field(..., description="ä½¿ç”¨è€…è¨Šæ¯", min_length=1, max_length=2000)
    vendor_id: int = Field(..., description="æ¥­è€… ID", ge=1)
    user_role: str = Field("customer", description="ç”¨æˆ¶è§’è‰²ï¼šcustomer (çµ‚ç«¯å®¢æˆ¶) æˆ– staff (æ¥­è€…å“¡å·¥/ç³»çµ±å•†)")
    mode: str = Field("tenant", description="æ¨¡å¼ï¼štenant (B2C) æˆ– customer_service (B2B)")
    session_id: Optional[str] = Field(None, description="æœƒè©± IDï¼ˆç”¨æ–¼è¿½è¹¤ï¼‰")
    user_id: Optional[str] = Field(None, description="ä½¿ç”¨è€… IDï¼ˆç§Ÿå®¢ ID æˆ–å®¢æœ IDï¼‰")
    top_k: int = Field(5, description="è¿”å›çŸ¥è­˜æ•¸é‡", ge=1, le=10)
    include_sources: bool = Field(True, description="æ˜¯å¦åŒ…å«çŸ¥è­˜ä¾†æº")
    disable_answer_synthesis: bool = Field(False, description="ç¦ç”¨ç­”æ¡ˆåˆæˆï¼ˆå›æ¸¬æ¨¡å¼å°ˆç”¨ï¼‰")
    skip_sop: bool = Field(False, description="è·³é SOP æª¢ç´¢ï¼Œåƒ…æª¢ç´¢çŸ¥è­˜åº«ï¼ˆå›æ¸¬æ¨¡å¼å°ˆç”¨ï¼‰")


class KnowledgeSource(BaseModel):
    """çŸ¥è­˜ä¾†æº"""
    id: int
    question_summary: str
    answer: str
    scope: str
    is_template: bool


class VendorChatResponse(BaseModel):
    """å¤šæ¥­è€…èŠå¤©å›æ‡‰"""
    answer: str = Field(..., description="å›ç­”å…§å®¹")
    intent_name: Optional[str] = Field(None, description="æ„åœ–åç¨±")
    intent_type: Optional[str] = Field(None, description="æ„åœ–é¡å‹")
    confidence: Optional[float] = Field(None, description="åˆ†é¡ä¿¡å¿ƒåº¦")
    all_intents: Optional[List[str]] = Field(None, description="æ‰€æœ‰ç›¸é—œæ„åœ–åç¨±ï¼ˆä¸»è¦ + æ¬¡è¦ï¼‰")
    secondary_intents: Optional[List[str]] = Field(None, description="æ¬¡è¦ç›¸é—œæ„åœ–")
    intent_ids: Optional[List[int]] = Field(None, description="æ‰€æœ‰æ„åœ– IDs")
    sources: Optional[List[KnowledgeSource]] = Field(None, description="çŸ¥è­˜ä¾†æºåˆ—è¡¨")
    source_count: int = Field(0, description="çŸ¥è­˜ä¾†æºæ•¸é‡")
    vendor_id: int
    mode: str
    session_id: Optional[str] = None
    timestamp: str
    # å½±ç‰‡è³‡è¨Š
    video_url: Optional[str] = Field(None, description="æ•™å­¸å½±ç‰‡ URL")
    video_file_size: Optional[int] = Field(None, description="å½±ç‰‡æª”æ¡ˆå¤§å°ï¼ˆbytesï¼‰")
    video_duration: Optional[int] = Field(None, description="å½±ç‰‡é•·åº¦ï¼ˆç§’ï¼‰")
    video_format: Optional[str] = Field(None, description="å½±ç‰‡æ ¼å¼")


@router.post("/message", response_model=VendorChatResponse)
async def vendor_chat_message(request: VendorChatRequest, req: Request):
    """
    å¤šæ¥­è€…é€šç”¨èŠå¤©ç«¯é»ï¼ˆPhase 1: B2C æ¨¡å¼ï¼‰- å·²é‡æ§‹

    æµç¨‹ï¼š
    1. é©—è­‰æ¥­è€…ç‹€æ…‹
    2. æª¢æŸ¥ç·©å­˜
    3. æ„åœ–åˆ†é¡
    4. æ ¹æ“šæ„åœ–è™•ç†ï¼šunclear â†’ SOP â†’ çŸ¥è­˜åº« â†’ RAG fallback
    5. LLM å„ªåŒ–ä¸¦è¿”å›ç­”æ¡ˆ

    é‡æ§‹ï¼šå–®ä¸€è·è²¬åŸå‰‡ï¼ˆSingle Responsibility Principleï¼‰
    - ä¸»å‡½æ•¸ä½œç‚ºç·¨æ’å™¨ï¼ˆOrchestratorï¼‰
    - å„åŠŸèƒ½æ¨¡å¡Šç¨ç«‹ç‚ºè¼”åŠ©å‡½æ•¸
    """
    try:
        # Step 1: é©—è­‰æ¥­è€…
        resolver = get_vendor_param_resolver()
        vendor_info = _validate_vendor(request.vendor_id, resolver)

        # Step 2: ç·©å­˜æª¢æŸ¥
        cache_service = req.app.state.cache_service
        cached_response = _check_cache(cache_service, request.vendor_id, request.message, request.user_role)
        if cached_response:
            return cached_response

        # Step 3: æ„åœ–åˆ†é¡
        intent_classifier = req.app.state.intent_classifier
        intent_result = intent_classifier.classify(request.message)

        # Step 4: è™•ç† unclear æ„åœ–ï¼ˆRAG fallback + æ¸¬è©¦å ´æ™¯è¨˜éŒ„ï¼‰
        if intent_result['intent_name'] == 'unclear':
            return await _handle_unclear_with_rag_fallback(
                request, req, intent_result, resolver, vendor_info, cache_service
            )

        # Step 5: ç²å–æ„åœ– ID
        intent_id = _get_intent_id(intent_result['intent_name'])

        # Step 6: å˜—è©¦æª¢ç´¢ SOPï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼‰- å›æ¸¬æ¨¡å¼å¯è·³é
        if not request.skip_sop:
            sop_items = await _retrieve_sop(request, intent_result)
            if sop_items:
                print(f"âœ… æ‰¾åˆ° {len(sop_items)} å€‹ SOP é …ç›®ï¼Œä½¿ç”¨ SOP æµç¨‹")
                return await _build_sop_response(
                    request, req, intent_result, sop_items, resolver, vendor_info, cache_service
                )
            print(f"â„¹ï¸  æ²’æœ‰æ‰¾åˆ° SOPï¼Œä½¿ç”¨çŸ¥è­˜åº«æª¢ç´¢")
        else:
            print(f"â„¹ï¸  [å›æ¸¬æ¨¡å¼] è·³é SOP æª¢ç´¢ï¼Œåƒ…ä½¿ç”¨çŸ¥è­˜åº«")

        # Step 7: æª¢ç´¢çŸ¥è­˜åº«ï¼ˆæ··åˆæ¨¡å¼ï¼šintent + å‘é‡ï¼‰
        knowledge_list = await _retrieve_knowledge(request, intent_id, intent_result)

        # Step 8: å¦‚æœçŸ¥è­˜åº«æ²’æœ‰çµæœï¼Œå˜—è©¦åƒæ•¸ç­”æ¡ˆæˆ– RAG fallback
        if not knowledge_list:
            print(f"âš ï¸  æ„åœ– '{intent_result['intent_name']}' (ID: {intent_id}) æ²’æœ‰é—œè¯çŸ¥è­˜ï¼Œå˜—è©¦åƒæ•¸ç­”æ¡ˆæˆ– RAG fallback...")
            return await _handle_no_knowledge_found(
                request, req, intent_result, resolver, cache_service, vendor_info
            )

        # Step 9: ä½¿ç”¨çŸ¥è­˜åº«çµæœæ§‹å»ºå„ªåŒ–å›æ‡‰
        return await _build_knowledge_response(
            request, req, intent_result, knowledge_list, resolver, vendor_info, cache_service
        )

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"è™•ç†èŠå¤©è«‹æ±‚å¤±æ•—: {str(e)}"
        )


def _get_intent_id(intent_name: str) -> int:
    """ç²å–æ„åœ– ID"""
    conn = psycopg2.connect(**get_db_config())
    cursor = conn.cursor()
    cursor.execute(
        "SELECT id FROM intents WHERE name = %s AND is_enabled = true",
        (intent_name,)
    )
    result = cursor.fetchone()
    intent_id = result[0] if result else None
    cursor.close()
    conn.close()

    if not intent_id:
        raise HTTPException(
            status_code=500,
            detail=f"è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°æ„åœ–: {intent_name}"
        )

    return intent_id


@router.get("/vendors/{vendor_id}/test")
async def test_vendor_config(vendor_id: int):
    """
    æ¸¬è©¦æ¥­è€…é…ç½®

    ç”¨æ–¼æª¢æŸ¥æ¥­è€…çš„åƒæ•¸æ˜¯å¦æ­£ç¢ºè¨­å®š
    """
    try:
        resolver = get_vendor_param_resolver()

        # ç²å–æ¥­è€…è³‡è¨Š
        vendor_info = resolver.get_vendor_info(vendor_id)
        if not vendor_info:
            raise HTTPException(status_code=404, detail="æ¥­è€…ä¸å­˜åœ¨")

        # ç²å–æ¥­è€…åƒæ•¸
        params = resolver.get_vendor_parameters(vendor_id)

        # æ¸¬è©¦æ¨¡æ¿è§£æ
        test_template = "ç¹³è²»æ—¥ç‚º {{payment_day}}ï¼Œé€¾æœŸè²» {{late_fee}}ã€‚"
        resolved = resolver.resolve_template(test_template, vendor_id)

        return {
            "vendor": vendor_info,
            "param_count": len(params),
            "parameters": params,
            "test_template": {
                "original": test_template,
                "resolved": resolved
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/reload")
async def reload_vendor_services():
    """
    é‡æ–°è¼‰å…¥å¤šæ¥­è€…æœå‹™

    ç”¨æ–¼æ„åœ–æˆ–çŸ¥è­˜æ›´æ–°å¾Œé‡æ–°è¼‰å…¥
    """
    try:
        global _vendor_param_resolver

        # æ¸…é™¤åƒæ•¸å¿«å–
        if _vendor_param_resolver:
            _vendor_param_resolver.clear_cache()

        return {
            "success": True,
            "message": "å¤šæ¥­è€…æœå‹™å·²é‡æ–°è¼‰å…¥",
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"é‡æ–°è¼‰å…¥å¤±æ•—: {str(e)}"
        )
