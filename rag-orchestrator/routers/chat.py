"""
èŠå¤© API è·¯ç”±
è™•ç†ä½¿ç”¨è€…å•é¡Œï¼Œæ•´åˆæ„åœ–åˆ†é¡ã€RAG æª¢ç´¢å’Œä¿¡å¿ƒåº¦è©•ä¼°

Phase 1: æ–°å¢å¤šæ¥­è€…æ”¯æ´ï¼ˆMulti-Vendor Chat APIï¼‰
"""
from __future__ import annotations  # å…è¨±é¡å‹æç¤ºçš„å‰å‘å¼•ç”¨

from fastapi import APIRouter, HTTPException, Request
from pydantic import BaseModel, Field, validator
from typing import Optional, List, Dict
from datetime import datetime
import time
import json
import os
import psycopg2
import psycopg2.extras
from services.db_utils import get_db_config
from services.embedding_utils import get_embedding_client

router = APIRouter()

# å¸¸é‡å®šç¾©
TARGET_USER_ROLES = ['tenant', 'landlord', 'property_manager', 'system_admin']
BUSINESS_MODES = ['b2c', 'b2b']


def _generate_config_version() -> str:
    """
    ç”Ÿæˆé…ç½®ç‰ˆæœ¬å­—ç¬¦ä¸²ï¼Œç”¨æ–¼ç·©å­˜éµçš„å€åˆ†

    åŸºæ–¼ç•¶å‰ LLM å„ªåŒ–å™¨é…ç½®ç”Ÿæˆç‰ˆæœ¬æ¨™è­˜
    æ ¼å¼: pm{perfect_match}_st{synthesis_threshold}
    ä¾‹å¦‚: pm90_st80 (perfect_match=0.90, synthesis_threshold=0.80)

    Returns:
        é…ç½®ç‰ˆæœ¬å­—ç¬¦ä¸²
    """
    perfect_match = float(os.getenv("PERFECT_MATCH_THRESHOLD", "0.90"))
    synthesis = float(os.getenv("SYNTHESIS_THRESHOLD", "0.80"))

    # è½‰æ›ç‚ºæ•´æ•¸ï¼ˆå»æ‰å°æ•¸é»ï¼‰
    pm_val = int(perfect_match * 100)
    st_val = int(synthesis * 100)

    return f"pm{pm_val}_st{st_val}"

# Phase 1: å¤šæ¥­è€…æœå‹™å¯¦ä¾‹ï¼ˆæ‡¶åŠ è¼‰ï¼‰
_vendor_knowledge_retriever = None
_vendor_param_resolver = None
_vendor_sop_retriever = None


def get_vendor_knowledge_retriever():
    """ç²å–æ¥­è€…çŸ¥è­˜æª¢ç´¢å™¨"""
    global _vendor_knowledge_retriever
    if _vendor_knowledge_retriever is None:
        from services.vendor_knowledge_retriever import VendorKnowledgeRetriever
        _vendor_knowledge_retriever = VendorKnowledgeRetriever()
    return _vendor_knowledge_retriever


def get_vendor_param_resolver():
    """ç²å–æ¥­è€…åƒæ•¸è§£æå™¨"""
    global _vendor_param_resolver
    if _vendor_param_resolver is None:
        from services.vendor_parameter_resolver import VendorParameterResolver
        _vendor_param_resolver = VendorParameterResolver()
    return _vendor_param_resolver


def get_vendor_sop_retriever():
    """ç²å–æ¥­è€… SOP æª¢ç´¢å™¨"""
    global _vendor_sop_retriever
    if _vendor_sop_retriever is None:
        from services.vendor_sop_retriever import VendorSOPRetriever
        _vendor_sop_retriever = VendorSOPRetriever()
    return _vendor_sop_retriever


def cache_response_and_return(cache_service, vendor_id: int, question: str, response, target_user: str = "tenant"):
    """
    ç·©å­˜éŸ¿æ‡‰ä¸¦è¿”å›ï¼ˆè¼”åŠ©å‡½æ•¸ï¼‰

    Args:
        cache_service: ç·©å­˜æœå‹™å¯¦ä¾‹
        vendor_id: æ¥­è€… ID
        question: ç”¨æˆ¶å•é¡Œ
        response: VendorChatResponse å¯¦ä¾‹
        target_user: ç›®æ¨™ç”¨æˆ¶è§’è‰²

    Returns:
        åŸå§‹ response
    """
    try:
        # ç”Ÿæˆé…ç½®ç‰ˆæœ¬
        config_version = _generate_config_version()

        # å°‡éŸ¿æ‡‰è½‰æ›ç‚ºå­—å…¸ä¸¦ç·©å­˜
        response_dict = response.dict()
        cache_service.cache_answer(
            vendor_id=vendor_id,
            question=question,
            answer_data=response_dict,
            target_user=target_user,
            config_version=config_version
        )
    except Exception as e:
        # ç·©å­˜å¤±æ•—ä¸æ‡‰å½±éŸ¿æ­£å¸¸éŸ¿æ‡‰
        print(f"âš ï¸  ç·©å­˜å­˜å„²å¤±æ•—: {e}")

    return response


# ==================== è¼”åŠ©å‡½æ•¸ï¼šSOP ç­”æ¡ˆæ ¼å¼åŒ– ====================

def _format_sop_answer(sop_items: list, group_name: str = None) -> str:
    """
    ç›´æ¥æ ¼å¼åŒ–SOPå…§å®¹ï¼Œä¸ç¶“éLLMé‡çµ„

    ä¿æŒåŸå§‹çš„ï¼š
    - item_nameï¼ˆæ¨™é¡Œï¼‰
    - contentï¼ˆå…§å®¹ï¼‰
    - é †åº

    Args:
        sop_items: SOPé …ç›®åˆ—è¡¨
        group_name: Groupåç¨±ï¼ˆå¯é¸ï¼‰

    Returns:
        æ ¼å¼åŒ–å¾Œçš„ç­”æ¡ˆå­—ä¸²
    """
    if not sop_items:
        return "æœªæ‰¾åˆ°ç›¸é—œçš„SOPè³‡æ–™ã€‚"

    # æ§‹å»ºç­”æ¡ˆ
    parts = []

    # å¦‚æœæœ‰group_nameï¼Œæ·»åŠ æ¨™é¡Œ
    if group_name:
        parts.append(f"ã€{group_name}ã€‘\n")

    for idx, sop in enumerate(sop_items, 1):
        item_name = sop.get('item_name', '')
        content = sop.get('content', '').strip()

        # è½‰ç¾© Markdown ç‰¹æ®Šå­—ç¬¦ï¼ˆé˜²æ­¢èª¤æ¸²æŸ“ï¼‰
        # ç‰¹åˆ¥è™•ç†æ³¢æµªè™Ÿï¼š1~15 ä¸æ‡‰è©²è¢«æ¸²æŸ“æˆåˆªé™¤ç·š
        content = content.replace('~', '\\~')
        item_name = item_name.replace('~', '\\~')

        # æ ¼å¼åŒ–æ¯æ¢SOPï¼ˆä¿æŒåŸå§‹æ¨™é¡Œå’Œå…§å®¹ï¼‰
        if len(sop_items) == 1:
            # åªæœ‰ä¸€æ¢ï¼Œä¸éœ€è¦ç·¨è™Ÿ
            parts.append(f"{item_name}\n{content}")
        else:
            # å¤šæ¢ï¼Œæ·»åŠ ç·¨è™Ÿæ–¹ä¾¿é–±è®€
            parts.append(f"{idx}. {item_name}\n{content}")

    # çµ„åˆç­”æ¡ˆ
    answer = "\n\n".join(parts)

    # æ·»åŠ å‹å¥½çš„çµå°¾
    answer += "\n\nå¦‚æœ‰ä»»ä½•ç–‘å•ï¼Œæ­¡è¿éš¨æ™‚è«®è©¢ï¼"

    return answer


# ==================== è¼”åŠ©å‡½æ•¸ï¼šç­”æ¡ˆæ¸…ç†èˆ‡æ¨¡æ¿æ›¿æ› ====================

def _clean_answer(answer: str, vendor_id: int, resolver) -> str:
    """
    æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰

    è™•ç†å…©ç¨®æƒ…æ³ï¼š
    1. æ¨¡æ¿è®Šæ•¸æ ¼å¼ï¼š{{service_hotline}} â†’ 02-2345-6789
    2. ç•°å¸¸æ ¼å¼ï¼š@vendorA, @vendor_name ç­‰ â†’ ç§»é™¤

    Args:
        answer: åŸå§‹ç­”æ¡ˆ
        vendor_id: æ¥­è€… ID
        resolver: åƒæ•¸è§£æå™¨

    Returns:
        æ¸…ç†å¾Œçš„ç­”æ¡ˆ
    """
    cleaned, _ = _clean_answer_with_tracking(answer, vendor_id, resolver)
    return cleaned


def _clean_answer_with_tracking(answer: str, vendor_id: int, resolver) -> tuple:
    """
    æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰ï¼ŒåŒæ™‚è¿½è¹¤ä½¿ç”¨çš„åƒæ•¸

    Args:
        answer: åŸå§‹ç­”æ¡ˆ
        vendor_id: æ¥­è€… ID
        resolver: åƒæ•¸è§£æå™¨

    Returns:
        (æ¸…ç†å¾Œçš„ç­”æ¡ˆ, ä½¿ç”¨çš„åƒæ•¸ key åˆ—è¡¨)
    """
    import re

    # 1. æ›¿æ›æ˜ç¢ºçš„æ¨¡æ¿è®Šæ•¸ {{xxx}} ä¸¦è¿½è¹¤ä½¿ç”¨çš„åƒæ•¸
    cleaned, used_params = resolver.resolve_template_with_tracking(answer, vendor_id, raise_on_missing=False)

    # 2. æ¸…ç†ç•°å¸¸æ ¼å¼ï¼ˆå·²åœç”¨ï¼Œå› ç‚ºæœƒèª¤åˆªçœŸå¯¦ LINE IDï¼‰
    # æ³¨æ„ï¼š@vendorA å¯èƒ½æ˜¯çœŸå¯¦çš„ LINE IDï¼Œä¸æ‡‰è©²ç§»é™¤
    # cleaned = re.sub(r'@vendor[A-Za-z0-9_]*', '', cleaned)  # â† å·²åœç”¨

    # 3. å¦‚æœä»æœ‰æœªæ›¿æ›çš„æ¨¡æ¿è®Šæ•¸ï¼Œè¨˜éŒ„è­¦å‘Š
    if '{{' in cleaned:
        remaining_vars = re.findall(r'\{\{(\w+)\}\}', cleaned)
        print(f"âš ï¸  è­¦å‘Šï¼šç­”æ¡ˆä¸­ä»æœ‰æœªæ›¿æ›çš„æ¨¡æ¿è®Šæ•¸: {remaining_vars}")

    return cleaned, used_params


def _remove_duplicate_question(answer: str, question: str) -> str:
    """
    ç§»é™¤ç­”æ¡ˆé–‹é ­é‡è¤‡çš„å•é¡Œ

    æœ‰æ™‚ LLM æœƒåœ¨ç­”æ¡ˆé–‹é ­é‡è¤‡ç”¨æˆ¶çš„å•é¡Œï¼Œé€™å€‹å‡½æ•¸æœƒæª¢æ¸¬ä¸¦ç§»é™¤é‡è¤‡çš„éƒ¨åˆ†ã€‚

    Args:
        answer: åŸå§‹ç­”æ¡ˆ
        question: ç”¨æˆ¶å•é¡Œ

    Returns:
        æ¸…ç†å¾Œçš„ç­”æ¡ˆ
    """
    if not answer or not question:
        return answer

    # ç§»é™¤å‰å¾Œç©ºç™½å¾Œæ¯”è¼ƒ
    answer_stripped = answer.strip()
    question_stripped = question.strip()

    # æª¢æŸ¥ç­”æ¡ˆæ˜¯å¦ä»¥å•é¡Œé–‹é ­ï¼ˆå…è¨±ä¸€äº›ç©ºç™½å·®ç•°ï¼‰
    if answer_stripped.startswith(question_stripped):
        # ç§»é™¤é‡è¤‡çš„å•é¡Œéƒ¨åˆ†
        remaining = answer_stripped[len(question_stripped):].strip()
        print(f"âœ‚ï¸  ç§»é™¤ç­”æ¡ˆä¸­é‡è¤‡çš„å•é¡Œ: {question_stripped[:50]}...")
        return remaining

    # æª¢æŸ¥æ˜¯å¦æœ‰æ›è¡Œç¬¦åˆ†éš”ï¼ˆä¾‹å¦‚ï¼šå•é¡Œ\n\nç­”æ¡ˆï¼‰
    lines = answer_stripped.split('\n')
    if lines and lines[0].strip() == question_stripped:
        # ç§»é™¤ç¬¬ä¸€è¡Œï¼ˆé‡è¤‡çš„å•é¡Œï¼‰
        remaining = '\n'.join(lines[1:]).strip()
        print(f"âœ‚ï¸  ç§»é™¤ç­”æ¡ˆé¦–è¡Œé‡è¤‡çš„å•é¡Œ: {question_stripped[:50]}...")
        return remaining

    # æ²’æœ‰æª¢æ¸¬åˆ°é‡è¤‡ï¼Œè¿”å›åŸç­”æ¡ˆ
    return answer


# ==================== è¼”åŠ©å‡½æ•¸ï¼šè¡¨å–®è½‰æ› ====================

def _convert_form_result_to_response(
    form_result: dict,
    request: VendorChatRequest
) -> VendorChatResponse:
    """
    å°‡è¡¨å–®è™•ç†çµæœè½‰æ›ç‚ºæ¨™æº– VendorChatResponse

    Args:
        form_result: FormManager è¿”å›çš„çµæœå­—å…¸
        request: åŸå§‹è«‹æ±‚

    Returns:
        VendorChatResponse å¯¦ä¾‹
    """
    from datetime import datetime

    return VendorChatResponse(
        answer=form_result.get('answer', ''),
        intent_name=form_result.get('intent_name', 'è¡¨å–®å¡«å¯«'),
        intent_type='form_filling',
        confidence=1.0,  # è¡¨å–®æµç¨‹å›ºå®šé«˜ç½®ä¿¡åº¦
        sources=None,
        source_count=0,
        vendor_id=request.vendor_id,
        mode=request.mode or 'b2c',
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat(),
        # è¡¨å–®å°ˆå±¬æ¬„ä½
        form_triggered=form_result.get('form_triggered', False),
        form_completed=form_result.get('form_completed', False),
        form_cancelled=form_result.get('form_cancelled', False),
        form_id=form_result.get('form_id'),
        current_field=form_result.get('current_field'),
        progress=form_result.get('progress'),
        allow_resume=form_result.get('allow_resume', False)
    )


# ==================== è¼”åŠ©å‡½æ•¸ï¼šæ¥­è€…é©—è­‰èˆ‡ç·©å­˜ ====================

def _validate_vendor(vendor_id: int, resolver) -> dict:
    """é©—è­‰æ¥­è€…ç‹€æ…‹"""
    vendor_info = resolver.get_vendor_info(vendor_id)

    if not vendor_info:
        raise HTTPException(
            status_code=404,
            detail=f"æ¥­è€…ä¸å­˜åœ¨: {vendor_id}"
        )

    if not vendor_info['is_active']:
        raise HTTPException(
            status_code=403,
            detail=f"æ¥­è€…æœªå•Ÿç”¨: {vendor_id}"
        )

    return vendor_info


def _check_cache(cache_service, vendor_id: int, question: str, target_user: str):
    """æª¢æŸ¥ç·©å­˜ï¼Œå¦‚æœå‘½ä¸­å‰‡è¿”å›ç·©å­˜çš„ç­”æ¡ˆ"""
    # ç”Ÿæˆé…ç½®ç‰ˆæœ¬
    config_version = _generate_config_version()

    cached_answer = cache_service.get_cached_answer(
        vendor_id=vendor_id,
        question=question,
        target_user=target_user,
        config_version=config_version
    )

    if cached_answer:
        print(f"âš¡ ç·©å­˜å‘½ä¸­ï¼ç›´æ¥è¿”å›ç­”æ¡ˆï¼ˆè·³é RAG è™•ç†ï¼‰- é…ç½®ç‰ˆæœ¬: {config_version}")
        return VendorChatResponse(**cached_answer)

    return None


#==================== è¼”åŠ©å‡½æ•¸ï¼šUnclear æ„åœ–è™•ç† ====================

async def _handle_unclear_with_rag_fallback(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    resolver,
    vendor_info: dict,
    cache_service
):
    """è™•ç† unclear æ„åœ–ï¼šRAG fallback + æ¸¬è©¦å ´æ™¯è¨˜éŒ„ + æ„åœ–å»ºè­°"""
    rag_engine = req.app.state.rag_engine

    # RAG æª¢ç´¢ï¼ˆä½¿ç”¨è¼ƒä½é–¾å€¼ï¼‰
    fallback_similarity_threshold = float(os.getenv("FALLBACK_SIMILARITY_THRESHOLD", "0.55"))
    rag_top_k = int(os.getenv("RAG_TOP_K", "5"))
    rag_results = await rag_engine.search(
        query=request.message,
        limit=rag_top_k,
        similarity_threshold=fallback_similarity_threshold,
        vendor_id=request.vendor_id,
        target_users=[request.target_user]  # âœ… æ·»åŠ  target_user éæ¿¾
    )

    # å¦‚æœ RAG æ‰¾åˆ°çµæœï¼Œå„ªåŒ–ä¸¦è¿”å›ç­”æ¡ˆ
    if rag_results:
        return await _build_rag_response(
            request, req, intent_result, rag_results,
            resolver, vendor_info, cache_service,
            confidence_level='medium',
            intent_name="unclear"
        )

    # å¦‚æœ RAG ä¹Ÿæ²’æ‰¾åˆ°ï¼Œè¨˜éŒ„å•é¡Œä¸¦è¿”å›å…œåº•å›æ‡‰
    await _record_unclear_question(request, req)

    params = resolver.get_vendor_parameters(request.vendor_id)

    # ä½¿ç”¨æ¨¡æ¿æ ¼å¼ä»¥ä¾¿è¿½è¹¤åƒæ•¸ä½¿ç”¨
    fallback_answer = "æˆ‘ç›®å‰æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ‚¨å•é¡Œçš„è³‡è¨Šï¼Œä½†æˆ‘å¯ä»¥å”åŠ©æ‚¨è½‰çµ¦å®¢æœè™•ç†ã€‚å¦‚éœ€ç«‹å³å”åŠ©ï¼Œè«‹æ’¥æ‰“å®¢æœå°ˆç·š {{service_hotline}}ã€‚è«‹å•æ‚¨æ–¹ä¾¿æä¾›æ›´è©³ç´°çš„å…§å®¹å—ï¼Ÿ"

    # æ¸…ç†ç­”æ¡ˆä¸¦è¿½è¹¤ä½¿ç”¨çš„åƒæ•¸
    final_answer, used_param_keys = _clean_answer_with_tracking(fallback_answer, request.vendor_id, resolver)

    # æ§‹å»ºèª¿è©¦è³‡è¨Šï¼ˆå¦‚æœè«‹æ±‚äº†ï¼‰
    debug_info = None
    if request.include_debug_info:
        debug_info = _build_debug_info(
            processing_path='unclear',
            intent_result=intent_result,
            llm_strategy='fallback',  # unclear å…œåº•å›æ‡‰
            vendor_params=params,
            used_param_keys=used_param_keys  # âœ… åªé¡¯ç¤ºå¯¦éš›è¢«æ³¨å…¥çš„åƒæ•¸
        )

    return VendorChatResponse(
        answer=final_answer,
        intent_name="unclear",
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=None,
        source_count=0,
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat(),
        debug_info=debug_info
    )


async def _record_unclear_question(request: VendorChatRequest, req: Request):
    """
    è¨˜éŒ„ unclear å•é¡Œåˆ°æ¸¬è©¦å ´æ™¯åº« + æ„åœ–å»ºè­°

    åŠŸèƒ½å¢å¼·ï¼ˆèªç¾©å»é‡ï¼‰ï¼š
    - ç›¸é—œåº¦éæ¿¾ï¼šrelevance_score >= 0.7
    - èªç¾©å»é‡ï¼šä½¿ç”¨ embedding æª¢æ¸¬ç›¸ä¼¼å•é¡Œï¼ˆsimilarity >= 0.80ï¼‰
    - ç·¨è¼¯è·é›¢ï¼šLevenshtein Distance <= 2ï¼ˆæ•¸æ“šåº«å±¤ï¼‰
    """
    # 1. ä½¿ç”¨æ„åœ–å»ºè­°å¼•æ“åˆ†æå•é¡Œç›¸é—œæ€§
    suggestion_engine = req.app.state.suggestion_engine
    analysis = suggestion_engine.analyze_unclear_question(
        question=request.message,
        vendor_id=request.vendor_id,
        user_id=request.user_id,
        conversation_context=None
    )

    # ç²å–ç›¸é—œåº¦è©•ä¼°çµæœ
    is_relevant = analysis.get('is_relevant', False)
    relevance_score = analysis.get('relevance_score', 0.0)
    should_record = analysis.get('should_record', False)

    # åªè¨˜éŒ„ç›¸é—œåº¦é«˜çš„å•é¡Œ (relevance_score >= 0.7)
    if not should_record:
        print(f"â­ï¸  è·³éè¨˜éŒ„ï¼šå•é¡Œç›¸é—œåº¦ä¸è¶³ (score: {relevance_score:.2f}, relevant: {is_relevant})")
        print(f"   å•é¡Œ: {request.message}")
        return

    # 2. ç”Ÿæˆå•é¡Œçš„ embeddingï¼ˆç”¨æ–¼èªç¾©å»é‡ï¼‰
    embedding_client = get_embedding_client()
    question_embedding = await embedding_client.get_embedding(request.message, verbose=False)

    if not question_embedding:
        print(f"âš ï¸  ç„¡æ³•ç”Ÿæˆå•é¡Œå‘é‡ï¼Œå›é€€åˆ°ç²¾ç¢ºåŒ¹é…æ¨¡å¼")
        # å¾ŒçºŒä»æœƒé€²è¡Œç²¾ç¢ºåŒ¹é…æª¢æŸ¥

    # 3. è¨˜éŒ„åˆ°æ¸¬è©¦å ´æ™¯åº«ï¼ˆç›¸é—œåº¦éæ¿¾ + èªç¾©å»é‡ï¼‰
    try:
        test_scenario_conn = psycopg2.connect(**get_db_config())
        test_scenario_cursor = test_scenario_conn.cursor(cursor_factory=psycopg2.extras.DictCursor)

        # 3a. ç²¾ç¢ºåŒ¹é…æª¢æŸ¥ï¼ˆå®Œå…¨ç›¸åŒçš„å•é¡Œï¼‰
        test_scenario_cursor.execute("""
            SELECT id, status FROM test_scenarios
            WHERE test_question = %s
              AND status IN ('pending_review', 'draft', 'approved')
              AND is_active = true
        """, (request.message,))
        exact_match = test_scenario_cursor.fetchone()

        if exact_match:
            scenario_id, existing_status = exact_match
            print(f"â­ï¸  è·³éè¨˜éŒ„ï¼šå®Œå…¨ç›¸åŒå•é¡Œå·²å­˜åœ¨ (Scenario ID: {scenario_id}, ç‹€æ…‹: {existing_status})")
            print(f"   å•é¡Œ: {request.message}")
            test_scenario_cursor.close()
            test_scenario_conn.close()
            return

        # 3b. èªç¾©ç›¸ä¼¼åº¦æª¢æŸ¥ï¼ˆä½¿ç”¨ embedding å‘é‡æœç´¢ï¼‰
        if question_embedding:
            vector_str = '[' + ','.join(map(str, question_embedding)) + ']'

            test_scenario_cursor.execute("""
                SELECT
                    id,
                    test_question,
                    status,
                    (1 - (question_embedding <=> %s::vector)) AS similarity
                FROM test_scenarios
                WHERE question_embedding IS NOT NULL
                  AND status IN ('pending_review', 'draft', 'approved')
                  AND is_active = true
                  AND test_question != %s
                  AND (1 - (question_embedding <=> %s::vector)) >= 0.80
                ORDER BY similarity DESC
                LIMIT 1
            """, (vector_str, request.message, vector_str))

            similar_match = test_scenario_cursor.fetchone()

            if similar_match:
                scenario_id = similar_match['id']
                similar_question = similar_match['test_question']
                similarity = similar_match['similarity']
                existing_status = similar_match['status']

                print(f"â­ï¸  è·³éè¨˜éŒ„ï¼šç›¸ä¼¼å•é¡Œå·²å­˜åœ¨ (Scenario ID: {scenario_id}, ç‹€æ…‹: {existing_status})")
                print(f"   åŸå•é¡Œ: {request.message}")
                print(f"   ç›¸ä¼¼å•é¡Œ: {similar_question}")
                print(f"   ç›¸ä¼¼åº¦: {similarity:.3f}")

                test_scenario_cursor.close()
                test_scenario_conn.close()
                return

        # 4. æ’å…¥æ–°çš„æ¸¬è©¦å ´æ™¯è¨˜éŒ„ï¼ˆå« embeddingï¼‰
        if question_embedding:
            vector_str = '[' + ','.join(map(str, question_embedding)) + ']'
            test_scenario_cursor.execute("""
                INSERT INTO test_scenarios (
                    test_question, status, source,
                    difficulty, priority, notes, test_purpose, created_by,
                    question_embedding
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s::vector)
                RETURNING id
            """, (
                request.message, 'pending_review', 'user_question',
                'hard', 80,
                f"ç”¨æˆ¶å•é¡Œæ„åœ–ä¸æ˜ç¢ºï¼ˆVendor {request.vendor_id}ï¼‰ï¼Œç›¸é—œåº¦: {relevance_score:.2f}",
                "è¿½è¹¤æ„åœ–è­˜åˆ¥ç¼ºå£ï¼Œæ”¹å–„åˆ†é¡å™¨",
                request.user_id or 'system',
                vector_str
            ))
        else:
            # ç„¡ embedding æ™‚ä»æ’å…¥è¨˜éŒ„ï¼ˆä½†ç„¡æ³•åšèªç¾©å»é‡ï¼‰
            test_scenario_cursor.execute("""
                INSERT INTO test_scenarios (
                    test_question, status, source,
                    difficulty, priority, notes, test_purpose, created_by
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                request.message, 'pending_review', 'user_question',
                'hard', 80,
                f"ç”¨æˆ¶å•é¡Œæ„åœ–ä¸æ˜ç¢ºï¼ˆVendor {request.vendor_id}ï¼‰ï¼Œç›¸é—œåº¦: {relevance_score:.2f}",
                "è¿½è¹¤æ„åœ–è­˜åˆ¥ç¼ºå£ï¼Œæ”¹å–„åˆ†é¡å™¨",
                request.user_id or 'system'
            ))

        scenario_id = test_scenario_cursor.fetchone()[0]
        test_scenario_conn.commit()

        embedding_status = "âœ… å«å‘é‡" if question_embedding else "âš ï¸  ç„¡å‘é‡"
        print(f"âœ… è¨˜éŒ„unclearå•é¡Œåˆ°æ¸¬è©¦å ´æ™¯åº« (Scenario ID: {scenario_id}, ç›¸é—œåº¦: {relevance_score:.2f}, {embedding_status})")

        test_scenario_cursor.close()
        test_scenario_conn.close()
    except Exception as e:
        print(f"âš ï¸ è¨˜éŒ„æ¸¬è©¦å ´æ™¯å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

    # 5. è¨˜éŒ„æ„åœ–å»ºè­°
    suggested_intent_id = suggestion_engine.record_suggestion(
        question=request.message,
        analysis=analysis,
        user_id=request.user_id
    )
    if suggested_intent_id:
        print(f"âœ… ç™¼ç¾æ–°æ„åœ–å»ºè­°: {analysis['suggested_intent']['name']} (ID: {suggested_intent_id})")


# ==================== è¼”åŠ©å‡½æ•¸ï¼šèª¿è©¦è³‡è¨Šæ§‹å»º ====================

def _build_debug_info(
    processing_path: str,
    intent_result: dict,
    llm_strategy: str = "none",
    sop_candidates: list = None,
    knowledge_candidates: list = None,
    synthesis_info: dict = None,
    vendor_params: dict = None,
    thresholds: dict = None,
    used_param_keys: list = None  # æ–°å¢ï¼šå¯¦éš›è¢«ä½¿ç”¨çš„åƒæ•¸ key åˆ—è¡¨
) -> DebugInfo:
    """æ§‹å»ºèª¿è©¦è³‡è¨Šå°è±¡"""
    # æ§‹å»ºæ„åœ–è©³æƒ…
    intent_details = IntentDetail(
        primary_intent=intent_result.get('intent_name', ''),
        primary_confidence=intent_result.get('confidence', 0.0),
        secondary_intents=intent_result.get('secondary_intents', []),
        all_intents_with_confidence=intent_result.get('all_intents_with_confidence', [])
    )

    # æ§‹å»º SOP å€™é¸åˆ—è¡¨
    sop_candidates_list = None
    if sop_candidates:
        sop_candidates_list = [
            CandidateSOP(**candidate) for candidate in sop_candidates
        ]

    # æ§‹å»ºçŸ¥è­˜åº«å€™é¸åˆ—è¡¨
    knowledge_candidates_list = None
    if knowledge_candidates:
        knowledge_candidates_list = []
        for k in knowledge_candidates:
            knowledge_candidates_list.append(CandidateKnowledge(
                id=k.get('id'),
                question_summary=k.get('question_summary', ''),
                scope=k.get('scope', ''),
                base_similarity=k.get('base_similarity', k.get('original_similarity', 0.0)),
                intent_boost=k.get('intent_boost', 1.0),
                intent_semantic_similarity=k.get('intent_semantic_similarity'),
                priority=k.get('priority'),
                priority_boost=k.get('priority_boost', 0.0),
                boosted_similarity=k.get('boosted_similarity', k.get('similarity', 0.0)),
                scope_weight=k.get('scope_weight', 0),
                intent_type=k.get('intent_type'),
                is_selected=k.get('is_selected', False)
            ))

    # æ§‹å»ºåˆæˆè³‡è¨Š
    synthesis_info_obj = None
    if synthesis_info:
        synthesis_info_obj = SynthesisInfo(**synthesis_info)

    # æ§‹å»ºæ¥­è€…åƒæ•¸åˆ—è¡¨ï¼ˆåªé¡¯ç¤ºå¯¦éš›è¢«æ³¨å…¥çš„åƒæ•¸ï¼‰
    vendor_params_injected = []
    if vendor_params:
        # å¦‚æœæœ‰æŒ‡å®š used_param_keysï¼Œåªé¡¯ç¤ºè¢«ä½¿ç”¨çš„åƒæ•¸
        if used_param_keys is not None:
            for key in used_param_keys:
                if key in vendor_params:
                    param = vendor_params[key]
                    if isinstance(param, dict) and param.get('value'):
                        vendor_params_injected.append(VendorParamInjected(
                            param_key=key,
                            display_name=param.get('display_name', key),
                            value=str(param.get('value', '')),
                            unit=param.get('unit')
                        ))
        else:
            # å¦‚æœæ²’æœ‰æŒ‡å®šï¼Œé¡¯ç¤ºæ‰€æœ‰æœ‰å€¼çš„åƒæ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            for key, param in vendor_params.items():
                if isinstance(param, dict) and param.get('value'):
                    vendor_params_injected.append(VendorParamInjected(
                        param_key=key,
                        display_name=param.get('display_name', key),
                        value=str(param.get('value', '')),
                        unit=param.get('unit')
                    ))

    # æ§‹å»ºé–¾å€¼è³‡è¨Š
    if thresholds is None:
        thresholds = {
            'sop_threshold': float(os.getenv('SOP_SIMILARITY_THRESHOLD', '0.75')),
            'knowledge_retrieval_threshold': float(os.getenv('KB_SIMILARITY_THRESHOLD', '0.55')),
            'high_quality_threshold': float(os.getenv('HIGH_QUALITY_THRESHOLD', '0.8'))
        }

    # æ§‹å»ºç³»çµ±é…ç½®ç‹€æ…‹
    system_config = {
        'llm_strategies': {
            'perfect_match': {
                'enabled': True,
                'threshold': float(os.getenv('PERFECT_MATCH_THRESHOLD', '0.90'))
            },
            'synthesis': {
                'enabled': os.getenv('ENABLE_ANSWER_SYNTHESIS', 'true').lower() == 'true',
                'threshold': float(os.getenv('SYNTHESIS_THRESHOLD', '0.80'))
            },
            'fast_path': {
                'enabled': True,  # é è¨­å•Ÿç”¨
                'threshold': float(os.getenv('FAST_PATH_THRESHOLD', '0.75'))
            },
            'template': {
                'enabled': True  # é è¨­å•Ÿç”¨
            },
            'llm': {
                'enabled': True  # ç¸½æ˜¯å•Ÿç”¨
            }
        },
        'processing_paths': {
            'sop': {'enabled': True, 'threshold': float(os.getenv('SOP_SIMILARITY_THRESHOLD', '0.75'))},
            'knowledge': {'enabled': True, 'threshold': float(os.getenv('KB_SIMILARITY_THRESHOLD', '0.55'))},
            'unclear': {'enabled': True},
            'param_answer': {'enabled': True},
            'no_knowledge_found': {'enabled': True}
        }
    }

    return DebugInfo(
        processing_path=processing_path,
        sop_candidates=sop_candidates_list,
        knowledge_candidates=knowledge_candidates_list,
        intent_details=intent_details,
        llm_strategy=llm_strategy,
        synthesis_info=synthesis_info_obj,
        vendor_params_injected=vendor_params_injected,
        thresholds=thresholds,
        system_config=system_config
    )


# ==================== è¼”åŠ©å‡½æ•¸ï¼šSOP æª¢ç´¢ ====================

async def _retrieve_sop(request: VendorChatRequest, intent_result: dict) -> list:
    """æª¢ç´¢ SOPï¼ˆSOP å„ªå…ˆæ–¼çŸ¥è­˜åº«ï¼‰- ä½¿ç”¨ Hybrid æ¨¡å¼ï¼ˆIntent + ç›¸ä¼¼åº¦ï¼‰"""
    from routers.chat_shared import retrieve_sop_hybrid

    # ä½¿ç”¨å…±ç”¨æ¨¡çµ„çš„ hybrid ç‰ˆæœ¬ï¼ˆintent + å‘é‡ç›¸ä¼¼åº¦éæ¿¾ï¼‰
    all_intent_ids = intent_result.get('intent_ids', [])
    sop_similarity_threshold = float(os.getenv("SOP_SIMILARITY_THRESHOLD", "0.75"))
    sop_items = await retrieve_sop_hybrid(
        vendor_id=request.vendor_id,
        intent_ids=all_intent_ids,
        query=request.message,  # â† å‚³å…¥å•é¡Œæ–‡æœ¬ç”¨æ–¼ç›¸ä¼¼åº¦è¨ˆç®—
        top_k=request.top_k,
        similarity_threshold=sop_similarity_threshold
    )

    return sop_items


async def _build_sop_response(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    sop_items: list,
    resolver,
    vendor_info: dict,
    cache_service
):
    """ä½¿ç”¨ SOP æ§‹å»ºå›æ‡‰ - ç›´æ¥è¿”å›åŸå§‹SOPï¼Œä¸ç¶“éLLMé‡çµ„"""

    # æå–group_nameï¼ˆGroupéš”é›¢å¾Œæ‰€æœ‰SOPéƒ½ä¾†è‡ªåŒä¸€å€‹Groupï¼‰
    group_name = None
    if sop_items and sop_items[0].get('group_name'):
        group_name = sop_items[0]['group_name']

    # ç›´æ¥æ ¼å¼åŒ–SOPå…§å®¹ï¼Œä¿æŒåŸå§‹æ¨™é¡Œå’Œå…§å®¹
    raw_answer = _format_sop_answer(sop_items, group_name)

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆè™•ç† {{service_hotline}} ç­‰åƒæ•¸ï¼‰ï¼ŒåŒæ™‚è¿½è¹¤ä½¿ç”¨çš„åƒæ•¸
    final_answer, used_param_keys = _clean_answer_with_tracking(raw_answer, request.vendor_id, resolver)

    # æ§‹å»ºä¾†æºåˆ—è¡¨
    sources = []
    if request.include_sources:
        sources = [KnowledgeSource(
            id=sop['id'],
            question_summary=sop['item_name'],
            answer=sop['content'],
            scope='vendor_sop'
        ) for sop in sop_items]

    # æ§‹å»ºèª¿è©¦è³‡è¨Šï¼ˆå¦‚æœè«‹æ±‚äº†ï¼‰
    debug_info = None
    if request.include_debug_info:
        # ç²å–æ¥­è€…åƒæ•¸
        vendor_params = resolver.get_vendor_parameters(request.vendor_id)

        # æ§‹å»º SOP å€™é¸åˆ—è¡¨
        sop_candidates_debug = []
        for sop in sop_items:
            similarity = sop.get('similarity', 1.0)
            sop_candidates_debug.append({
                'id': sop['id'],
                'item_name': sop['item_name'],
                'group_name': sop.get('group_name', ''),
                'base_similarity': similarity,
                'intent_boost': 1.0,  # SOP ä¸ä½¿ç”¨æ„åœ–åŠ æˆ
                'boosted_similarity': similarity,  # èˆ‡ base_similarity ç›¸åŒï¼ˆboost=1.0ï¼‰
                'is_selected': True  # SOP å…¨éƒ¨é¸å–
            })

        # æ§‹å»º SOP åˆæˆè³‡è¨Šï¼ˆå¤šå€‹ SOP é …ç›®çµ„åˆï¼‰
        synthesis_info_dict = None
        if len(sop_items) > 1:
            synthesis_info_dict = {
                'sources_count': len(sop_items),
                'sources_ids': [sop['id'] for sop in sop_items],
                'synthesis_reason': f'çµ„åˆ {len(sop_items)} å€‹ SOP é …ç›®ï¼ˆ{group_name}ï¼‰'
            }

        debug_info = _build_debug_info(
            processing_path='sop',
            intent_result=intent_result,
            llm_strategy='direct',  # SOP ç›´æ¥è¿”å›ï¼Œä¸ç¶“é LLM
            sop_candidates=sop_candidates_debug,
            synthesis_info=synthesis_info_dict,
            vendor_params=vendor_params,
            used_param_keys=used_param_keys  # âœ… åªé¡¯ç¤ºå¯¦éš›è¢«æ³¨å…¥çš„åƒæ•¸
        )

    response = VendorChatResponse(
        answer=final_answer,
        intent_name=intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=sources if request.include_sources else None,
        source_count=len(sop_items),
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat(),
        debug_info=debug_info
    )

    return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.target_user)


# ==================== è¼”åŠ©å‡½æ•¸ï¼šRAG å›æ‡‰æ§‹å»º ====================

async def _build_rag_response(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    rag_results: list,
    resolver,
    vendor_info: dict,
    cache_service,
    confidence_level: str = 'medium',
    intent_name: str = None
):
    """ä½¿ç”¨ RAG çµæœæ§‹å»ºå„ªåŒ–å›æ‡‰"""
    llm_optimizer = req.app.state.llm_answer_optimizer

    # ç²å–æ¥­è€…åƒæ•¸ï¼ˆä¿ç•™å®Œæ•´è³‡è¨ŠåŒ…å« display_name, unit ç­‰ï¼‰
    vendor_params = resolver.get_vendor_parameters(request.vendor_id)

    # æ ¹æ“š confidence_level è¨­å®š confidence_score
    confidence_score_map = {
        'high': 0.85,
        'medium': 0.70,
        'low': 0.55
    }
    confidence_score = confidence_score_map.get(confidence_level, 0.70)

    # LLM å„ªåŒ–ï¼ˆæ·»åŠ  confidence_score ä»¥ç¢ºä¿åƒæ•¸æ³¨å…¥ï¼‰
    optimization_result = llm_optimizer.optimize_answer(
        question=request.message,
        search_results=rag_results,
        confidence_level=confidence_level,
        confidence_score=confidence_score,  # æ ¹æ“š confidence_level è¨­å®šåˆ†æ•¸
        intent_info=intent_result,
        vendor_params=vendor_params,
        vendor_name=vendor_info['name'],
        vendor_info=vendor_info,  # å‚³å…¥å®Œæ•´æ¥­è€…è³‡è¨Š
        enable_synthesis_override=False if request.disable_answer_synthesis else None
    )

    # æ§‹å»ºä¾†æºåˆ—è¡¨
    sources = []
    if request.include_sources:
        sources = [KnowledgeSource(
            id=r['id'],
            question_summary=r['question_summary'],
            answer=r['content'],
            scope=r.get('scope', 'global'),  # âœ… ä½¿ç”¨å¯¦éš› scope
            vendor_id=r.get('vendor_id'),    # âœ… æ·»åŠ  vendor_id
            target_users=r.get('target_user')  # âœ… æ·»åŠ  target_users
        ) for r in rag_results]

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰ï¼ŒåŒæ™‚è¿½è¹¤ä½¿ç”¨çš„åƒæ•¸
    final_answer, used_param_keys = _clean_answer_with_tracking(optimization_result['optimized_answer'], request.vendor_id, resolver)

    # ç§»é™¤ç­”æ¡ˆä¸­é‡è¤‡çš„å•é¡Œï¼ˆLLM æœ‰æ™‚æœƒåœ¨ç­”æ¡ˆé–‹é ­é‡è¤‡å•é¡Œï¼‰
    final_answer = _remove_duplicate_question(final_answer, request.message)

    # æ§‹å»ºèª¿è©¦è³‡è¨Šï¼ˆå¦‚æœè«‹æ±‚äº†ï¼‰
    debug_info = None
    if request.include_debug_info:
        # æ¨™è¨˜å“ªäº›çŸ¥è­˜è¢«é¸å–äº†
        selected_ids = {r['id'] for r in rag_results[:optimization_result.get('sources_used', len(rag_results))]}
        knowledge_candidates_debug = []
        for r in rag_results:
            knowledge_candidates_debug.append({
                'id': r['id'],
                'question_summary': r.get('question_summary', ''),
                'scope': r.get('scope', 'global'),
                'base_similarity': r.get('similarity', 0.0),
                'intent_boost': 1.0,  # RAG fallback æ²’æœ‰ intent boost
                'boosted_similarity': r.get('similarity', 0.0),
                'scope_weight': 0,
                'intent_type': r.get('intent_type'),
                'priority': r.get('priority'),
                'is_selected': r['id'] in selected_ids
            })

        # æ§‹å»ºåˆæˆè³‡è¨Š
        synthesis_info_dict = None
        if optimization_result.get('synthesis_applied'):
            synthesis_info_dict = {
                'sources_count': len(rag_results),
                'sources_ids': [r['id'] for r in rag_results],
                'synthesis_reason': 'RAG fallback ä½¿ç”¨ç­”æ¡ˆåˆæˆ'
            }

        debug_info = _build_debug_info(
            processing_path='rag_fallback',
            intent_result=intent_result,
            llm_strategy=optimization_result.get('optimization_method', 'unknown'),
            knowledge_candidates=knowledge_candidates_debug,
            synthesis_info=synthesis_info_dict,
            vendor_params=vendor_params,
            used_param_keys=used_param_keys  # âœ… åªé¡¯ç¤ºå¯¦éš›è¢«æ³¨å…¥çš„åƒæ•¸
        )

    response = VendorChatResponse(
        answer=final_answer,
        intent_name=intent_name or intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=sources if request.include_sources else None,
        source_count=len(rag_results),
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat(),
        debug_info=debug_info
    )

    return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.target_user)


# ==================== è¼”åŠ©å‡½æ•¸ï¼šçŸ¥è­˜åº«æª¢ç´¢ ====================

async def _retrieve_knowledge(
    request: VendorChatRequest,
    intent_id: int,
    intent_result: dict
):
    """
    æª¢ç´¢çŸ¥è­˜åº«ï¼ˆæ··åˆæ¨¡å¼ï¼šintent + å‘é‡ç›¸ä¼¼åº¦ + èªç¾©åŒ¹é…ï¼‰

    âœ… é¸é …1å¯¦æ–½ï¼šçµ±ä¸€æª¢ç´¢è·¯å¾‘
    - é™ä½é–¾å€¼åˆ° 0.55ï¼ˆåŸ RAG fallback çš„é–¾å€¼ï¼‰
    - ä½¿ç”¨èªç¾©åŒ¹é…å‹•æ…‹è¨ˆç®— intent_boost
    - ä¸å†éœ€è¦ç¨ç«‹çš„ RAG fallback è·¯å¾‘
    """
    retriever = get_vendor_knowledge_retriever()
    all_intent_ids = intent_result.get('intent_ids', [intent_id])

    # âœ… é¸é …1ï¼šçµ±ä¸€é–¾å€¼ç‚º 0.55ï¼ˆæ¶µè“‹åŸ knowledge + rag_fallback ç¯„åœï¼‰
    # ç’°å¢ƒè®Šæ•¸å‘å¾Œå…¼å®¹ï¼Œä½†é»˜èªå€¼æ”¹ç‚º 0.55
    kb_similarity_threshold = float(os.getenv("KB_SIMILARITY_THRESHOLD", "0.55"))

    knowledge_list = await retriever.retrieve_knowledge_hybrid(
        query=request.message,
        intent_id=intent_id,
        vendor_id=request.vendor_id,
        top_k=request.top_k,
        similarity_threshold=kb_similarity_threshold,
        all_intent_ids=all_intent_ids,
        target_user=request.target_user,
        return_debug_info=request.include_debug_info
    )

    return knowledge_list


async def _handle_no_knowledge_found(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    resolver,
    cache_service,
    vendor_info: dict
):
    """
    è™•ç†æ‰¾ä¸åˆ°çŸ¥è­˜çš„æƒ…æ³ï¼šåƒæ•¸ç­”æ¡ˆ > å…œåº•å›æ‡‰

    âœ… é¸é …1å¯¦æ–½ï¼šç§»é™¤ç¨ç«‹çš„ RAG fallback è·¯å¾‘
    - Knowledge è·¯å¾‘å·²é™ä½é–¾å€¼åˆ° 0.55ï¼ˆæ¶µè“‹åŸ RAG fallback ç¯„åœï¼‰
    - ä½¿ç”¨èªç¾©åŒ¹é…ç¢ºä¿ç›¸é—œçŸ¥è­˜ä¸æœƒè¢«éºæ¼
    - ç°¡åŒ–æµç¨‹ï¼šåƒæ•¸ç­”æ¡ˆ â†’ å…œåº•å›æ‡‰
    """
    # Step 1: å„ªå…ˆæª¢æŸ¥æ˜¯å¦ç‚ºåƒæ•¸å‹å•é¡Œï¼ˆæ²’æœ‰çŸ¥è­˜åº«æ™‚çš„å‚™é¸æ–¹æ¡ˆï¼‰
    from routers.chat_shared import check_param_question
    param_category, param_answer = await check_param_question(
        vendor_config_service=req.app.state.vendor_config_service,
        question=request.message,
        vendor_id=request.vendor_id
    )

    if param_answer:
        print(f"   â„¹ï¸  çŸ¥è­˜åº«ç„¡çµæœï¼Œä½¿ç”¨åƒæ•¸å‹ç­”æ¡ˆï¼ˆcategory={param_category}ï¼‰")

        # æ§‹å»ºèª¿è©¦è³‡è¨Šï¼ˆå¦‚æœè«‹æ±‚äº†ï¼‰
        debug_info = None
        if request.include_debug_info:
            # ç²å–æ¥­è€…åƒæ•¸
            vendor_params = resolver.get_vendor_parameters(request.vendor_id)

            debug_info = _build_debug_info(
                processing_path='param_answer',
                intent_result=intent_result,
                llm_strategy='param_query',  # åƒæ•¸æŸ¥è©¢
                vendor_params=vendor_params
            )

        response = VendorChatResponse(
            answer=param_answer['answer'],
            intent_name="åƒæ•¸æŸ¥è©¢",
            intent_type="config_param",
            confidence=1.0,
            sources=[],
            source_count=0,
            vendor_id=request.vendor_id,
            mode=request.mode,
            timestamp=datetime.utcnow().isoformat() + "Z",
            video_url=None,
            debug_info=debug_info
        )
        return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.target_user)

    # âœ… é¸é …1ï¼šç§»é™¤ Step 2 (RAG fallback)
    # åŸå› ï¼šKnowledge è·¯å¾‘å·²é™ä½é–¾å€¼åˆ° 0.55 ä¸¦ä½¿ç”¨èªç¾©åŒ¹é…
    # ä¸å†éœ€è¦ç¨ç«‹çš„é™ç´šæª¢ç´¢è·¯å¾‘

    # Step 2: è¨˜éŒ„æ¸¬è©¦å ´æ™¯ä¸¦è¿”å›å…œåº•å›æ‡‰
    print(f"   âŒ çŸ¥è­˜åº«æ²’æœ‰æ‰¾åˆ°ç›¸é—œçŸ¥è­˜ï¼ˆé–¾å€¼: 0.55ï¼Œå·²å«èªç¾©åŒ¹é…ï¼‰")
    await _record_no_knowledge_scenario(request, intent_result, req)

    params = resolver.get_vendor_parameters(request.vendor_id)

    # ä½¿ç”¨æ¨¡æ¿æ ¼å¼ä»¥ä¾¿è¿½è¹¤åƒæ•¸ä½¿ç”¨
    fallback_answer = "æˆ‘ç›®å‰æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ‚¨å•é¡Œçš„è³‡è¨Šï¼Œä½†æˆ‘å¯ä»¥å”åŠ©æ‚¨è½‰çµ¦å®¢æœè™•ç†ã€‚å¦‚éœ€ç«‹å³å”åŠ©ï¼Œè«‹æ’¥æ‰“å®¢æœå°ˆç·š {{service_hotline}}ã€‚è«‹å•æ‚¨æ–¹ä¾¿æä¾›æ›´è©³ç´°çš„å…§å®¹å—ï¼Ÿ"

    # æ¸…ç†ç­”æ¡ˆä¸¦è¿½è¹¤ä½¿ç”¨çš„åƒæ•¸
    final_answer, used_param_keys = _clean_answer_with_tracking(fallback_answer, request.vendor_id, resolver)

    # æ§‹å»ºèª¿è©¦è³‡è¨Šï¼ˆå¦‚æœè«‹æ±‚äº†ï¼‰
    debug_info = None
    if request.include_debug_info:
        debug_info = _build_debug_info(
            processing_path='no_knowledge_found',
            intent_result=intent_result,
            llm_strategy='fallback',  # å…œåº•å›æ‡‰
            vendor_params=params,
            used_param_keys=used_param_keys  # âœ… åªé¡¯ç¤ºå¯¦éš›è¢«æ³¨å…¥çš„åƒæ•¸
        )

    return VendorChatResponse(
        answer=final_answer,
        intent_name=intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=None,
        source_count=0,
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat(),
        debug_info=debug_info
    )


async def _record_no_knowledge_scenario(request: VendorChatRequest, intent_result: dict, req: Request):
    """è¨˜éŒ„æ‰¾ä¸åˆ°çŸ¥è­˜çš„å ´æ™¯åˆ°æ¸¬è©¦åº« + æ„åœ–å»ºè­°"""
    # 1. è¨˜éŒ„åˆ°æ¸¬è©¦å ´æ™¯åº«
    try:
        test_scenario_conn = psycopg2.connect(**get_db_config())
        test_scenario_cursor = test_scenario_conn.cursor()

        test_scenario_cursor.execute(
            "SELECT id FROM test_scenarios WHERE test_question = %s AND status = 'pending_review'",
            (request.message,)
        )
        existing_scenario = test_scenario_cursor.fetchone()

        if not existing_scenario:
            test_scenario_cursor.execute("""
                INSERT INTO test_scenarios (
                    test_question, status, source,
                    difficulty, priority, notes, test_purpose, created_by
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                request.message,
                'pending_review', 'user_question', 'medium', 70,
                f"ç”¨æˆ¶çœŸå¯¦å•é¡Œï¼ˆVendor {request.vendor_id}ï¼‰ï¼Œæ„åœ–: {intent_result.get('intent_name', 'unknown')}ï¼Œç³»çµ±ç„¡æ³•æä¾›ç­”æ¡ˆ",
                "é©—è­‰çŸ¥è­˜åº«è¦†è“‹ç‡ï¼Œè¿½è¹¤ç”¨æˆ¶çœŸå¯¦éœ€æ±‚",
                request.user_id or 'system'
            ))
            scenario_id = test_scenario_cursor.fetchone()[0]
            test_scenario_conn.commit()
            print(f"âœ… è¨˜éŒ„åˆ°æ¸¬è©¦å ´æ™¯åº« (Scenario ID: {scenario_id})")

        test_scenario_cursor.close()
        test_scenario_conn.close()
    except Exception as e:
        print(f"âš ï¸ è¨˜éŒ„æ¸¬è©¦å ´æ™¯å¤±æ•—: {e}")

    # 2. ä½¿ç”¨æ„åœ–å»ºè­°å¼•æ“
    suggestion_engine = req.app.state.suggestion_engine
    analysis = suggestion_engine.analyze_unclear_question(
        question=request.message,
        vendor_id=request.vendor_id,
        user_id=request.user_id,
        conversation_context=None
    )

    if analysis.get('should_record'):
        suggested_intent_id = suggestion_engine.record_suggestion(
            question=request.message,
            analysis=analysis,
            user_id=request.user_id
        )
        if suggested_intent_id:
            print(f"âœ… ç™¼ç¾çŸ¥è­˜ç¼ºå£å»ºè­° (Vendor {request.vendor_id}): {analysis['suggested_intent']['name']} (å»ºè­°ID: {suggested_intent_id})")


async def _build_knowledge_response(
    request: VendorChatRequest,
    req: Request,
    intent_result: dict,
    knowledge_list: list,
    resolver,
    vendor_info: dict,
    cache_service
):
    """ä½¿ç”¨çŸ¥è­˜åº«çµæœæ§‹å»ºå„ªåŒ–å›æ‡‰"""
    llm_optimizer = req.app.state.llm_answer_optimizer
    confidence_evaluator = req.app.state.confidence_evaluator

    # â­ æ–°æ¶æ§‹ï¼šæª¢æŸ¥æœ€ä½³çŸ¥è­˜æ˜¯å¦é—œè¯è¡¨å–®
    if knowledge_list:
        print(f"ğŸ” [èª¿è©¦] knowledge_list[0] keys: {knowledge_list[0].keys()}")
        print(f"ğŸ” [èª¿è©¦] knowledge_list[0]['form_id']: {knowledge_list[0].get('form_id')}")

    if knowledge_list and knowledge_list[0].get('form_id'):
        best_knowledge = knowledge_list[0]
        form_id = best_knowledge['form_id']

        # ç¢ºä¿æœ‰ session_id å’Œ user_idï¼ˆè¡¨å–®å¿…é ˆï¼‰
        if not request.session_id or not request.user_id:
            print(f"âš ï¸  çŸ¥è­˜ {best_knowledge['id']} é—œè¯è¡¨å–® {form_id}ï¼Œä½†ç¼ºå°‘ session_id æˆ– user_idï¼Œè·³éè¡¨å–®è§¸ç™¼")
        else:
            print(f"ğŸ“ [è¡¨å–®è§¸ç™¼] çŸ¥è­˜ {best_knowledge['id']} é—œè¯è¡¨å–® {form_id}ï¼Œå•Ÿå‹•è¡¨å–®æµç¨‹")

            # ä½¿ç”¨çŸ¥è­˜çš„ form_intro æˆ– answer ä½œç‚ºå¼•å°èª
            intro_message = best_knowledge.get('form_intro') or best_knowledge.get('answer', '')

            # èª¿ç”¨ FormManager è§¸ç™¼è¡¨å–®
            form_manager = req.app.state.form_manager
            form_result = await form_manager.trigger_form_by_knowledge(
                knowledge_id=best_knowledge['id'],
                form_id=form_id,
                intro_message=intro_message,
                session_id=request.session_id,
                user_id=request.user_id,
                vendor_id=request.vendor_id,
                trigger_question=request.message
            )

            # è½‰æ›ç‚º VendorChatResponse ä¸¦è¿”å›
            return _convert_form_result_to_response(form_result, request)

    # ç²å–æ¥­è€…åƒæ•¸ï¼ˆä¿ç•™å®Œæ•´è³‡è¨ŠåŒ…å« display_name, unit ç­‰ï¼‰
    vendor_params = resolver.get_vendor_parameters(request.vendor_id)

    # âœ… é«˜è³ªé‡éæ¿¾ï¼šåªä¿ç•™åŠ æˆå¾Œç›¸ä¼¼åº¦ >= 0.8 çš„çŸ¥è­˜ç”¨æ–¼ç­”æ¡ˆç”Ÿæˆ
    # æ³¨æ„ï¼šknowledge['similarity'] å·²ç¶“æ˜¯åŠ æˆå¾Œç›¸ä¼¼åº¦ï¼ˆè¦‹ vendor_knowledge_retriever.py:455ï¼‰
    high_quality_threshold = float(os.getenv("HIGH_QUALITY_THRESHOLD", "0.8"))
    filtered_knowledge_list = [k for k in knowledge_list if k.get('similarity', 0) >= high_quality_threshold]

    if len(filtered_knowledge_list) < len(knowledge_list):
        print(f"ğŸ” [é«˜è³ªé‡éæ¿¾] åŸå§‹: {len(knowledge_list)} å€‹å€™é¸çŸ¥è­˜, éæ¿¾å¾Œ: {len(filtered_knowledge_list)} å€‹ (é–¾å€¼: {high_quality_threshold})")
        for k in knowledge_list:
            status = "âœ…" if k.get('similarity', 0) >= high_quality_threshold else "âŒ"
            print(f"   {status} ID {k['id']}: similarity={k.get('similarity', 0):.3f}")

    # å¦‚æœéæ¿¾å¾Œæ²’æœ‰é«˜è³ªé‡çŸ¥è­˜ï¼Œè¿”å›æ‰¾ä¸åˆ°çŸ¥è­˜çš„éŸ¿æ‡‰
    if not filtered_knowledge_list:
        print(f"âš ï¸  æ‰€æœ‰å€™é¸çŸ¥è­˜çš„ç›¸ä¼¼åº¦éƒ½ä½æ–¼é«˜è³ªé‡é–¾å€¼ {high_quality_threshold}ï¼Œå˜—è©¦åƒæ•¸ç­”æ¡ˆæˆ–å…œåº•å›æ‡‰...")
        return await _handle_no_knowledge_found(
            request, req, intent_result, resolver, cache_service, vendor_info
        )

    # æº–å‚™æœå°‹çµæœæ ¼å¼ï¼ˆä½¿ç”¨éæ¿¾å¾Œçš„é«˜è³ªé‡çŸ¥è­˜ï¼‰
    search_results = [{
        'id': k['id'],
        'question_summary': k['question_summary'],
        'content': k['answer'],
        'similarity': k.get('similarity', 0.9),  # ä½¿ç”¨å¯¦éš›ç›¸ä¼¼åº¦ï¼Œæ²’æœ‰å‰‡ç”¨é è¨­å€¼
        'keywords': k.get('keywords', [])        # æ·»åŠ  keywords ä¾›ä¿¡å¿ƒåº¦è©•ä¼°
    } for k in filtered_knowledge_list]

    # ä½¿ç”¨ ConfidenceEvaluator è©•ä¼°ä¿¡å¿ƒåº¦ï¼ˆèˆ‡ /v1/chat/stream çµ±ä¸€ï¼‰
    evaluation = confidence_evaluator.evaluate(
        search_results=search_results,
        question_keywords=intent_result.get('keywords', [])
    )

    confidence_level = evaluation['confidence_level']
    confidence_score = evaluation['confidence_score']

    print(f"ğŸ“Š [çŸ¥è­˜åº«ä¿¡å¿ƒåº¦è©•ä¼°] level={confidence_level}, score={confidence_score:.3f}, decision={evaluation['decision']}")

    # LLM å„ªåŒ–ï¼ˆä½¿ç”¨è©•ä¼°å¾Œçš„ä¿¡å¿ƒåº¦ï¼‰
    optimization_result = llm_optimizer.optimize_answer(
        question=request.message,
        search_results=search_results,
        confidence_level=confidence_level,
        confidence_score=confidence_score,  # ä½¿ç”¨ ConfidenceEvaluator è¨ˆç®—çš„åˆ†æ•¸
        intent_info=intent_result,
        vendor_params=vendor_params,
        vendor_name=vendor_info['name'],
        vendor_info=vendor_info,  # å‚³å…¥å®Œæ•´æ¥­è€…è³‡è¨Š
        enable_synthesis_override=False if request.disable_answer_synthesis else None
    )

    # æ§‹å»ºä¾†æºåˆ—è¡¨
    sources = []
    if request.include_sources:
        sources = [KnowledgeSource(
            id=k['id'],
            question_summary=k['question_summary'],
            answer=k['answer'],
            scope=k['scope'],
            vendor_id=k.get('vendor_id'),
            target_users=k.get('target_user')
        ) for k in knowledge_list]

    # æå–å½±ç‰‡è³‡è¨Šï¼ˆå¾ç¬¬ä¸€å€‹çŸ¥è­˜é …ç›®ï¼‰
    video_url = None
    video_file_size = None
    video_duration = None
    video_format = None
    if knowledge_list:
        first_knowledge = knowledge_list[0]
        video_url = first_knowledge.get('video_url')
        video_file_size = first_knowledge.get('video_file_size')
        video_duration = first_knowledge.get('video_duration')
        video_format = first_knowledge.get('video_format')

    # æ¸…ç†ç­”æ¡ˆä¸¦æ›¿æ›æ¨¡æ¿è®Šæ•¸ï¼ˆå…œåº•ä¿è­·ï¼‰ï¼ŒåŒæ™‚è¿½è¹¤ä½¿ç”¨çš„åƒæ•¸
    final_answer, used_param_keys = _clean_answer_with_tracking(optimization_result['optimized_answer'], request.vendor_id, resolver)

    # ç§»é™¤ç­”æ¡ˆä¸­é‡è¤‡çš„å•é¡Œï¼ˆLLM æœ‰æ™‚æœƒåœ¨ç­”æ¡ˆé–‹é ­é‡è¤‡å•é¡Œï¼‰
    final_answer = _remove_duplicate_question(final_answer, request.message)

    # æ§‹å»ºèª¿è©¦è³‡è¨Šï¼ˆå¦‚æœè«‹æ±‚äº†ï¼‰
    debug_info = None
    if request.include_debug_info:
        # æ¨™è¨˜å“ªäº›çŸ¥è­˜è¢«é¸å–äº†ï¼ˆä½¿ç”¨éæ¿¾å¾Œçš„é«˜è³ªé‡åˆ—è¡¨ï¼‰
        selected_ids = {k['id'] for k in filtered_knowledge_list[:optimization_result.get('sources_used', len(filtered_knowledge_list))]}
        knowledge_candidates_debug = []
        # é¡¯ç¤ºæ‰€æœ‰å€™é¸çŸ¥è­˜ï¼Œä½†åªæ¨™è¨˜é«˜è³ªé‡çš„ç‚ºè¢«é¸å–
        for k in knowledge_list:
            knowledge_candidates_debug.append({
                'id': k['id'],
                'question_summary': k.get('question_summary', ''),
                'scope': k.get('scope', ''),
                'base_similarity': k.get('original_similarity', k.get('similarity', 0.0)),
                'intent_boost': k.get('intent_boost', 1.0),
                'intent_semantic_similarity': k.get('intent_semantic_similarity'),
                'boosted_similarity': k.get('similarity', 0.0),
                'scope_weight': k.get('scope_weight', 0),
                'intent_type': k.get('intent_type'),
                'priority': k.get('priority'),
                'is_selected': k['id'] in selected_ids
            })

        # æ§‹å»ºåˆæˆè³‡è¨Šï¼ˆä½¿ç”¨éæ¿¾å¾Œçš„é«˜è³ªé‡åˆ—è¡¨ï¼‰
        synthesis_info_dict = None
        if optimization_result.get('synthesis_applied'):
            synthesis_info_dict = {
                'sources_count': len(filtered_knowledge_list),
                'sources_ids': [k['id'] for k in filtered_knowledge_list],
                'synthesis_reason': f'å¤šå€‹é«˜å“è³ªçµæœï¼ˆ>= {high_quality_threshold}ï¼‰ï¼Œä½¿ç”¨ç­”æ¡ˆåˆæˆ'
            }

        debug_info = _build_debug_info(
            processing_path='knowledge',
            intent_result=intent_result,
            llm_strategy=optimization_result.get('optimization_method', 'unknown'),
            knowledge_candidates=knowledge_candidates_debug,
            synthesis_info=synthesis_info_dict,
            vendor_params=vendor_params,
            used_param_keys=used_param_keys  # âœ… åªé¡¯ç¤ºå¯¦éš›è¢«æ³¨å…¥çš„åƒæ•¸
        )

    response = VendorChatResponse(
        answer=final_answer,
        intent_name=intent_result['intent_name'],
        intent_type=intent_result.get('intent_type'),
        confidence=intent_result['confidence'],
        all_intents=intent_result.get('all_intents', []),
        secondary_intents=intent_result.get('secondary_intents', []),
        intent_ids=intent_result.get('intent_ids', []),
        sources=sources if request.include_sources else None,
        source_count=len(knowledge_list),
        vendor_id=request.vendor_id,
        mode=request.mode,
        session_id=request.session_id,
        timestamp=datetime.utcnow().isoformat(),
        video_url=video_url,
        video_file_size=video_file_size,
        video_duration=video_duration,
        video_format=video_format,
        debug_info=debug_info
    )

    return cache_response_and_return(cache_service, request.vendor_id, request.message, response, request.target_user)


# ========================================
# /api/v1/chat ç«¯é»å·²æ–¼ 2025-10-21 ç§»é™¤
# ========================================
#
# ç§»é™¤åŸå› ï¼šåŠŸèƒ½å·²ç”±æ›´å¼·å¤§çš„ç«¯é»æ›¿ä»£
#
# æ›¿ä»£æ–¹æ¡ˆï¼š
# 1. /api/v1/message - å¤šæ¥­è€…é€šç”¨ç«¯é»
#    - æ”¯æŒ SOP æ•´åˆ
#    - æ”¯æŒæ¥­è€…åƒæ•¸é…ç½®
#    - æ”¯æŒå¤š Intent æª¢ç´¢
#
# 2. /api/v1/chat/stream - æµå¼èŠå¤©ç«¯é»
#    - æä¾›å³æ™‚åé¥‹
#    - æ›´å¥½çš„ç”¨æˆ¶é«”é©—
#
# è©³è¦‹ï¼š
# - docs/api/CHAT_ENDPOINT_REMOVAL_AUDIT.md (ç›¤æŸ¥å ±å‘Š)
# - docs/api/CHAT_API_MIGRATION_GUIDE.md (é·ç§»æŒ‡å—)
#
# å·²ç§»é™¤çš„é …ç›®ï¼š
# - class ChatRequest
# - class ChatResponse
# - POST /chat ç«¯é»å‡½æ•¸
#
# ========================================


@router.get("/conversations")
async def get_conversations(
    req: Request,
    limit: int = 20,
    offset: int = 0,
    user_id: Optional[str] = None,
    intent_type: Optional[str] = None
):
    """
    å–å¾—å°è©±è¨˜éŒ„åˆ—è¡¨
    """
    try:
        async with req.app.state.db_pool.acquire() as conn:
            query = """
                SELECT
                    id,
                    user_id,
                    question,
                    intent_type,
                    confidence_score,
                    final_answer,
                    user_rating,
                    escalated_to_human,
                    created_at
                FROM conversation_logs
                WHERE ($1::text IS NULL OR user_id = $1)
                  AND ($2::text IS NULL OR intent_type = $2)
                ORDER BY created_at DESC
                LIMIT $3 OFFSET $4
            """

            results = await conn.fetch(query, user_id, intent_type, limit, offset)

        return {
            "conversations": [dict(row) for row in results],
            "limit": limit,
            "offset": offset
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"å–å¾—å°è©±è¨˜éŒ„å¤±æ•—: {str(e)}"
        )


@router.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: int, req: Request):
    """
    å–å¾—ç‰¹å®šå°è©±çš„è©³ç´°è³‡è¨Š
    """
    try:
        async with req.app.state.db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT *
                FROM conversation_logs
                WHERE id = $1
            """, conversation_id)

            if not row:
                raise HTTPException(status_code=404, detail="å°è©±è¨˜éŒ„ä¸å­˜åœ¨")

            return dict(row)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"å–å¾—å°è©±è©³æƒ…å¤±æ•—: {str(e)}"
        )


class FeedbackRequest(BaseModel):
    """åé¥‹è«‹æ±‚"""
    rating: int = Field(..., ge=1, le=5, description="è©•åˆ† 1-5")
    feedback: Optional[str] = Field(None, max_length=1000, description="åé¥‹å…§å®¹")


@router.post("/conversations/{conversation_id}/feedback")
async def submit_feedback(
    conversation_id: int,
    feedback: FeedbackRequest,
    req: Request
):
    """
    æäº¤å°è©±åé¥‹
    """
    try:
        async with req.app.state.db_pool.acquire() as conn:
            result = await conn.execute("""
                UPDATE conversation_logs
                SET user_rating = $1,
                    user_feedback = $2
                WHERE id = $3
            """, feedback.rating, feedback.feedback, conversation_id)

            if result == "UPDATE 0":
                raise HTTPException(status_code=404, detail="å°è©±è¨˜éŒ„ä¸å­˜åœ¨")

            return {
                "message": "åé¥‹æäº¤æˆåŠŸ",
                "conversation_id": conversation_id
            }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"æäº¤åé¥‹å¤±æ•—: {str(e)}"
        )


# ========================================
# Phase 1: å¤šæ¥­è€…èŠå¤© API
# ========================================

class VendorChatRequest(BaseModel):
    """å¤šæ¥­è€…èŠå¤©è«‹æ±‚"""
    message: str = Field(..., description="ä½¿ç”¨è€…è¨Šæ¯", min_length=1, max_length=2000)
    vendor_id: int = Field(..., description="æ¥­è€… ID", ge=1)

    # âœ… æ–°æ¬„ä½ï¼ˆæ¨è–¦ä½¿ç”¨ï¼‰
    target_user: Optional[str] = Field(
        None,
        description="ç›®æ¨™ç”¨æˆ¶è§’è‰²ï¼štenant(ç§Ÿå®¢), landlord(æˆ¿æ±), property_manager(ç‰©ç®¡), system_admin(ç³»çµ±ç®¡ç†)"
    )
    mode: Optional[str] = Field(
        'b2c',
        description="æ¥­å‹™æ¨¡å¼ï¼šb2c(çµ‚ç«¯ç”¨æˆ¶), b2b(æ¥­è€…å“¡å·¥)"
    )

    # âš ï¸ èˆŠæ¬„ä½ï¼ˆå‘å¾Œå…¼å®¹ï¼Œå·²å»¢æ£„ï¼‰
    user_role: Optional[str] = Field(
        None,
        description="[å·²å»¢æ£„] è«‹ä½¿ç”¨ target_user æ›¿ä»£ã€‚èˆŠå€¼ï¼šcustomer æˆ– staff"
    )

    session_id: Optional[str] = Field(None, description="æœƒè©± IDï¼ˆç”¨æ–¼è¿½è¹¤ï¼‰")
    user_id: Optional[str] = Field(None, description="ä½¿ç”¨è€… IDï¼ˆç§Ÿå®¢ ID æˆ–å®¢æœ IDï¼‰")
    top_k: int = Field(5, description="è¿”å›çŸ¥è­˜æ•¸é‡", ge=1, le=10)
    include_sources: bool = Field(True, description="æ˜¯å¦åŒ…å«çŸ¥è­˜ä¾†æº")
    include_debug_info: bool = Field(False, description="æ˜¯å¦åŒ…å«èª¿è©¦è³‡è¨Šï¼ˆè™•ç†æµç¨‹è©³æƒ…ï¼‰")
    disable_answer_synthesis: bool = Field(False, description="ç¦ç”¨ç­”æ¡ˆåˆæˆï¼ˆå›æ¸¬æ¨¡å¼å°ˆç”¨ï¼‰")
    skip_sop: bool = Field(False, description="è·³é SOP æª¢ç´¢ï¼Œåƒ…æª¢ç´¢çŸ¥è­˜åº«ï¼ˆå›æ¸¬æ¨¡å¼å°ˆç”¨ï¼‰")

    @validator('target_user', always=True)
    def migrate_user_role(cls, v, values):
        """è‡ªå‹•å¾èˆŠæ¬„ä½é·ç§»åˆ°æ–°æ¬„ä½"""
        if v:
            # å·²æä¾›æ–°æ¬„ä½ï¼Œé©—è­‰ä¸¦è¿”å›
            if v not in TARGET_USER_ROLES:
                raise ValueError(f"target_user å¿…é ˆæ˜¯ {TARGET_USER_ROLES} ä¹‹ä¸€ï¼Œç•¶å‰å€¼ï¼š{v}")
            return v

        # å‘å¾Œå…¼å®¹ï¼šå¾èˆŠæ¬„ä½è½‰æ›
        old_user_role = values.get('user_role')
        mode = values.get('mode', 'b2c')

        if old_user_role:
            # èˆŠå€¼è½‰æ›é‚è¼¯
            if old_user_role == 'staff':
                return 'property_manager'  # B2B é»˜èªç‚ºç‰©ç®¡
            elif old_user_role == 'customer':
                return 'tenant'  # B2C é»˜èªç‚ºç§Ÿå®¢
            elif old_user_role in TARGET_USER_ROLES:
                return old_user_role  # å·²ç¶“æ˜¯æ–°æ ¼å¼

        # é»˜èªå€¼ï¼šæ ¹æ“š mode åˆ¤æ–·
        if mode in ['b2b', 'customer_service']:
            return 'property_manager'
        else:
            return 'tenant'

    @validator('mode')
    def normalize_mode(cls, v):
        """æ¨™æº–åŒ–æ¥­å‹™æ¨¡å¼"""
        if v == 'tenant':  # èˆŠå€¼
            return 'b2c'
        elif v == 'customer_service':  # èˆŠå€¼
            return 'b2b'
        elif v in BUSINESS_MODES:
            return v
        else:
            return 'b2c'  # é»˜èª B2C


class KnowledgeSource(BaseModel):
    """çŸ¥è­˜ä¾†æº"""
    id: int
    question_summary: str
    answer: str
    scope: str = Field(..., description="çŸ¥è­˜ç¯„åœï¼šglobal(å…¨åŸŸ), vendor(æ¥­è€…å°ˆå±¬), customized(å®¢è£½åŒ–)")
    vendor_id: Optional[int] = Field(None, description="æ¥­è€… IDï¼ˆå¦‚ç‚ºæ¥­è€…å°ˆå±¬çŸ¥è­˜ï¼‰")
    target_users: Optional[List[str]] = Field(None, description="ç›®æ¨™ç”¨æˆ¶åˆ—è¡¨")


# ========================================
# èª¿è©¦è³‡è¨Šæ¨¡å‹ï¼ˆDebug Info Modelsï¼‰
# ========================================

class CandidateKnowledge(BaseModel):
    """å€™é¸çŸ¥è­˜é …ç›®ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰"""
    id: int
    question_summary: str
    scope: str
    base_similarity: float = Field(..., description="åŸºç¤å‘é‡ç›¸ä¼¼åº¦")
    intent_boost: float = Field(..., description="æ„åœ–åŠ æˆä¿‚æ•¸")
    intent_semantic_similarity: Optional[float] = Field(None, description="æ„åœ–èªç¾©ç›¸ä¼¼åº¦")
    priority: Optional[int] = Field(None, description="äººå·¥å„ªå…ˆç´š")
    priority_boost: float = Field(0.0, description="å„ªå…ˆç´šåŠ æˆå€¼")
    boosted_similarity: float = Field(..., description="åŠ æˆå¾Œç›¸ä¼¼åº¦")
    scope_weight: int = Field(..., description="Scope æ¬Šé‡")
    intent_type: Optional[str] = Field(None, description="æ„åœ–é¡å‹ï¼šprimary/secondary")
    is_selected: bool = Field(..., description="æ˜¯å¦è¢«é¸å–")


class CandidateSOP(BaseModel):
    """å€™é¸ SOP é …ç›®ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰"""
    id: int
    item_name: str
    group_name: Optional[str] = None
    base_similarity: float = Field(..., description="åŸºç¤å‘é‡ç›¸ä¼¼åº¦")
    intent_boost: float = Field(..., description="æ„åœ–åŠ æˆä¿‚æ•¸")
    boosted_similarity: float = Field(..., description="åŠ æˆå¾Œç›¸ä¼¼åº¦")
    is_selected: bool = Field(..., description="æ˜¯å¦è¢«é¸å–")


class IntentDetail(BaseModel):
    """æ„åœ–åˆ†æè©³æƒ…ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰"""
    primary_intent: str
    primary_confidence: float
    secondary_intents: Optional[List[str]] = None
    all_intents_with_confidence: Optional[List[Dict]] = None


class SynthesisInfo(BaseModel):
    """ç­”æ¡ˆåˆæˆè³‡è¨Šï¼ˆç”¨æ–¼èª¿è©¦ï¼‰"""
    sources_count: int
    sources_ids: List[int]
    synthesis_reason: str


class VendorParamInjected(BaseModel):
    """å·²æ³¨å…¥çš„æ¥­è€…åƒæ•¸ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰"""
    param_key: str
    display_name: str
    value: str
    unit: Optional[str] = None


class DebugInfo(BaseModel):
    """èª¿è©¦è³‡è¨Šï¼ˆå®Œæ•´è™•ç†æµç¨‹ç´°ç¯€ï¼‰"""
    processing_path: str = Field(..., description="è™•ç†è·¯å¾‘ï¼šsop | knowledge | fallback")

    # SOP æª¢ç´¢çµæœ
    sop_candidates: Optional[List[CandidateSOP]] = Field(None, description="SOP å€™é¸é …ç›®åˆ—è¡¨")

    # çŸ¥è­˜åº«æª¢ç´¢çµæœ
    knowledge_candidates: Optional[List[CandidateKnowledge]] = Field(None, description="çŸ¥è­˜åº«å€™é¸é …ç›®åˆ—è¡¨")

    # æ„åœ–åˆ†é¡è©³æƒ…
    intent_details: IntentDetail = Field(..., description="æ„åœ–åˆ†æè©³æƒ…")

    # LLM å„ªåŒ–ç­–ç•¥
    llm_strategy: str = Field(..., description="LLM å„ªåŒ–ç­–ç•¥ï¼šperfect_match | synthesis | fast_path | template | full_optimization")

    # ç­”æ¡ˆåˆæˆè³‡è¨Š
    synthesis_info: Optional[SynthesisInfo] = Field(None, description="ç­”æ¡ˆåˆæˆè³‡è¨Šï¼ˆå¦‚æœæœ‰ï¼‰")

    # æ¥­è€…åƒæ•¸æ³¨å…¥
    vendor_params_injected: List[VendorParamInjected] = Field(default_factory=list, description="å·²æ³¨å…¥çš„æ¥­è€…åƒæ•¸")

    # ç›¸ä¼¼åº¦é–¾å€¼è³‡è¨Š
    thresholds: Dict = Field(default_factory=dict, description="ç›¸ä¼¼åº¦é–¾å€¼é…ç½®")

    # ç³»çµ±é…ç½®ç‹€æ…‹
    system_config: Optional[Dict] = Field(None, description="ç³»çµ±é…ç½®ç‹€æ…‹ï¼ˆå•Ÿç”¨çš„ç­–ç•¥ç­‰ï¼‰")


class VendorChatResponse(BaseModel):
    """å¤šæ¥­è€…èŠå¤©å›æ‡‰"""
    answer: str = Field(..., description="å›ç­”å…§å®¹")
    intent_name: Optional[str] = Field(None, description="æ„åœ–åç¨±")
    intent_type: Optional[str] = Field(None, description="æ„åœ–é¡å‹")
    confidence: Optional[float] = Field(None, description="åˆ†é¡ä¿¡å¿ƒåº¦")
    all_intents: Optional[List[str]] = Field(None, description="æ‰€æœ‰ç›¸é—œæ„åœ–åç¨±ï¼ˆä¸»è¦ + æ¬¡è¦ï¼‰")
    secondary_intents: Optional[List[str]] = Field(None, description="æ¬¡è¦ç›¸é—œæ„åœ–")
    intent_ids: Optional[List[int]] = Field(None, description="æ‰€æœ‰æ„åœ– IDs")
    sources: Optional[List[KnowledgeSource]] = Field(None, description="çŸ¥è­˜ä¾†æºåˆ—è¡¨")
    source_count: int = Field(0, description="çŸ¥è­˜ä¾†æºæ•¸é‡")
    vendor_id: int
    mode: str
    session_id: Optional[str] = None
    timestamp: str
    # å½±ç‰‡è³‡è¨Š
    video_url: Optional[str] = Field(None, description="æ•™å­¸å½±ç‰‡ URL")
    video_file_size: Optional[int] = Field(None, description="å½±ç‰‡æª”æ¡ˆå¤§å°ï¼ˆbytesï¼‰")
    video_duration: Optional[int] = Field(None, description="å½±ç‰‡é•·åº¦ï¼ˆç§’ï¼‰")
    video_format: Optional[str] = Field(None, description="å½±ç‰‡æ ¼å¼")
    # è¡¨å–®å¡«å¯«è³‡è¨Šï¼ˆPhase X: è¡¨å–®å¡«å¯«å°è©±åŠŸèƒ½ï¼‰
    form_triggered: Optional[bool] = Field(None, description="è¡¨å–®æ˜¯å¦è¢«è§¸ç™¼")
    form_completed: Optional[bool] = Field(None, description="è¡¨å–®æ˜¯å¦å·²å®Œæˆ")
    form_cancelled: Optional[bool] = Field(None, description="è¡¨å–®æ˜¯å¦å·²å–æ¶ˆ")
    form_id: Optional[str] = Field(None, description="è¡¨å–® ID")
    current_field: Optional[str] = Field(None, description="ç•¶å‰æ¬„ä½åç¨±")
    progress: Optional[str] = Field(None, description="å¡«å¯«é€²åº¦ï¼ˆå¦‚ï¼š2/4ï¼‰")
    allow_resume: Optional[bool] = Field(None, description="æ˜¯å¦å…è¨±æ¢å¾©è¡¨å–®å¡«å¯«")
    # èª¿è©¦è³‡è¨Š
    debug_info: Optional[DebugInfo] = Field(None, description="èª¿è©¦è³‡è¨Šï¼ˆè™•ç†æµç¨‹è©³æƒ…ï¼‰")


@router.post("/message", response_model=VendorChatResponse)
async def vendor_chat_message(request: VendorChatRequest, req: Request):
    """
    å¤šæ¥­è€…é€šç”¨èŠå¤©ç«¯é»ï¼ˆPhase 1: B2C æ¨¡å¼ï¼‰- å·²é‡æ§‹

    æµç¨‹ï¼š
    0. æª¢æŸ¥è¡¨å–®æœƒè©±ï¼ˆPhase X: è¡¨å–®å¡«å¯«åŠŸèƒ½ï¼‰
    1. é©—è­‰æ¥­è€…ç‹€æ…‹
    2. æª¢æŸ¥ç·©å­˜
    3. æ„åœ–åˆ†é¡
    3.5. æª¢æŸ¥è¡¨å–®è§¸ç™¼ï¼ˆPhase X: è¡¨å–®å¡«å¯«åŠŸèƒ½ï¼‰
    4. æ ¹æ“šæ„åœ–è™•ç†ï¼šunclear â†’ SOP â†’ çŸ¥è­˜åº« â†’ RAG fallback
    5. LLM å„ªåŒ–ä¸¦è¿”å›ç­”æ¡ˆ

    é‡æ§‹ï¼šå–®ä¸€è·è²¬åŸå‰‡ï¼ˆSingle Responsibility Principleï¼‰
    - ä¸»å‡½æ•¸ä½œç‚ºç·¨æ’å™¨ï¼ˆOrchestratorï¼‰
    - å„åŠŸèƒ½æ¨¡å¡Šç¨ç«‹ç‚ºè¼”åŠ©å‡½æ•¸
    """
    try:
        # Step 0: æª¢æŸ¥è¡¨å–®æœƒè©±ï¼ˆPhase X: è¡¨å–®å¡«å¯«åŠŸèƒ½ï¼‰
        if request.session_id:
            form_manager = req.app.state.form_manager
            session_state = await form_manager.get_session_state(request.session_id)

            # è™•ç† REVIEWING ç‹€æ…‹ï¼ˆå¯©æ ¸ç¢ºèªï¼‰
            if session_state and session_state['state'] == 'REVIEWING':
                user_choice = request.message.strip()

                # ç¢ºèªæäº¤
                if user_choice.lower() in ["ç¢ºèª", "confirm", "ok", "æäº¤", "submit"]:
                    print(f"ğŸ“‹ ç”¨æˆ¶ç¢ºèªæäº¤è¡¨å–®")
                    # å®Œæˆè¡¨å–®
                    form_schema = await form_manager.get_form_schema(
                        session_state['form_id'],
                        request.vendor_id
                    )
                    form_result = await form_manager._complete_form(
                        session_state,
                        form_schema,
                        session_state['collected_data']
                    )
                    return _convert_form_result_to_response(form_result, request)

                # å–æ¶ˆè¡¨å–®
                elif user_choice.lower() in ["å–æ¶ˆ", "cancel", "æ”¾æ£„"]:
                    print(f"ğŸ“‹ ç”¨æˆ¶å–æ¶ˆè¡¨å–®")
                    form_result = await form_manager.cancel_form(request.session_id)
                    return _convert_form_result_to_response(form_result, request)

                # ä¿®æ”¹æ¬„ä½
                else:
                    print(f"ğŸ“‹ ç”¨æˆ¶è¦æ±‚ä¿®æ”¹æ¬„ä½ï¼š{user_choice}")
                    form_result = await form_manager.handle_edit_request(
                        session_id=request.session_id,
                        user_input=request.message,
                        vendor_id=request.vendor_id
                    )
                    return _convert_form_result_to_response(form_result, request)

            # è™•ç† EDITING ç‹€æ…‹ï¼ˆç·¨è¼¯æ¬„ä½ï¼‰
            if session_state and session_state['state'] == 'EDITING':
                print(f"ğŸ“‹ ç”¨æˆ¶è¼¸å…¥ç·¨è¼¯å¾Œçš„æ¬„ä½å€¼")
                form_result = await form_manager.collect_edited_field(
                    session_id=request.session_id,
                    user_message=request.message,
                    vendor_id=request.vendor_id
                )
                return _convert_form_result_to_response(form_result, request)

            # è™•ç† COLLECTING å’Œ DIGRESSION ç‹€æ…‹ï¼ˆæ”¶é›†æ¬„ä½ï¼‰
            if session_state and session_state['state'] in ['COLLECTING', 'DIGRESSION']:
                # ç”¨æˆ¶æ­£åœ¨å¡«å¯«è¡¨å–® â†’ èµ°è¡¨å–®æ”¶é›†æµç¨‹
                print(f"ğŸ“‹ æª¢æ¸¬åˆ°é€²è¡Œä¸­çš„è¡¨å–®æœƒè©±ï¼ˆ{session_state['form_id']}ï¼‰ï¼Œä½¿ç”¨è¡¨å–®æ”¶é›†æµç¨‹")

                intent_classifier = req.app.state.intent_classifier
                intent_result = intent_classifier.classify(request.message)

                form_result = await form_manager.collect_field_data(
                    user_message=request.message,
                    session_id=request.session_id,
                    intent_result=intent_result,
                    vendor_id=request.vendor_id,
                    language='zh-TW'  # TODO: å¾ request æˆ–ç”¨æˆ¶è¨­å®šè®€å–èªè¨€
                )

                # å¦‚æœç”¨æˆ¶é¸æ“‡å›ç­”å•é¡Œæˆ–å–æ¶ˆè¡¨å–®ï¼Œç¹¼çºŒè™•ç†å¾…è™•ç†çš„å•é¡Œ
                if form_result.get('form_cancelled'):
                    pending_question = form_result.get('pending_question')
                    if pending_question:
                        print(f"ğŸ“‹ ç”¨æˆ¶å–æ¶ˆè¡¨å–®ï¼Œç¹¼çºŒè™•ç†å¾…è™•ç†çš„å•é¡Œï¼š{pending_question}")
                        # æ›¿æ› request.message ç‚ºå¾…è™•ç†çš„å•é¡Œ
                        request.message = pending_question
                        # ç¹¼çºŒå¾€ä¸‹èµ°æ­£å¸¸æµç¨‹
                    else:
                        print(f"ğŸ“‹ ç”¨æˆ¶å–æ¶ˆè¡¨å–®ï¼Œä½†æ²’æœ‰å¾…è™•ç†çš„å•é¡Œ")
                        # æ²’æœ‰å¾…è™•ç†çš„å•é¡Œï¼Œç›´æ¥è¿”å›å–æ¶ˆè¨Šæ¯
                        return _convert_form_result_to_response(form_result, request)
                else:
                    # å°‡è¡¨å–®çµæœè½‰æ›ç‚º VendorChatResponse æ ¼å¼
                    return _convert_form_result_to_response(form_result, request)

        # Step 1: é©—è­‰æ¥­è€…
        resolver = get_vendor_param_resolver()
        vendor_info = _validate_vendor(request.vendor_id, resolver)

        # Step 2: ç·©å­˜æª¢æŸ¥ï¼ˆè¡¨å–®æœŸé–“ä¸ä½¿ç”¨ç·©å­˜ï¼‰
        cache_service = req.app.state.cache_service
        cached_response = _check_cache(cache_service, request.vendor_id, request.message, request.target_user)
        if cached_response:
            return cached_response

        # Step 3: æ„åœ–åˆ†é¡
        intent_classifier = req.app.state.intent_classifier
        intent_result = intent_classifier.classify(request.message)

        # Step 3.5: æª¢æŸ¥è¡¨å–®è§¸ç™¼ï¼ˆPhase X: è¡¨å–®å¡«å¯«åŠŸèƒ½ï¼‰
        if request.session_id and request.user_id:
            form_manager = req.app.state.form_manager
            form_trigger_result = await form_manager.trigger_form_filling(
                intent_name=intent_result['intent_name'],
                session_id=request.session_id,
                user_id=request.user_id,
                vendor_id=request.vendor_id
            )

            if form_trigger_result.get('form_triggered'):
                # è¡¨å–®å·²è§¸ç™¼ â†’ è¿”å›ç¬¬ä¸€å€‹æ¬„ä½æç¤º
                print(f"ğŸ“‹ è¡¨å–®å·²è§¸ç™¼ï¼š{form_trigger_result.get('form_id')}")
                return _convert_form_result_to_response(form_trigger_result, request)

        # Step 4: å˜—è©¦æª¢ç´¢ SOPï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼Œä¸ç®¡æ„åœ–æ˜¯ä»€éº¼éƒ½å…ˆå˜—è©¦ï¼‰- å›æ¸¬æ¨¡å¼å¯è·³é
        if not request.skip_sop:
            sop_items = await _retrieve_sop(request, intent_result)
            if sop_items:
                print(f"âœ… æ‰¾åˆ° {len(sop_items)} å€‹ SOP é …ç›®ï¼Œä½¿ç”¨ SOP æµç¨‹")
                return await _build_sop_response(
                    request, req, intent_result, sop_items, resolver, vendor_info, cache_service
                )
            print(f"â„¹ï¸  æ²’æœ‰æ‰¾åˆ° SOPï¼Œç¹¼çºŒå…¶ä»–æµç¨‹")
        else:
            print(f"â„¹ï¸  [å›æ¸¬æ¨¡å¼] è·³é SOP æª¢ç´¢ï¼Œåƒ…ä½¿ç”¨çŸ¥è­˜åº«")

        # Step 5: è™•ç† unclear æ„åœ–ï¼ˆRAG fallback + æ¸¬è©¦å ´æ™¯è¨˜éŒ„ï¼‰
        if intent_result['intent_name'] == 'unclear':
            return await _handle_unclear_with_rag_fallback(
                request, req, intent_result, resolver, vendor_info, cache_service
            )

        # Step 6: ç²å–æ„åœ– ID
        intent_id = _get_intent_id(intent_result['intent_name'])

        # Step 7: æª¢ç´¢çŸ¥è­˜åº«ï¼ˆæ··åˆæ¨¡å¼ï¼šintent + å‘é‡ï¼‰
        knowledge_list = await _retrieve_knowledge(request, intent_id, intent_result)

        # Step 8: å¦‚æœçŸ¥è­˜åº«æ²’æœ‰çµæœï¼Œå˜—è©¦åƒæ•¸ç­”æ¡ˆæˆ– RAG fallback
        if not knowledge_list:
            print(f"âš ï¸  æ„åœ– '{intent_result['intent_name']}' (ID: {intent_id}) æ²’æœ‰é—œè¯çŸ¥è­˜ï¼Œå˜—è©¦åƒæ•¸ç­”æ¡ˆæˆ– RAG fallback...")
            return await _handle_no_knowledge_found(
                request, req, intent_result, resolver, cache_service, vendor_info
            )

        # Step 9: ä½¿ç”¨çŸ¥è­˜åº«çµæœæ§‹å»ºå„ªåŒ–å›æ‡‰
        return await _build_knowledge_response(
            request, req, intent_result, knowledge_list, resolver, vendor_info, cache_service
        )

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"è™•ç†èŠå¤©è«‹æ±‚å¤±æ•—: {str(e)}"
        )


def _get_intent_id(intent_name: str) -> int:
    """ç²å–æ„åœ– ID"""
    conn = psycopg2.connect(**get_db_config())
    cursor = conn.cursor()
    cursor.execute(
        "SELECT id FROM intents WHERE name = %s AND is_enabled = true",
        (intent_name,)
    )
    result = cursor.fetchone()
    intent_id = result[0] if result else None
    cursor.close()
    conn.close()

    if not intent_id:
        raise HTTPException(
            status_code=500,
            detail=f"è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ°æ„åœ–: {intent_name}"
        )

    return intent_id


@router.get("/vendors/{vendor_id}/test")
async def test_vendor_config(vendor_id: int):
    """
    æ¸¬è©¦æ¥­è€…é…ç½®

    ç”¨æ–¼æª¢æŸ¥æ¥­è€…çš„åƒæ•¸æ˜¯å¦æ­£ç¢ºè¨­å®š
    """
    try:
        resolver = get_vendor_param_resolver()

        # ç²å–æ¥­è€…è³‡è¨Š
        vendor_info = resolver.get_vendor_info(vendor_id)
        if not vendor_info:
            raise HTTPException(status_code=404, detail="æ¥­è€…ä¸å­˜åœ¨")

        # ç²å–æ¥­è€…åƒæ•¸
        params = resolver.get_vendor_parameters(vendor_id)

        # æ¸¬è©¦æ¨¡æ¿è§£æ
        test_template = "ç¹³è²»æ—¥ç‚º {{payment_day}}ï¼Œé€¾æœŸè²» {{late_fee}}ã€‚"
        resolved = resolver.resolve_template(test_template, vendor_id)

        return {
            "vendor": vendor_info,
            "param_count": len(params),
            "parameters": params,
            "test_template": {
                "original": test_template,
                "resolved": resolved
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/reload")
async def reload_vendor_services():
    """
    é‡æ–°è¼‰å…¥å¤šæ¥­è€…æœå‹™

    ç”¨æ–¼æ„åœ–æˆ–çŸ¥è­˜æ›´æ–°å¾Œé‡æ–°è¼‰å…¥
    """
    try:
        global _vendor_param_resolver

        # æ¸…é™¤åƒæ•¸å¿«å–
        if _vendor_param_resolver:
            _vendor_param_resolver.clear_cache()

        return {
            "success": True,
            "message": "å¤šæ¥­è€…æœå‹™å·²é‡æ–°è¼‰å…¥",
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"é‡æ–°è¼‰å…¥å¤±æ•—: {str(e)}"
        )
