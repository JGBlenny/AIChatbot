"""
Lookup API - é€šç”¨æŸ¥è©¢æœå‹™

æ”¯æŒ:
- ç²¾ç¢ºåŒ¹é…
- æ¨¡ç³ŠåŒ¹é… (åŸºæ–¼ difflib)
- å¤šç§Ÿæˆ¶éš”é›¢
- é«˜æ€§èƒ½æŸ¥è©¢

ä½œè€…: AI Chatbot Development Team
å‰µå»ºæ—¥æœŸ: 2026-02-04
"""

from fastapi import APIRouter, Query, HTTPException, Request
from typing import Optional, Dict, Any, List
import logging
import json
from difflib import get_close_matches, SequenceMatcher

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api", tags=["lookup"])


@router.get("/lookup")
async def lookup(
    request: Request,
    category: str = Query(..., description="æŸ¥è©¢é¡åˆ¥ ID (å¦‚ billing_interval)"),
    key: str = Query(..., description="æŸ¥è©¢éµ (å¦‚åœ°å€)"),
    vendor_id: int = Query(..., description="æ¥­è€… ID"),
    fuzzy: bool = Query(True, description="æ˜¯å¦å•Ÿç”¨æ¨¡ç³ŠåŒ¹é…"),
    threshold: float = Query(0.75, ge=0.0, le=1.0, description="æ¨¡ç³ŠåŒ¹é…é–¾å€¼ (0-1)")
) -> Dict[str, Any]:
    """
    é€šç”¨ Lookup æŸ¥è©¢æœå‹™

    ç²¾ç¢ºåŒ¹é…å„ªå…ˆï¼Œå¤±æ•—å‰‡å˜—è©¦æ¨¡ç³ŠåŒ¹é…ã€‚

    Args:
        category: æŸ¥è©¢é¡åˆ¥ (å¦‚ billing_interval, property_manager)
        key: æŸ¥è©¢éµ (å¦‚åœ°å€ã€è»Šç‰Œè™Ÿ)
        vendor_id: æ¥­è€… ID
        fuzzy: æ˜¯å¦å•Ÿç”¨æ¨¡ç³ŠåŒ¹é… (é»˜èª true)
        threshold: æ¨¡ç³ŠåŒ¹é…é–¾å€¼ 0-1 (é»˜èª 0.6)

    Returns:
        {
            "success": True/False,
            "match_type": "exact" | "fuzzy" | "none",
            "value": æŸ¥è©¢çµæœ,
            "metadata": é¡å¤–æ•¸æ“š,
            "suggestions": å»ºè­°åˆ—è¡¨ (ç•¶æœªåŒ¹é…æ™‚)
        }

    Examples:
        # ç²¾ç¢ºåŒ¹é…
        GET /api/lookup?category=billing_interval&key=æ–°åŒ—å¸‚æ¿æ©‹å€å¿ å­è·¯48å··4å¼„8è™ŸäºŒæ¨“&vendor_id=1

        # æ¨¡ç³ŠåŒ¹é…ï¼ˆèª¿ä½é–¾å€¼ï¼‰
        GET /api/lookup?category=billing_interval&key=æ–°åŒ—å¸‚æ¿æ©‹å€&vendor_id=1&threshold=0.5
    """

    logger.info(
        f"ğŸ” Lookup æŸ¥è©¢ | category={category}, key={key[:50]}{'...' if len(key) > 50 else ''}, "
        f"vendor_id={vendor_id}, fuzzy={fuzzy}, threshold={threshold}"
    )

    db_pool = request.app.state.db_pool

    try:
        # ===== æ­¥é©Ÿ 1: ç²¾ç¢ºåŒ¹é… =====
        async with db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT lookup_value, metadata
                FROM lookup_tables
                WHERE vendor_id = $1
                  AND category = $2
                  AND lookup_key = $3
                  AND is_active = true
            """, vendor_id, category, key)

            if row:
                logger.info(f"âœ… ç²¾ç¢ºåŒ¹é…æˆåŠŸ | value={row['lookup_value']}")

                # å¾ metadata è®€å–èªªæ˜æ–‡å­—ï¼ˆå®Œå…¨é…ç½®åŒ–ï¼‰
                metadata_raw = row['metadata']
                # asyncpg å¯èƒ½è¿”å›å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼Œéœ€è¦çµ±ä¸€è™•ç†
                if isinstance(metadata_raw, str):
                    metadata_dict = json.loads(metadata_raw) if metadata_raw else {}
                elif isinstance(metadata_raw, dict):
                    metadata_dict = metadata_raw
                else:
                    metadata_dict = {}

                note = metadata_dict.get('note', '')

                return {
                    "success": True,
                    "match_type": "exact",
                    "category": category,
                    "key": key,
                    "value": row['lookup_value'],
                    "note": note,
                    "fuzzy_warning": "",  # ç²¾ç¢ºåŒ¹é…ç„¡è­¦å‘Š
                    "metadata": metadata_dict
                }

        # ===== æ­¥é©Ÿ 2: æ¨¡ç³ŠåŒ¹é… =====
        if fuzzy:
            logger.info(f"ğŸ” å˜—è©¦æ¨¡ç³ŠåŒ¹é… | threshold={threshold}")

            async with db_pool.acquire() as conn:
                # ç²å–æ‰€æœ‰è©²é¡åˆ¥çš„ keys
                rows = await conn.fetch("""
                    SELECT lookup_key, lookup_value, metadata
                    FROM lookup_tables
                    WHERE vendor_id = $1
                      AND category = $2
                      AND is_active = true
                """, vendor_id, category)

                if not rows:
                    logger.warning(f"âš ï¸  é¡åˆ¥ [{category}] ç„¡æ•¸æ“š")
                    return {
                        "success": False,
                        "error": "no_data",
                        "category": category,
                        "message": f"é¡åˆ¥ [{category}] æš«ç„¡æ•¸æ“š"
                    }

                # ä½¿ç”¨ difflib é€²è¡Œæ¨¡ç³ŠåŒ¹é…
                all_keys = [row['lookup_key'] for row in rows]

                logger.info(f"ğŸ“Š å¾…åŒ¹é…æ•¸æ“š: {len(all_keys)} ç­†")

                matches = get_close_matches(
                    key,
                    all_keys,
                    n=5,  # è¿”å›æœ€å¤š 5 å€‹åŒ¹é…
                    cutoff=threshold
                )

                if matches:
                    # è¨ˆç®—æ‰€æœ‰åŒ¹é…çš„ç›¸ä¼¼åº¦åˆ†æ•¸
                    match_scores = [
                        {
                            "key": match,
                            "score": SequenceMatcher(None, key, match).ratio()
                        }
                        for match in matches
                    ]

                    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
                    match_scores.sort(key=lambda x: x['score'], reverse=True)

                    best_score = match_scores[0]['score']
                    best_match = match_scores[0]['key']

                    # æª¢æŸ¥æ˜¯å¦æœ‰å¤šå€‹ç›¸ä¼¼åº¦æ¥è¿‘çš„åŒ¹é…ï¼ˆå·®è·å°æ–¼ 2%ï¼‰
                    ambiguous_threshold = 0.02
                    similar_matches = [
                        m for m in match_scores
                        if abs(m['score'] - best_score) < ambiguous_threshold
                    ]

                    # å¦‚æœæœ‰å¤šå€‹ç›¸ä¼¼åº¦æ¥è¿‘çš„åŒ¹é…ï¼Œè¦æ±‚æä¾›å®Œæ•´åœ°å€
                    if len(similar_matches) > 1:
                        logger.warning(
                            f"âš ï¸  æ¨¡ç³ŠåŒ¹é…çµæœä¸æ˜ç¢º | æ‰¾åˆ° {len(similar_matches)} å€‹ç›¸ä¼¼åº¦æ¥è¿‘çš„åŒ¹é…"
                        )

                        # å–å¾—é€™äº›åŒ¹é…å°æ‡‰çš„å€¼
                        suggestion_list = []
                        for m in similar_matches[:5]:  # æœ€å¤šé¡¯ç¤º 5 å€‹
                            matched_row = next(r for r in rows if r['lookup_key'] == m['key'])
                            suggestion_list.append({
                                "key": m['key'],
                                "score": round(m['score'], 2),
                                "value": matched_row['lookup_value']
                            })

                        return {
                            "success": False,
                            "error": "ambiguous_match",
                            "category": category,
                            "key": key,
                            "suggestions": suggestion_list,
                            "message": "æ‚¨è¼¸å…¥çš„åœ°å€ä¸å¤ å®Œæ•´ï¼Œæ‰¾åˆ°å¤šå€‹å¯èƒ½çš„åŒ¹é…ã€‚è«‹æä¾›å®Œæ•´çš„åœ°å€ï¼ˆåŒ…å«æ¨“å±¤ç­‰è©³ç´°è³‡è¨Šï¼‰ã€‚"
                        }

                    # åªæœ‰ä¸€å€‹æ˜ç¢ºåŒ¹é…ï¼Œè¿”å›çµæœ
                    matched_row = next(r for r in rows if r['lookup_key'] == best_match)

                    logger.info(
                        f"âœ… æ¨¡ç³ŠåŒ¹é…æˆåŠŸ | matched_key={best_match[:50]}, "
                        f"value={matched_row['lookup_value']}, score={best_score:.2f}"
                    )

                    # å¾ metadata è®€å–èªªæ˜æ–‡å­—ï¼ˆèˆ‡ç²¾ç¢ºåŒ¹é…ç›¸åŒï¼‰
                    metadata_raw = matched_row['metadata']
                    # asyncpg å¯èƒ½è¿”å›å­—ç¬¦ä¸²æˆ–å­—å…¸ï¼Œéœ€è¦çµ±ä¸€è™•ç†
                    if isinstance(metadata_raw, str):
                        metadata_dict = json.loads(metadata_raw) if metadata_raw else {}
                    elif isinstance(metadata_raw, dict):
                        metadata_dict = metadata_raw
                    else:
                        metadata_dict = {}

                    note = metadata_dict.get('note', '')

                    # ç”Ÿæˆæ¨¡ç³ŠåŒ¹é…è­¦å‘Šè¨Šæ¯
                    fuzzy_warning = (
                        f"âš ï¸ **æ³¨æ„**ï¼šæ‚¨è¼¸å…¥çš„åœ°å€èˆ‡è³‡æ–™åº«è¨˜éŒ„ä¸å®Œå…¨ç›¸åŒï¼ˆç›¸ä¼¼åº¦ {round(best_score * 100)}%ï¼‰\n"
                        f"ğŸ“ æ‚¨è¼¸å…¥ï¼š{key}\n"
                        f"ğŸ“ å¯¦éš›åŒ¹é…ï¼š**{best_match}**\n\n"
                        f"å¦‚æœé€™ä¸æ˜¯æ‚¨è¦æŸ¥è©¢çš„åœ°å€ï¼Œè«‹æä¾›å®Œæ•´æ­£ç¢ºçš„åœ°å€ã€‚"
                    )

                    return {
                        "success": True,
                        "match_type": "fuzzy",
                        "match_score": round(best_score, 2),
                        "category": category,
                        "key": key,
                        "matched_key": best_match,
                        "value": matched_row['lookup_value'],
                        "note": note,
                        "fuzzy_warning": fuzzy_warning,
                        "metadata": metadata_dict
                    }
                else:
                    # è¿”å›å»ºè­°ï¼ˆé™ä½é–¾å€¼ï¼‰
                    suggestions = get_close_matches(
                        key,
                        all_keys,
                        n=5,
                        cutoff=max(0.3, threshold - 0.2)  # é™ä½é–¾å€¼ä»¥æä¾›å»ºè­°
                    )

                    logger.info(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é… | è¿”å› {len(suggestions)} å€‹å»ºè­°")

                    suggestion_list = [
                        {
                            "key": s,
                            "score": round(SequenceMatcher(None, key, s).ratio(), 2)
                        }
                        for s in suggestions
                    ]

                    return {
                        "success": False,
                        "error": "no_match",
                        "category": category,
                        "key": key,
                        "suggestions": suggestion_list,
                        "message": "æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„è¨˜éŒ„ï¼Œä»¥ä¸‹æ˜¯ç›¸ä¼¼é¸é …"
                    }

        # ===== æ­¥é©Ÿ 3: ç„¡åŒ¹é…ï¼ˆfuzzy=Falseï¼‰ =====
        logger.warning(f"âŒ æœªæ‰¾åˆ°åŒ¹é…è¨˜éŒ„ï¼ˆfuzzy=Falseï¼‰")
        return {
            "success": False,
            "error": "no_match",
            "category": category,
            "key": key,
            "message": "æœªæ‰¾åˆ°åŒ¹é…çš„è¨˜éŒ„"
        }

    except Exception as e:
        logger.error(f"âŒ Lookup æŸ¥è©¢å¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è©¢å¤±æ•—: {str(e)}")


@router.get("/lookup/categories")
async def list_categories(
    request: Request,
    vendor_id: int = Query(..., description="æ¥­è€… ID")
) -> Dict[str, Any]:
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æŸ¥è©¢é¡åˆ¥

    Args:
        vendor_id: æ¥­è€… ID

    Returns:
        {
            "success": True,
            "vendor_id": 1,
            "categories": [
                {
                    "category": "billing_interval",
                    "category_name": "é›»è²»å¯„é€å€é–“",
                    "record_count": 220
                },
                ...
            ],
            "total": 1
        }

    Example:
        GET /api/lookup/categories?vendor_id=1
    """

    logger.info(f"ğŸ“‹ æŸ¥è©¢é¡åˆ¥åˆ—è¡¨ | vendor_id={vendor_id}")

    db_pool = request.app.state.db_pool

    try:
        async with db_pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT DISTINCT
                    category,
                    category_name,
                    COUNT(*) as record_count
                FROM lookup_tables
                WHERE vendor_id = $1
                  AND is_active = true
                GROUP BY category, category_name
                ORDER BY category
            """, vendor_id)

            categories = [
                {
                    "category": row['category'],
                    "category_name": row['category_name'],
                    "record_count": row['record_count']
                }
                for row in rows
            ]

            logger.info(f"âœ… æ‰¾åˆ° {len(categories)} å€‹é¡åˆ¥")

            return {
                "success": True,
                "vendor_id": vendor_id,
                "categories": categories,
                "total": len(categories)
            }

    except Exception as e:
        logger.error(f"âŒ æŸ¥è©¢é¡åˆ¥å¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è©¢å¤±æ•—: {str(e)}")


@router.get("/lookup/stats")
async def get_stats(
    request: Request,
    vendor_id: int = Query(..., description="æ¥­è€… ID"),
    category: Optional[str] = Query(None, description="é¡åˆ¥ IDï¼ˆå¯é¸ï¼‰")
) -> Dict[str, Any]:
    """
    ç²å– Lookup çµ±è¨ˆè³‡æ–™

    Args:
        vendor_id: æ¥­è€… ID
        category: é¡åˆ¥ IDï¼ˆå¯é¸ï¼Œä¸æä¾›å‰‡é¡¯ç¤ºå…¨éƒ¨ï¼‰

    Returns:
        çµ±è¨ˆè³‡æ–™

    Example:
        GET /api/lookup/stats?vendor_id=1&category=billing_interval
    """

    logger.info(f"ğŸ“Š æŸ¥è©¢çµ±è¨ˆè³‡æ–™ | vendor_id={vendor_id}, category={category}")

    db_pool = request.app.state.db_pool

    try:
        async with db_pool.acquire() as conn:
            if category:
                # ç‰¹å®šé¡åˆ¥çµ±è¨ˆ
                rows = await conn.fetch("""
                    SELECT lookup_value, COUNT(*) as count
                    FROM lookup_tables
                    WHERE vendor_id = $1
                      AND category = $2
                      AND is_active = true
                    GROUP BY lookup_value
                    ORDER BY count DESC
                """, vendor_id, category)

                total = await conn.fetchval("""
                    SELECT COUNT(*)
                    FROM lookup_tables
                    WHERE vendor_id = $1
                      AND category = $2
                      AND is_active = true
                """, vendor_id, category)

                return {
                    "success": True,
                    "vendor_id": vendor_id,
                    "category": category,
                    "total_records": total,
                    "value_distribution": [
                        {"value": row['lookup_value'], "count": row['count']}
                        for row in rows
                    ]
                }
            else:
                # å…¨éƒ¨é¡åˆ¥çµ±è¨ˆ
                rows = await conn.fetch("""
                    SELECT
                        category,
                        category_name,
                        COUNT(*) as record_count,
                        COUNT(DISTINCT lookup_key) as unique_keys
                    FROM lookup_tables
                    WHERE vendor_id = $1
                      AND is_active = true
                    GROUP BY category, category_name
                    ORDER BY record_count DESC
                """, vendor_id)

                return {
                    "success": True,
                    "vendor_id": vendor_id,
                    "categories": [
                        {
                            "category": row['category'],
                            "category_name": row['category_name'],
                            "record_count": row['record_count'],
                            "unique_keys": row['unique_keys']
                        }
                        for row in rows
                    ]
                }

    except Exception as e:
        logger.error(f"âŒ æŸ¥è©¢çµ±è¨ˆå¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è©¢å¤±æ•—: {str(e)}")
