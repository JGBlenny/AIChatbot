"""
RAG Orchestrator ä¸»æœå‹™
æ•´åˆæ„åœ–åˆ†é¡ã€RAG æª¢ç´¢ã€ä¿¡å¿ƒåº¦è©•ä¼°å’Œæœªé‡æ¸…å•é¡Œç®¡ç†
"""
import os
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import asyncpg
from asyncpg.pool import Pool

# å°å…¥æœå‹™
from services.intent_classifier import IntentClassifier
from services.rag_engine import RAGEngine
from services.confidence_evaluator import ConfidenceEvaluator
from services.unclear_question_manager import UnclearQuestionManager
from services.llm_answer_optimizer import LLMAnswerOptimizer
from services.intent_suggestion_engine import IntentSuggestionEngine

# å°å…¥è·¯ç”±
from routers import chat, unclear_questions, suggested_intents, business_scope, intents, knowledge, vendors, knowledge_import, knowledge_generation, platform_sop

# å…¨å±€è®Šæ•¸
db_pool: Pool = None
intent_classifier: IntentClassifier = None
rag_engine: RAGEngine = None
confidence_evaluator: ConfidenceEvaluator = None
unclear_question_manager: UnclearQuestionManager = None
llm_answer_optimizer: LLMAnswerOptimizer = None
suggestion_engine: IntentSuggestionEngine = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç”Ÿå‘½é€±æœŸç®¡ç†"""
    # å•Ÿå‹•æ™‚åˆå§‹åŒ–
    global db_pool, intent_classifier, rag_engine, confidence_evaluator, unclear_question_manager, llm_answer_optimizer, suggestion_engine

    print("ğŸš€ åˆå§‹åŒ– RAG Orchestrator...")

    # å»ºç«‹è³‡æ–™åº«é€£æ¥æ± 
    db_pool = await asyncpg.create_pool(
        host=os.getenv("DB_HOST", "postgres"),
        port=int(os.getenv("DB_PORT", "5432")),
        database=os.getenv("DB_NAME", "aichatbot_admin"),
        user=os.getenv("DB_USER", "aichatbot"),
        password=os.getenv("DB_PASSWORD", "aichatbot_password"),
        min_size=2,
        max_size=10
    )
    print("âœ… è³‡æ–™åº«é€£æ¥æ± å·²å»ºç«‹")

    # åˆå§‹åŒ–æœå‹™
    intent_classifier = IntentClassifier()
    print("âœ… æ„åœ–åˆ†é¡å™¨å·²åˆå§‹åŒ–")

    rag_engine = RAGEngine(db_pool)
    print("âœ… RAG æª¢ç´¢å¼•æ“å·²åˆå§‹åŒ–")

    confidence_evaluator = ConfidenceEvaluator()
    print("âœ… ä¿¡å¿ƒåº¦è©•ä¼°å™¨å·²åˆå§‹åŒ–")

    unclear_question_manager = UnclearQuestionManager(db_pool)
    print("âœ… æœªé‡æ¸…å•é¡Œç®¡ç†å™¨å·²åˆå§‹åŒ–")

    # Phase 3 æ“´å±•ï¼šé…ç½® LLM ç­”æ¡ˆå„ªåŒ–å™¨ï¼ˆå«ç­”æ¡ˆåˆæˆåŠŸèƒ½ï¼‰
    llm_optimizer_config = {
        "enable_synthesis": os.getenv("ENABLE_ANSWER_SYNTHESIS", "false").lower() == "true",
        "synthesis_threshold": float(os.getenv("SYNTHESIS_THRESHOLD", "0.7")),
        "synthesis_min_results": int(os.getenv("SYNTHESIS_MIN_RESULTS", "2")),
        "synthesis_max_results": int(os.getenv("SYNTHESIS_MAX_RESULTS", "3"))
    }

    llm_answer_optimizer = LLMAnswerOptimizer(config=llm_optimizer_config)

    if llm_optimizer_config["enable_synthesis"]:
        print(f"âœ… LLM ç­”æ¡ˆå„ªåŒ–å™¨å·²åˆå§‹åŒ– (Phase 3 + ç­”æ¡ˆåˆæˆåŠŸèƒ½å·²å•Ÿç”¨)")
        print(f"   åˆæˆé–¾å€¼: {llm_optimizer_config['synthesis_threshold']}")
        print(f"   åˆæˆä¾†æºæ•¸: {llm_optimizer_config['synthesis_min_results']}-{llm_optimizer_config['synthesis_max_results']}")
    else:
        print("âœ… LLM ç­”æ¡ˆå„ªåŒ–å™¨å·²åˆå§‹åŒ– (Phase 3ï¼Œç­”æ¡ˆåˆæˆåŠŸèƒ½åœç”¨)")

    suggestion_engine = IntentSuggestionEngine()
    print("âœ… æ„åœ–å»ºè­°å¼•æ“å·²åˆå§‹åŒ– (Phase B)")

    # å°‡æœå‹™æ³¨å…¥åˆ° app.state
    app.state.db_pool = db_pool
    app.state.intent_classifier = intent_classifier
    app.state.rag_engine = rag_engine
    app.state.confidence_evaluator = confidence_evaluator
    app.state.unclear_question_manager = unclear_question_manager
    app.state.llm_answer_optimizer = llm_answer_optimizer
    app.state.suggestion_engine = suggestion_engine

    print("ğŸ‰ RAG Orchestrator å•Ÿå‹•å®Œæˆï¼ï¼ˆå« Phase 3 LLM å„ªåŒ– + Phase B æ„åœ–å»ºè­°ï¼‰")
    print(f"ğŸ“ API æ–‡ä»¶: http://localhost:8100/docs")

    yield

    # é—œé–‰æ™‚æ¸…ç†
    print("ğŸ”„ é—œé–‰ RAG Orchestrator...")
    await db_pool.close()
    print("ğŸ‘‹ RAG Orchestrator å·²é—œé–‰")


# å»ºç«‹ FastAPI æ‡‰ç”¨
app = FastAPI(
    title="RAG Orchestrator",
    description="å¢å¼·å‹ RAG ç³»çµ± - æ„åœ–åˆ†é¡ã€æª¢ç´¢ã€ä¿¡å¿ƒåº¦è©•ä¼°",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ä¸­é–“ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¨»å†Šè·¯ç”±
app.include_router(chat.router, prefix="/api/v1", tags=["chat"])
app.include_router(unclear_questions.router, prefix="/api/v1", tags=["unclear_questions"])
app.include_router(suggested_intents.router, prefix="/api/v1", tags=["suggested_intents"])
app.include_router(business_scope.router, prefix="/api/v1", tags=["business_scope"])
app.include_router(intents.router, prefix="/api/v1", tags=["intents"])
app.include_router(knowledge.router, tags=["knowledge"])
app.include_router(vendors.router, tags=["vendors"])  # Phase 1: Multi-Vendor Support
app.include_router(knowledge_import.router, tags=["knowledge_import"])  # Knowledge Import from LINE chats
app.include_router(knowledge_generation.router, prefix="/api/v1", tags=["knowledge_generation"])  # AI Knowledge Generation
app.include_router(platform_sop.router, tags=["platform_sop"])  # Platform SOP Template Management


@app.get("/")
async def root():
    """æ ¹è·¯å¾‘"""
    return {
        "name": "RAG Orchestrator",
        "version": "1.0.0",
        "description": "å¢å¼·å‹ RAG ç³»çµ±",
        "docs": "/docs"
    }


@app.get("/api/v1/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    try:
        # æ¸¬è©¦è³‡æ–™åº«é€£æ¥
        async with app.state.db_pool.acquire() as conn:
            await conn.fetchval("SELECT 1")

        return {
            "status": "healthy",
            "database": "connected",
            "services": {
                "intent_classifier": "ready",
                "rag_engine": "ready",
                "confidence_evaluator": "ready",
                "unclear_question_manager": "ready",
                "llm_answer_optimizer": "ready (Phase 3)",
                "suggestion_engine": "ready (Phase B)"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Service unhealthy: {str(e)}")


@app.get("/api/v1/stats")
async def get_stats():
    """å–å¾—çµ±è¨ˆè³‡è¨Š"""
    try:
        # å°è©±è¨˜éŒ„çµ±è¨ˆ
        async with app.state.db_pool.acquire() as conn:
            total_conversations = await conn.fetchval(
                "SELECT COUNT(*) FROM conversation_logs"
            )

            # æ„åœ–é¡å‹åˆ†å¸ƒ
            intent_dist = await conn.fetch("""
                SELECT intent_type, COUNT(*) as count
                FROM conversation_logs
                WHERE intent_type IS NOT NULL
                GROUP BY intent_type
                ORDER BY count DESC
            """)

            # å¹³å‡ä¿¡å¿ƒåº¦
            avg_confidence = await conn.fetchval("""
                SELECT AVG(confidence_score)
                FROM conversation_logs
                WHERE confidence_score IS NOT NULL
            """)

            # ä½¿ç”¨è€…è©•åˆ†
            avg_rating = await conn.fetchval("""
                SELECT AVG(user_rating)
                FROM conversation_logs
                WHERE user_rating IS NOT NULL
            """)

        # æœªé‡æ¸…å•é¡Œçµ±è¨ˆ
        unclear_stats = await app.state.unclear_question_manager.get_stats()

        return {
            "conversations": {
                "total": total_conversations,
                "avg_confidence": float(avg_confidence) if avg_confidence else 0.0,
                "avg_rating": float(avg_rating) if avg_rating else 0.0,
                "intent_distribution": {
                    row['intent_type']: row['count']
                    for row in intent_dist
                }
            },
            "unclear_questions": unclear_stats
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get stats: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8100,
        reload=True
    )
