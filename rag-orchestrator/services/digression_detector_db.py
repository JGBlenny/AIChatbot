"""
é›¢é¡Œåµæ¸¬å™¨ï¼ˆDigression Detectorï¼‰- è³‡æ–™åº«é…ç½®ç‰ˆæœ¬
è² è²¬åµæ¸¬ç”¨æˆ¶æ˜¯å¦é›¢é¡Œæˆ–æƒ³è·³å‡ºè¡¨å–®å¡«å¯«æµç¨‹

æ–¹æ¡ˆ Bï¼šæ”¯æ´å¤šæ¥­è€…ã€å¤šèªè¨€ã€å‹•æ…‹èª¿æ•´
é…ç½®å¾è³‡æ–™åº« digression_config è¡¨è®€å–ï¼Œæ”¯æ´ç·©å­˜
"""
from typing import Tuple, Optional, Dict
from services.embedding_utils import get_embedding_client
from datetime import datetime, timedelta
import asyncpg


class DigressionType:
    """é›¢é¡Œé¡å‹æšèˆ‰"""
    EXPLICIT_EXIT = "explicit_exit"  # æ˜ç¢ºé€€å‡ºï¼ˆ"å–æ¶ˆ"ã€"ä¸å¡«äº†"ï¼‰
    QUESTION = "question"  # ç”¨æˆ¶å•å•é¡Œï¼ˆ"ç‚ºä»€éº¼"ã€"å¦‚ä½•"ï¼‰
    INTENT_SHIFT = "intent_shift"  # æ„åœ–è½‰ç§»ï¼ˆæª¢æ¸¬åˆ°ä¸ç›¸é—œçš„é«˜ç½®ä¿¡åº¦æ„åœ–ï¼‰
    IRRELEVANT_RESPONSE = "irrelevant_response"  # ä¸ç›¸é—œå›ç­”


class DigressionDetectorDB:
    """é›¢é¡Œåµæ¸¬å™¨ï¼ˆè³‡æ–™åº«é…ç½®ç‰ˆæœ¬ï¼‰"""

    def __init__(self, db_pool: asyncpg.Pool):
        """
        åˆå§‹åŒ–é›¢é¡Œåµæ¸¬å™¨

        Args:
            db_pool: è³‡æ–™åº«é€£æ¥æ± 
        """
        self.db_pool = db_pool
        self.embedding_client = get_embedding_client()

        # é…ç½®ç·©å­˜
        self._config_cache = {}
        self._cache_ttl = timedelta(minutes=5)  # ç·©å­˜ 5 åˆ†é˜

        # é»˜èªé…ç½®ï¼ˆç•¶è³‡æ–™åº«æŸ¥è©¢å¤±æ•—æ™‚ä½¿ç”¨ï¼‰
        self._default_exit_keywords = [
            "å–æ¶ˆ", "ä¸å¡«äº†", "ç®—äº†", "ä¸æƒ³å¡«", "åœæ­¢",
            "é€€å‡º", "é›¢é–‹", "çµæŸ", "exit", "cancel", "stop"
        ]
        self._default_question_keywords = [
            "ç‚ºä»€éº¼", "å¦‚ä½•", "æ€éº¼", "ä»€éº¼", "å“ªè£¡",
            "å¤šå°‘", "å¹¾", "å—", "?", "ï¼Ÿ"
        ]
        self._default_thresholds = {
            "intent_shift_threshold": 0.7,
            "semantic_similarity_threshold": 0.25,
            "short_answer_length_intent": 15,
            "short_answer_length_semantic": 10
        }

    async def _load_config(self, vendor_id: int, language: str = 'zh-TW') -> Dict:
        """
        å¾è³‡æ–™åº«è¼‰å…¥é…ç½®ï¼ˆå«ç·©å­˜ï¼‰

        Args:
            vendor_id: æ¥­è€… ID
            language: èªè¨€ä»£ç¢¼ï¼ˆzh-TW, en, zh-CN ç­‰ï¼‰

        Returns:
            é…ç½®å­—å…¸ {
                'exit': [...],
                'question': [...],
                'thresholds': {...}
            }
        """
        # ç”Ÿæˆç·©å­˜éµ
        cache_key = f"{vendor_id}:{language}"

        # æª¢æŸ¥ç·©å­˜
        if cache_key in self._config_cache:
            cached_config, cached_time = self._config_cache[cache_key]
            if datetime.now() - cached_time < self._cache_ttl:
                print(f"ğŸ”§ [é…ç½®] ä½¿ç”¨ç·©å­˜é…ç½®ï¼ˆvendor={vendor_id}, lang={language}ï¼‰")
                return cached_config

        # å¾è³‡æ–™åº«è¼‰å…¥
        try:
            async with self.db_pool.acquire() as conn:
                rows = await conn.fetch("""
                    SELECT DISTINCT ON (keyword_type)
                        keyword_type,
                        keywords,
                        thresholds
                    FROM digression_config
                    WHERE is_active = true
                      AND (vendor_id = $1 OR vendor_id IS NULL)
                      AND (language = $2 OR language IS NULL)
                    ORDER BY keyword_type,
                             vendor_id NULLS LAST,      -- æ¥­è€…é…ç½®å„ªå…ˆæ–¼å…¨å±€é…ç½®
                             priority DESC,              -- é«˜å„ªå…ˆç´šå„ªå…ˆ
                             created_at DESC             -- æœ€æ–°é…ç½®å„ªå…ˆ
                """, vendor_id, language)

            # è§£æé…ç½®
            import json
            config = {
                'exit': self._default_exit_keywords.copy(),
                'question': self._default_question_keywords.copy(),
                'thresholds': self._default_thresholds.copy()
            }

            for row in rows:
                keyword_type = row['keyword_type']

                # è™•ç† keywordsï¼ˆå¯èƒ½æ˜¯å­—ä¸²æˆ–åˆ—è¡¨ï¼‰
                if keyword_type == 'exit' and row['keywords']:
                    keywords_data = row['keywords']
                    if isinstance(keywords_data, str):
                        config['exit'] = json.loads(keywords_data)
                    else:
                        config['exit'] = keywords_data

                elif keyword_type == 'question' and row['keywords']:
                    keywords_data = row['keywords']
                    if isinstance(keywords_data, str):
                        config['question'] = json.loads(keywords_data)
                    else:
                        config['question'] = keywords_data

                elif keyword_type == 'thresholds' and row['thresholds']:
                    thresholds_data = row['thresholds']
                    if isinstance(thresholds_data, str):
                        config['thresholds'] = json.loads(thresholds_data)
                    else:
                        config['thresholds'] = thresholds_data

            # ç·©å­˜é…ç½®
            self._config_cache[cache_key] = (config, datetime.now())

            print(f"âœ… [é…ç½®] å·²è¼‰å…¥é…ç½®ï¼ˆvendor={vendor_id}, lang={language}ï¼‰")
            print(f"   é€€å‡ºé—œéµå­—: {len(config['exit'])} å€‹")
            print(f"   å•é¡Œé—œéµå­—: {len(config['question'])} å€‹")
            print(f"   æ„åœ–è½‰ç§»é–¾å€¼: {config['thresholds'].get('intent_shift_threshold')}")

            return config

        except Exception as e:
            print(f"âš ï¸  [é…ç½®] è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨é»˜èªé…ç½®: {e}")
            # è¿”å›é»˜èªé…ç½®
            return {
                'exit': self._default_exit_keywords,
                'question': self._default_question_keywords,
                'thresholds': self._default_thresholds
            }

    def clear_cache(self):
        """æ¸…ç©ºé…ç½®ç·©å­˜ï¼ˆç”¨æ–¼æ¸¬è©¦æˆ–å¼·åˆ¶é‡æ–°è¼‰å…¥ï¼‰"""
        self._config_cache.clear()
        print("ğŸ—‘ï¸  [é…ç½®] ç·©å­˜å·²æ¸…ç©º")

    async def detect(
        self,
        user_message: str,
        current_field: Dict,
        form_schema: Dict,
        intent_result: Optional[Dict] = None,
        vendor_id: int = 1,
        language: str = 'zh-TW'
    ) -> Tuple[bool, Optional[str], float]:
        """
        åµæ¸¬ç”¨æˆ¶æ˜¯å¦é›¢é¡Œ

        Args:
            user_message: ç”¨æˆ¶è¼¸å…¥
            current_field: ç•¶å‰æ¬„ä½é…ç½®
            form_schema: è¡¨å–®å®šç¾©
            intent_result: æ„åœ–åˆ†é¡çµæœï¼ˆå¯é¸ï¼‰
            vendor_id: æ¥­è€… IDï¼ˆç”¨æ–¼è¼‰å…¥å°ˆå±¬é…ç½®ï¼‰
            language: èªè¨€ä»£ç¢¼ï¼ˆç”¨æ–¼è¼‰å…¥å°æ‡‰èªè¨€çš„é—œéµå­—ï¼‰

        Returns:
            (is_digression, digression_type, confidence)
            - is_digression: æ˜¯å¦é›¢é¡Œ
            - digression_type: é›¢é¡Œé¡å‹
            - confidence: ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
        """
        # è¼‰å…¥é…ç½®
        config = await self._load_config(vendor_id, language)

        # ç­–ç•¥ 1ï¼šæ˜ç¢ºé—œéµå­—æª¢æ¸¬ï¼ˆå„ªå…ˆç´šæœ€é«˜ï¼‰
        result = self._check_explicit_keywords(user_message, config['exit'])
        if result[0]:
            return result

        # ç­–ç•¥ 2ï¼šå•é¡Œé—œéµå­—æª¢æ¸¬
        result = self._check_question_keywords(user_message, config['question'])
        if result[0]:
            return result

        # ç­–ç•¥ 3ï¼šæ„åœ–è½‰ç§»æª¢æ¸¬ï¼ˆå¦‚æœæä¾›äº†æ„åœ–åˆ†é¡çµæœï¼‰
        if intent_result:
            result = self._check_intent_shift(
                intent_result,
                form_schema,
                user_message,
                config['thresholds']
            )
            if result[0]:
                return result

        # ç­–ç•¥ 4ï¼šèªç¾©ç›¸ä¼¼åº¦æª¢æ¸¬ï¼ˆèˆ‡ç•¶å‰æ¬„ä½æç¤ºçš„ç›¸é—œæ€§ï¼‰
        result = await self._check_semantic_similarity(
            user_message,
            current_field,
            config['thresholds']
        )
        if result[0]:
            return result

        # æ²’æœ‰æª¢æ¸¬åˆ°é›¢é¡Œ
        return (False, None, 0.0)

    def _check_explicit_keywords(
        self,
        user_message: str,
        exit_keywords: list
    ) -> Tuple[bool, Optional[str], float]:
        """
        æª¢æŸ¥æ˜ç¢ºé€€å‡ºé—œéµå­—

        Args:
            user_message: ç”¨æˆ¶è¼¸å…¥
            exit_keywords: é€€å‡ºé—œéµå­—åˆ—è¡¨

        Returns:
            (is_digression, digression_type, confidence)
        """
        message_lower = user_message.lower()

        for keyword in exit_keywords:
            if keyword.lower() in message_lower:
                print(f"ğŸšª [é›¢é¡Œåµæ¸¬] æ˜ç¢ºé€€å‡ºé—œéµå­—ï¼š{keyword}")
                return (True, DigressionType.EXPLICIT_EXIT, 1.0)

        return (False, None, 0.0)

    def _check_question_keywords(
        self,
        user_message: str,
        question_keywords: list
    ) -> Tuple[bool, Optional[str], float]:
        """
        æª¢æŸ¥å•é¡Œé—œéµå­—

        Args:
            user_message: ç”¨æˆ¶è¼¸å…¥
            question_keywords: å•é¡Œé—œéµå­—åˆ—è¡¨

        Returns:
            (is_digression, digression_type, confidence)
        """
        # å¦‚æœæ¶ˆæ¯å¤ªçŸ­ï¼ˆ< 5å­—ï¼‰ï¼Œå¯èƒ½ä¸æ˜¯å•é¡Œ
        if len(user_message) < 5:
            return (False, None, 0.0)

        for keyword in question_keywords:
            if keyword in user_message:
                print(f"â“ [é›¢é¡Œåµæ¸¬] å•é¡Œé—œéµå­—ï¼š{keyword}")
                return (True, DigressionType.QUESTION, 0.8)

        return (False, None, 0.0)

    def _check_intent_shift(
        self,
        intent_result: Dict,
        form_schema: Dict,
        user_message: str,
        thresholds: Dict
    ) -> Tuple[bool, Optional[str], float]:
        """
        æª¢æŸ¥æ„åœ–è½‰ç§»

        å¦‚æœæª¢æ¸¬åˆ°é«˜ç½®ä¿¡åº¦çš„ä¸ç›¸é—œæ„åœ–ï¼Œè¦–ç‚ºé›¢é¡Œ

        Args:
            intent_result: æ„åœ–åˆ†é¡çµæœ
            form_schema: è¡¨å–®å®šç¾©
            user_message: ç”¨æˆ¶è¼¸å…¥
            thresholds: é–¾å€¼é…ç½®

        Returns:
            (is_digression, digression_type, confidence)
        """
        intent_name = intent_result.get('intent_name', '')
        confidence = intent_result.get('confidence', 0.0)

        # æ„åœ–ä¸æ˜ç¢ºï¼Œä¸åˆ¤å®šç‚ºé›¢é¡Œ
        if intent_name == 'unclear':
            return (False, None, 0.0)

        # å¾é…ç½®è®€å–çŸ­ç­”æ¡ˆé•·åº¦é–¾å€¼
        short_length = thresholds.get('short_answer_length_intent', 15)

        # å¦‚æœç”¨æˆ¶è¼¸å…¥å¾ˆçŸ­ï¼ˆ<= short_length å­—ï¼‰ï¼Œè·³éæ„åœ–è½‰ç§»æª¢æŸ¥
        if user_message and len(user_message) <= short_length:
            print(f"â„¹ï¸  [é›¢é¡Œåµæ¸¬] ç”¨æˆ¶è¼¸å…¥è¼ƒçŸ­ï¼ˆ{len(user_message)}å­—ï¼‰ï¼Œè·³éæ„åœ–è½‰ç§»æª¢æŸ¥")
            return (False, None, 0.0)

        # å¾é…ç½®è®€å–æ„åœ–è½‰ç§»é–¾å€¼
        intent_threshold = thresholds.get('intent_shift_threshold', 0.7)

        # æª¢æŸ¥æ˜¯å¦ç‚ºè¡¨å–®ç›¸é—œæ„åœ–
        trigger_intents = form_schema.get('trigger_intents') or []
        if trigger_intents and intent_name not in trigger_intents and confidence > intent_threshold:
            print(f"ğŸ”€ [é›¢é¡Œåµæ¸¬] æ„åœ–è½‰ç§»ï¼š{intent_name} (ç½®ä¿¡åº¦: {confidence:.2f}, é–¾å€¼: {intent_threshold})")
            return (True, DigressionType.INTENT_SHIFT, confidence)

        return (False, None, 0.0)

    async def _check_semantic_similarity(
        self,
        user_message: str,
        current_field: Dict,
        thresholds: Dict
    ) -> Tuple[bool, Optional[str], float]:
        """
        æª¢æŸ¥èªç¾©ç›¸ä¼¼åº¦ï¼ˆèˆ‡ç•¶å‰æ¬„ä½æç¤ºçš„ç›¸é—œæ€§ï¼‰

        å¦‚æœç›¸ä¼¼åº¦éä½ï¼Œå¯èƒ½æ˜¯ä¸ç›¸é—œçš„å›ç­”

        Args:
            user_message: ç”¨æˆ¶è¼¸å…¥
            current_field: ç•¶å‰æ¬„ä½é…ç½®
            thresholds: é–¾å€¼é…ç½®

        Returns:
            (is_digression, digression_type, confidence)
        """
        # å¾é…ç½®è®€å–çŸ­ç­”æ¡ˆé•·åº¦é–¾å€¼
        short_length = thresholds.get('short_answer_length_semantic', 10)

        # å¦‚æœç”¨æˆ¶è¼¸å…¥å¾ˆçŸ­ï¼ˆ<= short_length å­—ï¼‰ï¼Œè·³éèªç¾©ç›¸ä¼¼åº¦æª¢æŸ¥
        if len(user_message) <= short_length:
            print(f"â„¹ï¸  [é›¢é¡Œåµæ¸¬] ç”¨æˆ¶è¼¸å…¥è¼ƒçŸ­ï¼ˆ{len(user_message)}å­—ï¼‰ï¼Œè·³éèªç¾©ç›¸ä¼¼åº¦æª¢æŸ¥")
            return (False, None, 0.0)

        try:
            # ç²å–æ¬„ä½æç¤º
            field_prompt = current_field.get('prompt', '')

            # è¨ˆç®—èªç¾©ç›¸ä¼¼åº¦
            user_embedding = await self.embedding_client.get_embedding(user_message, verbose=False)
            prompt_embedding = await self.embedding_client.get_embedding(field_prompt, verbose=False)

            if not user_embedding or not prompt_embedding:
                # ç„¡æ³•è¨ˆç®—ç›¸ä¼¼åº¦ï¼Œä¸åˆ¤å®šç‚ºé›¢é¡Œ
                return (False, None, 0.0)

            # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = self._cosine_similarity(user_embedding, prompt_embedding)

            # å¾é…ç½®è®€å–èªç¾©ç›¸ä¼¼åº¦é–¾å€¼
            similarity_threshold = thresholds.get('semantic_similarity_threshold', 0.25)

            # ç›¸ä¼¼åº¦éä½è¦–ç‚ºä¸ç›¸é—œ
            if similarity < similarity_threshold:
                print(f"ğŸ“‰ [é›¢é¡Œåµæ¸¬] èªç¾©ç›¸ä¼¼åº¦éä½ï¼š{similarity:.3f}ï¼ˆé–¾å€¼ï¼š{similarity_threshold}ï¼‰")
                return (True, DigressionType.IRRELEVANT_RESPONSE, 0.6)

        except Exception as e:
            print(f"âš ï¸  [é›¢é¡Œåµæ¸¬] èªç¾©ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            # è¨ˆç®—å¤±æ•—ï¼Œä¸åˆ¤å®šç‚ºé›¢é¡Œ
            return (False, None, 0.0)

        return (False, None, 0.0)

    def _cosine_similarity(self, vec1: list, vec2: list) -> float:
        """
        è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦

        Args:
            vec1: å‘é‡1
            vec2: å‘é‡2

        Returns:
            ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
        """
        import numpy as np

        vec1_np = np.array(vec1)
        vec2_np = np.array(vec2)

        dot_product = np.dot(vec1_np, vec2_np)
        norm_vec1 = np.linalg.norm(vec1_np)
        norm_vec2 = np.linalg.norm(vec2_np)

        if norm_vec1 == 0 or norm_vec2 == 0:
            return 0.0

        return dot_product / (norm_vec1 * norm_vec2)
