"""
æœªé‡æ¸…å•é¡Œç®¡ç†æœå‹™
è² è²¬è¨˜éŒ„ã€æŸ¥è©¢å’Œç®¡ç†ä½ä¿¡å¿ƒåº¦çš„æœªé‡æ¸…å•é¡Œ

å¢å¼·åŠŸèƒ½ï¼ˆMigration 34ï¼‰ï¼š
- çµ„åˆç­–ç•¥ï¼šèªç¾©ç›¸ä¼¼åº¦ â‰¥ 0.80 OR ç·¨è¼¯è·é›¢ â‰¤ 2
- æ‹¼éŸ³æª¢æ¸¬ï¼šè™•ç†åš´é‡åŒéŸ³éŒ¯èª¤ï¼ˆèªç¾© 0.60-0.80 + æ‹¼éŸ³ç›¸ä¼¼åº¦ â‰¥ 0.80ï¼‰
"""
from typing import List, Dict, Optional
from datetime import datetime
from asyncpg.pool import Pool
import json
import os
from pypinyin import lazy_pinyin
from .embedding_utils import get_embedding_client


class UnclearQuestionManager:
    """æœªé‡æ¸…å•é¡Œç®¡ç†å™¨"""

    def __init__(self, db_pool: Pool):
        """
        åˆå§‹åŒ–ç®¡ç†å™¨

        Args:
            db_pool: è³‡æ–™åº«é€£æ¥æ± 
        """
        self.db_pool = db_pool
        # ä½¿ç”¨å…±ç”¨çš„ embedding å®¢æˆ¶ç«¯
        self.embedding_client = get_embedding_client()

    async def record_unclear_question(
        self,
        question: str,
        user_id: Optional[str] = None,
        intent_type: Optional[str] = None,
        similarity_score: Optional[float] = None,
        retrieved_docs: Optional[Dict] = None,
        semantic_similarity_threshold: float = 0.80,
        pinyin_similarity_threshold: float = 0.80
    ) -> int:
        """
        è¨˜éŒ„æœªé‡æ¸…å•é¡Œï¼ˆä½¿ç”¨å¤šå±¤æª¢æ¸¬å»é‡ï¼‰

        å¦‚æœç›¸åŒæˆ–ç›¸ä¼¼çš„å•é¡Œå·²å­˜åœ¨ï¼Œå‰‡æ›´æ–°é »ç‡å’Œæœ€å¾Œè©¢å•æ™‚é–“

        æª¢æ¸¬ç­–ç•¥ï¼ˆä¸‰å±¤ï¼‰ï¼š
        1. ç²¾ç¢ºåŒ¹é…
        2. çµ„åˆæª¢æ¸¬ï¼šèªç¾©ç›¸ä¼¼åº¦ â‰¥ 0.80 OR ç·¨è¼¯è·é›¢ â‰¤ 2
        3. æ‹¼éŸ³æª¢æ¸¬ï¼šèªç¾© 0.60-0.80 + æ‹¼éŸ³ç›¸ä¼¼åº¦ â‰¥ 0.80ï¼ˆé‡å°åš´é‡åŒéŸ³éŒ¯èª¤ï¼‰

        Args:
            question: å•é¡Œå…§å®¹
            user_id: ä½¿ç”¨è€… ID
            intent_type: æ„åœ–é¡å‹
            similarity_score: ç›¸ä¼¼åº¦åˆ†æ•¸
            retrieved_docs: æª¢ç´¢åˆ°çš„æ–‡ä»¶
            semantic_similarity_threshold: èªç¾©ç›¸ä¼¼åº¦é–¾å€¼ (default: 0.80)
            pinyin_similarity_threshold: æ‹¼éŸ³ç›¸ä¼¼åº¦é–¾å€¼ (default: 0.80)

        Returns:
            å•é¡Œ ID
        """
        # 1. ç”Ÿæˆå•é¡Œçš„å‘é‡è¡¨ç¤º
        question_embedding = await self._get_embedding(question)

        if not question_embedding:
            print(f"âš ï¸  ç„¡æ³•ç”Ÿæˆå•é¡Œå‘é‡ï¼Œå›é€€åˆ°ç²¾ç¢ºåŒ¹é…æ¨¡å¼")
            # Fallback to exact match if embedding fails
            return await self._record_without_semantics(
                question, user_id, intent_type, similarity_score, retrieved_docs
            )

        # 2. ä½¿ç”¨è³‡æ–™åº«å‡½æ•¸é€²è¡Œèªç¾©å»é‡
        async with self.db_pool.acquire() as conn:
            # å°‡ embedding è½‰æ›ç‚º PostgreSQL vector æ ¼å¼
            # question_embedding is a list of floats, convert to [x,y,z,...] format
            vector_str = '[' + ','.join(str(x) for x in question_embedding) + ']'

            # åºåˆ—åŒ– retrieved_docs ç‚º JSON å­—ç¬¦ä¸²
            retrieved_docs_json = json.dumps(retrieved_docs) if retrieved_docs else None

            # å‘¼å«è³‡æ–™åº«å‡½æ•¸é€²è¡Œèªç¾©å»é‡
            result = await conn.fetchrow("""
                SELECT * FROM record_unclear_question_with_semantics(
                    $1::TEXT,
                    $2::vector,
                    $3::VARCHAR(100),
                    $4::DECIMAL
                )
            """, question, vector_str, intent_type, semantic_similarity_threshold)

            unclear_question_id = result['unclear_question_id']
            is_new = result['is_new_question']
            matched_question = result['matched_similar_question']
            sim_score = result['sim_score']
            frequency = result['current_frequency']

            # 3. å¦‚æœæ˜¯æ–°å•é¡Œï¼Œå˜—è©¦æ‹¼éŸ³æª¢æ¸¬ï¼ˆé‡å°åš´é‡åŒéŸ³éŒ¯èª¤ï¼‰
            if is_new:
                print(f"ğŸ” æ–°å•é¡Œå»ºç«‹ï¼Œæª¢æŸ¥æ‹¼éŸ³ç›¸ä¼¼åº¦...")

                # æŸ¥è©¢æ‰€æœ‰ç¾æœ‰å•é¡Œé€²è¡Œæ‹¼éŸ³æ¯”å°
                pinyin_candidates = await conn.fetch("""
                    SELECT
                        id,
                        question,
                        question_embedding,
                        frequency
                    FROM unclear_questions
                    WHERE id != $1
                        AND status != 'resolved'
                        AND question_embedding IS NOT NULL
                    ORDER BY frequency DESC
                    LIMIT 100
                """, unclear_question_id)

                best_pinyin_match = None
                best_pinyin_score = 0.0
                best_semantic_score = 0.0

                for candidate in pinyin_candidates:
                    # è¨ˆç®—æ‹¼éŸ³ç›¸ä¼¼åº¦
                    pinyin_sim = self._pinyin_similarity(question, candidate['question'])

                    # è¨ˆç®—èªç¾©ç›¸ä¼¼åº¦
                    # PostgreSQL pgvector è¿”å›çš„æ˜¯å­—ç¬¦ä¸²æ ¼å¼ "[0.1,0.2,...]"
                    if candidate['question_embedding'] is not None:
                        try:
                            # asyncpg è¿”å› pgvector ç‚ºå­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ
                            emb_str = candidate['question_embedding']
                            if isinstance(emb_str, str):
                                # ç§»é™¤é¦–å°¾çš„æ–¹æ‹¬è™Ÿä¸¦æŒ‰é€—è™Ÿåˆ†å‰²
                                candidate_emb = [float(x) for x in emb_str.strip('[]').split(',')]
                            elif isinstance(emb_str, (list, tuple)):
                                # å¦‚æœå·²ç¶“æ˜¯åˆ—è¡¨ï¼ˆæŸäº›æƒ…æ³ä¸‹å¯èƒ½ï¼‰
                                candidate_emb = [float(x) for x in emb_str]
                            else:
                                # ç„¡æ³•è­˜åˆ¥çš„æ ¼å¼ï¼Œè·³é
                                continue
                        except (TypeError, ValueError) as e:
                            # å¦‚æœè½‰æ›å¤±æ•—ï¼Œè·³éæ­¤å€™é¸é …
                            print(f"âš ï¸  å‘é‡è½‰æ›å¤±æ•— (ID: {candidate['id']}): {e}")
                            continue
                    else:
                        continue

                    semantic_sim = self._cosine_similarity(question_embedding, candidate_emb)

                    # æª¢æŸ¥æ˜¯å¦ç¬¦åˆæ‹¼éŸ³æª¢æ¸¬æ¢ä»¶ï¼š
                    # èªç¾©ç›¸ä¼¼åº¦åœ¨ 0.60-0.80 ä¹‹é–“ AND æ‹¼éŸ³ç›¸ä¼¼åº¦ >= é–¾å€¼
                    if (0.60 <= semantic_sim < semantic_similarity_threshold and
                        pinyin_sim >= pinyin_similarity_threshold):

                        if pinyin_sim > best_pinyin_score:
                            best_pinyin_match = candidate
                            best_pinyin_score = pinyin_sim
                            best_semantic_score = semantic_sim

                # å¦‚æœæ‰¾åˆ°æ‹¼éŸ³åŒ¹é…ï¼Œåˆä½µåˆ°è©²å•é¡Œ
                if best_pinyin_match:
                    print(f"ğŸ¯ æ‹¼éŸ³æª¢æ¸¬å‘½ä¸­ï¼")
                    print(f"   æ–°å•é¡Œ: {question}")
                    print(f"   åŒ¹é…å•é¡Œ: {best_pinyin_match['question']}")
                    print(f"   èªç¾©ç›¸ä¼¼åº¦: {best_semantic_score:.4f}")
                    print(f"   æ‹¼éŸ³ç›¸ä¼¼åº¦: {best_pinyin_score:.4f}")

                    # åˆªé™¤å‰›å»ºç«‹çš„æ–°å•é¡Œ
                    await conn.execute("""
                        DELETE FROM unclear_questions WHERE id = $1
                    """, unclear_question_id)

                    # æ›´æ–°åŒ¹é…å•é¡Œçš„é »ç‡
                    await conn.execute("""
                        UPDATE unclear_questions
                        SET frequency = frequency + 1,
                            last_asked_at = NOW()
                        WHERE id = $1
                    """, best_pinyin_match['id'])

                    # è¿”å›åŒ¹é…å•é¡Œçš„ ID
                    return best_pinyin_match['id']
                else:
                    print(f"âœ… è¨˜éŒ„æ–°çš„æœªé‡æ¸…å•é¡Œ (ID: {unclear_question_id}): {question}")
            elif matched_question == question:
                print(f"â™»ï¸  ç²¾ç¢ºåŒ¹é…å·²å­˜åœ¨å•é¡Œ (ID: {unclear_question_id}), é »ç‡: {frequency}")
            else:
                print(f"ğŸ”— èªç¾©/ç·¨è¼¯è·é›¢åŒ¹é…å·²å­˜åœ¨å•é¡Œ (ID: {unclear_question_id})")
                print(f"   æ–°å•é¡Œ: {question}")
                print(f"   ç›¸ä¼¼å•é¡Œ: {matched_question}")
                print(f"   ç›¸ä¼¼åº¦: {sim_score:.4f}, é »ç‡: {frequency}")

            return unclear_question_id

    async def _record_without_semantics(
        self,
        question: str,
        user_id: Optional[str] = None,
        intent_type: Optional[str] = None,
        similarity_score: Optional[float] = None,
        retrieved_docs: Optional[Dict] = None
    ) -> int:
        """
        ä¸ä½¿ç”¨èªç¾©ç›¸ä¼¼åº¦è¨˜éŒ„å•é¡Œï¼ˆå›é€€æ–¹æ¡ˆï¼‰

        åƒ…é€²è¡Œç²¾ç¢ºæ–‡å­—åŒ¹é…
        """
        async with self.db_pool.acquire() as conn:
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå•é¡Œ
            existing = await conn.fetchrow("""
                SELECT id, frequency
                FROM unclear_questions
                WHERE question = $1
                    AND status != 'resolved'
            """, question)

            if existing:
                # æ›´æ–°é »ç‡å’Œæœ€å¾Œè©¢å•æ™‚é–“
                await conn.execute("""
                    UPDATE unclear_questions
                    SET frequency = frequency + 1,
                        last_asked_at = CURRENT_TIMESTAMP
                    WHERE id = $1
                """, existing['id'])
                return existing['id']
            else:
                # å»ºç«‹æ–°è¨˜éŒ„
                # åºåˆ—åŒ– retrieved_docs ç‚º JSON å­—ç¬¦ä¸²
                retrieved_docs_json = json.dumps(retrieved_docs) if retrieved_docs else None

                # Use explicit column values to avoid ambiguity
                sim_score_value = similarity_score

                row = await conn.fetchrow("""
                    INSERT INTO unclear_questions (
                        question,
                        user_id,
                        intent_type,
                        similarity_score,
                        retrieved_docs,
                        status
                    ) VALUES ($1, $2, $3, $4::double precision, $5, 'pending')
                    RETURNING id
                """, question, user_id, intent_type, sim_score_value, retrieved_docs_json)
                return row['id']

    async def _get_embedding(self, text: str) -> Optional[List[float]]:
        """
        å‘¼å« Embedding API å°‡æ–‡å­—è½‰æ›ç‚ºå‘é‡

        Args:
            text: è¦è½‰æ›çš„æ–‡å­—

        Returns:
            å‘é‡åˆ—è¡¨ï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› None
        """
        # ä½¿ç”¨å…±ç”¨çš„ embedding å®¢æˆ¶ç«¯
        embedding = await self.embedding_client.get_embedding(text, verbose=False)

        if embedding:
            print(f"   âœ… ç²å¾—å•é¡Œå‘é‡: ç¶­åº¦ {len(embedding)}")

        return embedding

    def _pinyin_similarity(self, text1: str, text2: str) -> float:
        """
        è¨ˆç®—æ‹¼éŸ³ç›¸ä¼¼åº¦ï¼ˆç”¨æ–¼æª¢æ¸¬åš´é‡åŒéŸ³éŒ¯èª¤ï¼‰

        ä½¿ç”¨ Levenshtein è·é›¢æ¯”è¼ƒæ‹¼éŸ³å­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦

        Args:
            text1: ç¬¬ä¸€å€‹æ–‡å­—
            text2: ç¬¬äºŒå€‹æ–‡å­—

        Returns:
            æ‹¼éŸ³ç›¸ä¼¼åº¦åˆ†æ•¸ (0.0-1.0)
        """
        # è½‰æ›ç‚ºæ‹¼éŸ³ï¼ˆä¸å¸¶éŸ³èª¿ï¼‰
        pinyin1 = ''.join(lazy_pinyin(text1))
        pinyin2 = ''.join(lazy_pinyin(text2))

        # ä½¿ç”¨ç·¨è¼¯è·é›¢è¨ˆç®—ç›¸ä¼¼åº¦
        max_len = max(len(pinyin1), len(pinyin2))
        if max_len == 0:
            return 1.0

        # ç°¡å–®çš„ç·¨è¼¯è·é›¢å¯¦ç¾
        edit_dist = self._levenshtein_distance(pinyin1, pinyin2)

        # è½‰æ›ç‚ºç›¸ä¼¼åº¦åˆ†æ•¸ (0.0-1.0)
        similarity = 1.0 - (edit_dist / max_len)

        return similarity

    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """
        è¨ˆç®— Levenshtein ç·¨è¼¯è·é›¢

        Args:
            s1: ç¬¬ä¸€å€‹å­—ç¬¦ä¸²
            s2: ç¬¬äºŒå€‹å­—ç¬¦ä¸²

        Returns:
            ç·¨è¼¯è·é›¢
        """
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)

        if len(s2) == 0:
            return len(s1)

        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row

        return previous_row[-1]

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """
        è¨ˆç®—å…©å€‹å‘é‡çš„é¤˜å¼¦ç›¸ä¼¼åº¦

        Args:
            vec1: ç¬¬ä¸€å€‹å‘é‡
            vec2: ç¬¬äºŒå€‹å‘é‡

        Returns:
            é¤˜å¼¦ç›¸ä¼¼åº¦ (0.0-1.0)
        """
        import numpy as np

        # ç¢ºä¿å‘é‡æ˜¯ numpy é™£åˆ—
        try:
            v1 = np.array(vec1, dtype=float)
            v2 = np.array(vec2, dtype=float)
        except (TypeError, ValueError) as e:
            print(f"âš ï¸  å‘é‡è½‰æ›éŒ¯èª¤: {e}")
            print(f"   vec1 type: {type(vec1)}, vec2 type: {type(vec2)}")
            return 0.0

        # è¨ˆç®—é»ç©
        dot_product = np.dot(v1, v2)

        # è¨ˆç®—å‘é‡é•·åº¦
        norm1 = np.linalg.norm(v1)
        norm2 = np.linalg.norm(v2)

        # é¿å…é™¤ä»¥é›¶
        if norm1 == 0 or norm2 == 0:
            return 0.0

        return float(dot_product / (norm1 * norm2))

    async def get_unclear_questions(
        self,
        status: Optional[str] = None,
        limit: int = 50,
        offset: int = 0,
        order_by: str = "frequency"
    ) -> List[Dict]:
        """
        å–å¾—æœªé‡æ¸…å•é¡Œåˆ—è¡¨

        Args:
            status: ç‹€æ…‹ç¯©é¸ (pending/in_progress/resolved/ignored)
            limit: è¿”å›æ•¸é‡
            offset: åç§»é‡
            order_by: æ’åºæ¬„ä½ (frequency/last_asked_at/created_at)

        Returns:
            å•é¡Œåˆ—è¡¨
        """
        # é©—è­‰æ’åºæ¬„ä½
        valid_order_fields = ['frequency', 'last_asked_at', 'created_at']
        if order_by not in valid_order_fields:
            order_by = 'frequency'

        async with self.db_pool.acquire() as conn:
            query = f"""
                SELECT
                    id,
                    question,
                    user_id,
                    intent_type,
                    similarity_score,
                    retrieved_docs,
                    frequency,
                    first_asked_at,
                    last_asked_at,
                    status,
                    assigned_to,
                    resolved_at,
                    resolution_note,
                    suggested_answers,
                    created_at,
                    updated_at
                FROM unclear_questions
                WHERE ($1::text IS NULL OR status = $1)
                ORDER BY {order_by} DESC
                LIMIT $2 OFFSET $3
            """

            results = await conn.fetch(query, status, limit, offset)

        return [dict(row) for row in results]

    async def get_unclear_question_by_id(self, question_id: int) -> Optional[Dict]:
        """
        æ ¹æ“š ID å–å¾—æœªé‡æ¸…å•é¡Œ

        Args:
            question_id: å•é¡Œ ID

        Returns:
            å•é¡Œè³‡æ–™ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› None
        """
        async with self.db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT
                    id,
                    question,
                    user_id,
                    intent_type,
                    similarity_score,
                    retrieved_docs,
                    frequency,
                    first_asked_at,
                    last_asked_at,
                    status,
                    assigned_to,
                    resolved_at,
                    resolution_note,
                    suggested_answers,
                    created_at,
                    updated_at
                FROM unclear_questions
                WHERE id = $1
            """, question_id)

            return dict(row) if row else None

    async def update_unclear_question(
        self,
        question_id: int,
        status: Optional[str] = None,
        assigned_to: Optional[str] = None,
        resolution_note: Optional[str] = None,
        suggested_answers: Optional[List[str]] = None
    ) -> bool:
        """
        æ›´æ–°æœªé‡æ¸…å•é¡Œ

        Args:
            question_id: å•é¡Œ ID
            status: æ–°ç‹€æ…‹
            assigned_to: æŒ‡æ´¾çµ¦èª°
            resolution_note: è§£æ±ºèªªæ˜
            suggested_answers: å»ºè­°ç­”æ¡ˆ

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        updates = []
        params = []
        param_count = 1

        if status is not None:
            updates.append(f"status = ${param_count}")
            params.append(status)
            param_count += 1

            # å¦‚æœç‹€æ…‹æ”¹ç‚º resolvedï¼Œè¨­å®š resolved_at
            if status == 'resolved':
                updates.append(f"resolved_at = CURRENT_TIMESTAMP")

        if assigned_to is not None:
            updates.append(f"assigned_to = ${param_count}")
            params.append(assigned_to)
            param_count += 1

        if resolution_note is not None:
            updates.append(f"resolution_note = ${param_count}")
            params.append(resolution_note)
            param_count += 1

        if suggested_answers is not None:
            updates.append(f"suggested_answers = ${param_count}")
            params.append(suggested_answers)
            param_count += 1

        if not updates:
            return False

        updates.append("updated_at = CURRENT_TIMESTAMP")
        params.append(question_id)

        async with self.db_pool.acquire() as conn:
            query = f"""
                UPDATE unclear_questions
                SET {', '.join(updates)}
                WHERE id = ${param_count}
            """
            await conn.execute(query, *params)

        return True

    async def delete_unclear_question(self, question_id: int) -> bool:
        """
        åˆªé™¤æœªé‡æ¸…å•é¡Œ

        Args:
            question_id: å•é¡Œ ID

        Returns:
            æ˜¯å¦åˆªé™¤æˆåŠŸ
        """
        async with self.db_pool.acquire() as conn:
            result = await conn.execute("""
                DELETE FROM unclear_questions
                WHERE id = $1
            """, question_id)

            return result != "DELETE 0"

    async def get_stats(self) -> Dict:
        """
        å–å¾—çµ±è¨ˆè³‡è¨Š

        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸
        """
        async with self.db_pool.acquire() as conn:
            # ç‹€æ…‹çµ±è¨ˆ
            status_stats = await conn.fetch("""
                SELECT status, COUNT(*) as count
                FROM unclear_questions
                GROUP BY status
            """)

            stats = {
                "total": 0,
                "pending": 0,
                "in_progress": 0,
                "resolved": 0,
                "ignored": 0
            }

            for row in status_stats:
                stats[row['status']] = row['count']
                stats['total'] += row['count']

            # æœ€å¸¸è¦‹çš„å•é¡Œ (top 10)
            top_questions = await conn.fetch("""
                SELECT
                    id,
                    question,
                    frequency,
                    status,
                    last_asked_at
                FROM unclear_questions
                WHERE status != 'ignored'
                ORDER BY frequency DESC
                LIMIT 10
            """)

            stats['top_questions'] = [
                {
                    "id": row['id'],
                    "question": row['question'],
                    "frequency": row['frequency'],
                    "status": row['status'],
                    "last_asked_at": row['last_asked_at'].isoformat() if row['last_asked_at'] else None
                }
                for row in top_questions
            ]

            # å¹³å‡ç›¸ä¼¼åº¦åˆ†æ•¸
            avg_score = await conn.fetchval("""
                SELECT AVG(similarity_score)
                FROM unclear_questions
                WHERE similarity_score IS NOT NULL
            """)

            stats['avg_similarity_score'] = float(avg_score) if avg_score else 0.0

        return stats

    async def search_unclear_questions(
        self,
        keyword: str,
        limit: int = 20
    ) -> List[Dict]:
        """
        æœå°‹æœªé‡æ¸…å•é¡Œ

        Args:
            keyword: æœå°‹é—œéµå­—
            limit: è¿”å›æ•¸é‡

        Returns:
            æœå°‹çµæœ
        """
        async with self.db_pool.acquire() as conn:
            results = await conn.fetch("""
                SELECT
                    id,
                    question,
                    frequency,
                    status,
                    last_asked_at
                FROM unclear_questions
                WHERE question ILIKE $1
                ORDER BY frequency DESC
                LIMIT $2
            """, f"%{keyword}%", limit)

        return [dict(row) for row in results]


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    import asyncio
    import asyncpg
    import os

    async def test_unclear_question_manager():
        """æ¸¬è©¦æœªé‡æ¸…å•é¡Œç®¡ç†å™¨"""
        # å»ºç«‹è³‡æ–™åº«é€£æ¥
        pool = await asyncpg.create_pool(
            host=os.getenv("DB_HOST", "localhost"),
            port=int(os.getenv("DB_PORT", "5432")),
            database=os.getenv("DB_NAME", "aichatbot_admin"),
            user=os.getenv("DB_USER", "aichatbot"),
            password=os.getenv("DB_PASSWORD", "aichatbot_password"),
            min_size=2,
            max_size=10
        )

        manager = UnclearQuestionManager(pool)

        # æ¸¬è©¦è¨˜éŒ„æœªé‡æ¸…å•é¡Œ
        print("ğŸ“ è¨˜éŒ„æœªé‡æ¸…å•é¡Œ...")
        q_id = await manager.record_unclear_question(
            question="IOT é–€é–ä¸€ç›´å—¶å—¶å«æ€éº¼è¾¦ï¼Ÿ",
            user_id="user123",
            intent_type="unclear",
            similarity_score=0.65
        )
        print(f"   å•é¡Œ ID: {q_id}")

        # æ¸¬è©¦é‡è¤‡å•é¡Œï¼ˆæ‡‰è©²æ›´æ–°é »ç‡ï¼‰
        q_id2 = await manager.record_unclear_question(
            question="IOT é–€é–ä¸€ç›´å—¶å—¶å«æ€éº¼è¾¦ï¼Ÿ",
            user_id="user456",
            intent_type="unclear",
            similarity_score=0.63
        )
        print(f"   é‡è¤‡å•é¡Œ ID: {q_id2} (æ‡‰è©²èˆ‡ä¸Šé¢ç›¸åŒ)")

        # æŸ¥è©¢å•é¡Œ
        print("\nğŸ” æŸ¥è©¢æœªé‡æ¸…å•é¡Œ...")
        questions = await manager.get_unclear_questions(status="pending", limit=5)
        for q in questions:
            print(f"   - {q['question']} (é »ç‡: {q['frequency']})")

        # æ›´æ–°å•é¡Œç‹€æ…‹
        print("\nâœï¸ æ›´æ–°å•é¡Œç‹€æ…‹...")
        await manager.update_unclear_question(
            question_id=q_id,
            status="in_progress",
            assigned_to="admin",
            resolution_note="æ­£åœ¨è™•ç†ä¸­"
        )
        print("   ç‹€æ…‹å·²æ›´æ–°ç‚º in_progress")

        # å–å¾—çµ±è¨ˆ
        print("\nğŸ“Š çµ±è¨ˆè³‡è¨Š...")
        stats = await manager.get_stats()
        print(f"   ç¸½æ•¸: {stats['total']}")
        print(f"   å¾…è™•ç†: {stats['pending']}")
        print(f"   è™•ç†ä¸­: {stats['in_progress']}")
        print(f"   å·²è§£æ±º: {stats['resolved']}")
        print(f"   å¹³å‡ç›¸ä¼¼åº¦: {stats['avg_similarity_score']:.2f}")

        # é—œé–‰é€£æ¥æ± 
        await pool.close()

    # åŸ·è¡Œæ¸¬è©¦
    asyncio.run(test_unclear_question_manager())
