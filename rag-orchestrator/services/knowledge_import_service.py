"""
çŸ¥è­˜åŒ¯å…¥æœå‹™
çµ±ä¸€è™•ç†å„ç¨®æ ¼å¼çš„çŸ¥è­˜åŒ¯å…¥ï¼ŒåŒ…æ‹¬æª”æ¡ˆè§£æã€å‘é‡ç”Ÿæˆã€è³‡æ–™åº«å„²å­˜
"""
import os
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import pandas as pd
import asyncpg
from asyncpg.pool import Pool
from openai import AsyncOpenAI
import time


class KnowledgeImportService:
    """çŸ¥è­˜åŒ¯å…¥æœå‹™"""

    def __init__(self, db_pool: Pool):
        """
        åˆå§‹åŒ–çŸ¥è­˜åŒ¯å…¥æœå‹™

        Args:
            db_pool: è³‡æ–™åº«é€£æ¥æ± 
        """
        self.db_pool = db_pool
        self.openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.embedding_model = "text-embedding-3-small"
        self.llm_model = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")

        # è³ªé‡è©•ä¼°é…ç½®
        self.quality_evaluation_enabled = os.getenv("QUALITY_EVALUATION_ENABLED", "true").lower() == "true"
        self.quality_evaluation_threshold = int(os.getenv("QUALITY_EVALUATION_THRESHOLD", "6"))

    async def process_import_job(
        self,
        job_id: str,
        file_path: str,
        vendor_id: Optional[int],
        import_mode: str,
        enable_deduplication: bool,
        skip_review: bool = False,
        default_priority: int = 0,
        user_id: str = "admin"
    ) -> Dict:
        """
        è™•ç†çŸ¥è­˜åŒ¯å…¥ä½œæ¥­ï¼ˆä¸»è¦å…¥å£ï¼‰

        æ‰€æœ‰åŒ¯å…¥çš„çŸ¥è­˜éƒ½æœƒå…ˆé€²å…¥å¯©æ ¸ä½‡åˆ—ï¼Œ
        ç¶“éäººå·¥å¯©æ ¸é€šéå¾Œæ‰æœƒåŠ å…¥æ­£å¼çŸ¥è­˜åº«ã€‚

        Args:
            job_id: ä½œæ¥­ ID
            file_path: ä¸Šå‚³çš„æª”æ¡ˆè·¯å¾‘
            vendor_id: æ¥­è€… IDï¼ˆå¯é¸ï¼‰
            import_mode: åŒ¯å…¥æ¨¡å¼ï¼ˆappend/replace/mergeï¼‰
            enable_deduplication: æ˜¯å¦å•Ÿç”¨å»é‡
            skip_review: æ˜¯å¦è·³éå¯©æ ¸ç›´æ¥åŠ å…¥çŸ¥è­˜åº«
            user_id: åŸ·è¡Œè€… ID

        Returns:
            åŒ¯å…¥çµæœçµ±è¨ˆ
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ é–‹å§‹è™•ç†çŸ¥è­˜åŒ¯å…¥ä½œæ¥­")
        print(f"   ä½œæ¥­ ID: {job_id}")
        print(f"   æª”æ¡ˆ: {file_path}")
        print(f"   æ¥­è€…: {vendor_id or 'é€šç”¨çŸ¥è­˜'}")
        print(f"   æ¨¡å¼: {import_mode}")
        print(f"{'='*60}\n")

        try:
            # 1. æ›´æ–°ä½œæ¥­ç‹€æ…‹ç‚ºè™•ç†ä¸­
            await self.update_job_status(job_id, "processing", progress={"current": 0, "total": 100})

            # 2. åµæ¸¬æª”æ¡ˆé¡å‹ä¸¦é¸æ“‡è§£æå™¨
            file_type = self._detect_file_type(file_path)
            print(f"ğŸ“„ æª”æ¡ˆé¡å‹: {file_type}")

            # 3. è§£ææª”æ¡ˆ
            await self.update_job_status(job_id, "processing", progress={"current": 10, "total": 100, "stage": "è§£ææª”æ¡ˆ"})
            knowledge_list = await self._parse_file(file_path, file_type)

            if not knowledge_list:
                raise Exception("æœªèƒ½å¾æª”æ¡ˆä¸­æå–ä»»ä½•çŸ¥è­˜")

            print(f"âœ… è§£æå‡º {len(knowledge_list)} æ¢çŸ¥è­˜")

            # 4. é å…ˆå»é‡ï¼ˆæ–‡å­—å®Œå…¨ç›¸åŒï¼‰- åœ¨ LLM å‰åŸ·è¡Œï¼Œç¯€çœæˆæœ¬
            if enable_deduplication:
                await self.update_job_status(job_id, "processing", progress={"current": 20, "total": 100, "stage": "æ–‡å­—å»é‡"})
                original_count = len(knowledge_list)
                knowledge_list = await self._deduplicate_exact_match(knowledge_list)
                text_skipped = original_count - len(knowledge_list)
                print(f"ğŸ” æ–‡å­—å»é‡: è·³é {text_skipped} æ¢å®Œå…¨ç›¸åŒçš„é …ç›®ï¼Œå‰©é¤˜ {len(knowledge_list)} æ¢")

            # 5. ç”Ÿæˆå•é¡Œæ‘˜è¦ï¼ˆä½¿ç”¨ LLMï¼‰- åªè™•ç†å»é‡å¾Œçš„çŸ¥è­˜
            await self.update_job_status(job_id, "processing", progress={"current": 35, "total": 100, "stage": "ç”Ÿæˆå•é¡Œæ‘˜è¦"})
            await self._generate_question_summaries(knowledge_list)

            # 6. ç”Ÿæˆå‘é‡åµŒå…¥ - åªè™•ç†å»é‡å¾Œçš„çŸ¥è­˜
            await self.update_job_status(job_id, "processing", progress={"current": 55, "total": 100, "stage": "ç”Ÿæˆå‘é‡åµŒå…¥"})
            await self._generate_embeddings(knowledge_list)

            # 7. èªæ„å»é‡ï¼ˆä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦ï¼‰- äºŒæ¬¡éæ¿¾
            if enable_deduplication:
                await self.update_job_status(job_id, "processing", progress={"current": 70, "total": 100, "stage": "èªæ„å»é‡"})
                semantic_original = len(knowledge_list)
                knowledge_list = await self._deduplicate_by_similarity(knowledge_list)
                semantic_skipped = semantic_original - len(knowledge_list)
                print(f"ğŸ” èªæ„å»é‡: è·³é {semantic_skipped} æ¢èªæ„ç›¸ä¼¼çš„é …ç›®ï¼Œå‰©é¤˜ {len(knowledge_list)} æ¢")
                print(f"ğŸ“Š ç¸½è¨ˆè·³é: {text_skipped + semantic_skipped} æ¢ï¼ˆæ–‡å­—: {text_skipped}, èªæ„: {semantic_skipped}ï¼‰")

            # 8. æ¨è–¦æ„åœ–ï¼ˆä½¿ç”¨ LLM æˆ–åˆ†é¡å™¨ï¼‰
            await self.update_job_status(job_id, "processing", progress={"current": 76, "total": 100, "stage": "æ¨è–¦æ„åœ–"})
            await self._recommend_intents(knowledge_list)

            # 8.5. è³ªé‡è©•ä¼°ï¼ˆè‡ªå‹•ç¯©é¸ä½è³ªé‡çŸ¥è­˜ï¼‰
            await self.update_job_status(job_id, "processing", progress={"current": 77, "total": 100, "stage": "è³ªé‡è©•ä¼°"})
            await self._evaluate_quality(knowledge_list)

            # 9. å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°ï¼ˆéœ€æ±‚ 2ï¼šé‡å° B2C çŸ¥è­˜ï¼‰
            await self.update_job_status(job_id, "processing", progress={"current": 78, "total": 100, "stage": "å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°"})
            test_scenario_count = await self._create_test_scenario_suggestions(knowledge_list, vendor_id)

            # 10. æ ¹æ“š skip_review åƒæ•¸æ±ºå®šåŒ¯å…¥ç›®æ¨™
            if skip_review:
                # ç›´æ¥åŒ¯å…¥åˆ°æ­£å¼çŸ¥è­˜åº«
                await self.update_job_status(job_id, "processing", progress={"current": 85, "total": 100, "stage": "ç›´æ¥åŒ¯å…¥çŸ¥è­˜åº«"})
                result = await self._import_to_database(
                    knowledge_list,
                    vendor_id=vendor_id,
                    import_mode=import_mode,
                    default_priority=default_priority,
                    created_by=user_id
                )
                result['test_scenarios_created'] = test_scenario_count
                result['mode'] = 'direct'
            else:
                # åŒ¯å…¥åˆ°å¯©æ ¸ä½‡åˆ—ï¼ˆéœ€æ±‚ 3ï¼šæ‰€æœ‰çŸ¥è­˜éƒ½éœ€è¦å¯©æ ¸ï¼‰
                # çŸ¥è­˜æœƒå…ˆé€²å…¥ ai_generated_knowledge_candidates è¡¨
                # äººå·¥å¯©æ ¸é€šéå¾Œæ‰æœƒåŠ å…¥æ­£å¼çš„ knowledge_base è¡¨
                await self.update_job_status(job_id, "processing", progress={"current": 85, "total": 100, "stage": "åŒ¯å…¥å¯©æ ¸ä½‡åˆ—"})
                result = await self._import_to_review_queue(
                    knowledge_list,
                    vendor_id=vendor_id,
                    created_by=user_id
                )
                result['test_scenarios_created'] = test_scenario_count

            # 11. æ›´æ–°ä½œæ¥­ç‹€æ…‹ç‚ºå®Œæˆ
            await self.update_job_status(
                job_id,
                "completed",
                progress={"current": 100, "total": 100},
                result=result
            )

            print(f"\n{'='*60}")
            if skip_review:
                print(f"âœ… åŒ¯å…¥å®Œæˆï¼ˆå·²ç›´æ¥åŠ å…¥æ­£å¼çŸ¥è­˜åº«ï¼‰")
            else:
                print(f"âœ… åŒ¯å…¥å®Œæˆï¼ˆå·²é€²å…¥å¯©æ ¸ä½‡åˆ—ï¼‰")
            print(f"   åŒ¯å…¥çŸ¥è­˜: {result['imported']} æ¢")
            print(f"   è·³é: {result.get('skipped', 0)} æ¢")
            print(f"   éŒ¯èª¤: {result.get('errors', 0)} æ¢")
            if result.get('test_scenarios_created', 0) > 0:
                print(f"   æ¸¬è©¦æƒ…å¢ƒå»ºè­°: {result['test_scenarios_created']} å€‹")
            if not skip_review:
                print(f"   âš ï¸  æ‰€æœ‰çŸ¥è­˜éœ€ç¶“äººå·¥å¯©æ ¸å¾Œæ‰æœƒæ­£å¼åŠ å…¥çŸ¥è­˜åº«")
            print(f"{'='*60}\n")

            return result

        except Exception as e:
            # æ›´æ–°ä½œæ¥­ç‹€æ…‹ç‚ºå¤±æ•—
            error_message = str(e)
            print(f"\nâŒ åŒ¯å…¥å¤±æ•—: {error_message}")
            await self.update_job_status(
                job_id,
                "failed",
                error=error_message
            )
            raise

    def _detect_file_type(self, file_path: str) -> str:
        """
        åµæ¸¬æª”æ¡ˆé¡å‹

        Args:
            file_path: æª”æ¡ˆè·¯å¾‘

        Returns:
            æª”æ¡ˆé¡å‹ï¼ˆexcel, csv, pdf, txt, jsonï¼‰
        """
        suffix = Path(file_path).suffix.lower()

        if suffix in ['.xlsx', '.xls']:
            return 'excel'
        elif suffix == '.csv':
            return 'csv'
        elif suffix == '.pdf':
            return 'pdf'
        elif suffix == '.txt':
            return 'txt'
        elif suffix == '.json':
            return 'json'
        else:
            return 'unknown'

    def _clean_html(self, html_text: str) -> str:
        """
        æ¸…ç† HTML æ¨™ç±¤ï¼Œä¿ç•™æ–‡å­—å…§å®¹ä¸¦ç¶­æŒé©ç•¶æ ¼å¼

        ä½¿ç”¨ BeautifulSoup é€²è¡Œæ™ºèƒ½ HTML æ¸…ç†ï¼š
        - ç§»é™¤æ‰€æœ‰ style å±¬æ€§
        - ç§»é™¤ script å’Œ style æ¨™ç±¤
        - ä¿ç•™åŸºæœ¬æ®µè½çµæ§‹ï¼ˆ<p>ã€<br> è½‰æ›ç‚ºæ›è¡Œï¼‰
        - ä¿ç•™åˆ—è¡¨çµæ§‹ï¼ˆ<li> æ·»åŠ é …ç›®ç¬¦è™Ÿï¼‰
        - ç§»é™¤æ‰€æœ‰å…¶ä»– HTML æ¨™ç±¤
        - æ¸…ç†å¤šé¤˜ç©ºç™½

        Args:
            html_text: åŒ…å« HTML æ¨™ç±¤çš„æ–‡å­—

        Returns:
            æ¸…ç†å¾Œçš„ç´”æ–‡å­—
        """
        # å¦‚æœä¸åŒ…å« HTML æ¨™ç±¤ï¼Œç›´æ¥è¿”å›
        if '<' not in html_text or '>' not in html_text:
            return html_text

        try:
            from bs4 import BeautifulSoup

            # è§£æ HTML
            soup = BeautifulSoup(html_text, 'lxml')

            # ç§»é™¤ script å’Œ style æ¨™ç±¤
            for tag in soup(['script', 'style']):
                tag.decompose()

            # ç§»é™¤æ‰€æœ‰ style å±¬æ€§
            for tag in soup.find_all(True):
                if 'style' in tag.attrs:
                    del tag.attrs['style']

            # è™•ç†æ®µè½å’Œæ›è¡Œ
            for p in soup.find_all('p'):
                p.insert_after(soup.new_string('\n\n'))

            for br in soup.find_all('br'):
                br.replace_with(soup.new_string('\n'))

            # è™•ç†åˆ—è¡¨é …ç›®
            for li in soup.find_all('li'):
                li.insert_before(soup.new_string('â€¢ '))
                li.insert_after(soup.new_string('\n'))

            # æå–ç´”æ–‡å­—
            text = soup.get_text()

            # æ¸…ç†å¤šé¤˜ç©ºç™½
            import re
            # ç§»é™¤æ¯è¡Œå‰å¾Œçš„ç©ºç™½
            lines = [line.strip() for line in text.split('\n')]
            # ç§»é™¤ç©ºè¡Œï¼ˆä½†ä¿ç•™å–®å€‹æ›è¡Œï¼‰
            text = '\n'.join(lines)
            # å°‡é€£çºŒ 3 å€‹ä»¥ä¸Šçš„æ›è¡Œç¬¦ç¸®æ¸›ç‚º 2 å€‹
            text = re.sub(r'\n{3,}', '\n\n', text)

            return text.strip()

        except Exception as e:
            print(f"   âš ï¸  HTML æ¸…ç†å¤±æ•—: {str(e)}ï¼Œä½¿ç”¨åŸå§‹æ–‡å­—")
            return html_text

    async def _parse_file(self, file_path: str, file_type: str) -> List[Dict]:
        """
        è§£ææª”æ¡ˆ

        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            file_type: æª”æ¡ˆé¡å‹

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        if file_type == 'excel':
            return await self._parse_excel(file_path)
        elif file_type == 'csv':
            return await self._parse_csv(file_path)
        elif file_type == 'txt':
            return await self._parse_txt(file_path)
        elif file_type == 'json':
            return await self._parse_json(file_path)
        elif file_type == 'pdf':
            return await self._parse_pdf(file_path)
        else:
            raise Exception(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {file_type}")

    async def _parse_excel(self, file_path: str) -> List[Dict]:
        """
        è§£æ Excel æª”æ¡ˆ

        æ”¯æ´æ ¼å¼ï¼š
        - æ¬„ä½: å•é¡Œ / question / å•é¡Œæ‘˜è¦
        - æ¬„ä½: ç­”æ¡ˆ / answer / å›è¦†
        - æ¬„ä½: åˆ†é¡ / category (å¯é¸)
        - æ¬„ä½: å°è±¡ / audience (å¯é¸)
        - æ¬„ä½: é—œéµå­— / keywords (å¯é¸)

        Args:
            file_path: Excel æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ Excel æª”æ¡ˆ: {file_path}")

        df = pd.read_excel(file_path, engine='openpyxl')
        print(f"   è®€å– {len(df)} è¡Œè³‡æ–™")
        print(f"   æ¬„ä½: {list(df.columns)}")

        # æ¬„ä½æ˜ å°„ï¼ˆæ”¯æ´å¤šç¨®æ¬„ä½åç¨±ï¼‰
        question_cols = ['å•é¡Œ', 'question', 'å•é¡Œæ‘˜è¦', 'question_summary', 'title', 'æ¨™é¡Œ']
        answer_cols = ['ç­”æ¡ˆ', 'answer', 'å›è¦†', 'response', 'content', 'å…§å®¹']
        category_cols = ['åˆ†é¡', 'category', 'é¡åˆ¥', 'type']
        audience_cols = ['å°è±¡', 'audience', 'å—çœ¾']
        keywords_cols = ['é—œéµå­—', 'keywords', 'æ¨™ç±¤', 'tags']

        # æ‰¾åˆ°å°æ‡‰çš„æ¬„ä½
        question_col = next((col for col in df.columns if col in question_cols), None)
        answer_col = next((col for col in df.columns if col in answer_cols), None)
        category_col = next((col for col in df.columns if col in category_cols), None)
        audience_col = next((col for col in df.columns if col in audience_cols), None)
        keywords_col = next((col for col in df.columns if col in keywords_cols), None)

        if not answer_col:
            raise Exception(f"æ‰¾ä¸åˆ°ç­”æ¡ˆæ¬„ä½ã€‚æ”¯æ´çš„æ¬„ä½åç¨±: {', '.join(answer_cols)}")

        knowledge_list = []
        current_category = None

        for idx, row in df.iterrows():
            # å¦‚æœæœ‰åˆ†é¡æ¬„ä½ä¸”è©²è¡Œæœ‰å€¼ï¼Œæ›´æ–°ç•¶å‰åˆ†é¡
            if category_col and pd.notna(row[category_col]):
                potential_category = str(row[category_col]).strip()
                # éæ¿¾æ‰éåˆ†é¡çš„æè¿°æ€§æ–‡å­—
                if potential_category and len(potential_category) < 50:
                    current_category = potential_category

            # è§£æç­”æ¡ˆï¼ˆå¿…å¡«ï¼‰
            answer = row.get(answer_col)
            if pd.isna(answer) or not str(answer).strip() or len(str(answer).strip()) < 10:
                continue

            answer = str(answer).strip()

            # HTML æ¸…ç†ï¼ˆä½¿ç”¨ BeautifulSoupï¼‰
            answer = self._clean_html(answer)

            # è§£æå•é¡Œï¼ˆå¯é¸ï¼Œå¦‚æœæ²’æœ‰æœƒç”¨ LLM ç”Ÿæˆï¼‰
            question = None
            if question_col and pd.notna(row[question_col]):
                question = str(row[question_col]).strip()

            # è§£æå°è±¡
            audience = 'ç§Ÿå®¢'  # é è¨­
            if audience_col and pd.notna(row[audience_col]):
                audience = str(row[audience_col]).strip()

            # è§£æé—œéµå­—
            keywords = []
            if keywords_col and pd.notna(row[keywords_col]):
                keywords_str = str(row[keywords_col])
                keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]

            knowledge_list.append({
                'question_summary': question,  # å¯èƒ½ç‚º Noneï¼Œå¾ŒçºŒç”¨ LLM ç”Ÿæˆ
                'answer': answer,
                'category': current_category or 'ä¸€èˆ¬å•é¡Œ',
                'audience': audience,
                'keywords': keywords,
                'source_file': Path(file_path).name
            })

        print(f"   âœ… è§£æå‡º {len(knowledge_list)} å€‹æœ‰æ•ˆçŸ¥è­˜é …ç›®")
        return knowledge_list

    async def _parse_csv(self, file_path: str) -> List[Dict]:
        """
        è§£æ CSV æª”æ¡ˆï¼ˆåŠ å¼·ç‰ˆï¼šæ”¯æ´ JSON æ¬„ä½æ ¼å¼ï¼‰

        æ”¯æ´æ ¼å¼ï¼š
        1. æ¨™æº– CSV æ ¼å¼ï¼š
           - æ¬„ä½: å•é¡Œ / question / å•é¡Œæ‘˜è¦ / title
           - æ¬„ä½: ç­”æ¡ˆ / answer / å›è¦† / content
           - æ¬„ä½: åˆ†é¡ / category (å¯é¸)
           - æ¬„ä½: å°è±¡ / audience (å¯é¸)
           - æ¬„ä½: é—œéµå­— / keywords (å¯é¸)

        2. JSON æ¬„ä½æ ¼å¼ï¼ˆå¦‚ help_datas.csvï¼‰ï¼š
           - æ¬„ä½å€¼ç‚º JSON å­—ä¸²ï¼Œè‡ªå‹•æå– zh-TW èªç³»
           - ä¾‹å¦‚: {"zh-TW":"ç‰©ä»¶","en-US":"Property"}

        Args:
            file_path: CSV æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ CSV æª”æ¡ˆ: {file_path}")

        # è®€å– CSVï¼Œpandas æœƒè‡ªå‹•è™•ç†ç·¨ç¢¼
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
        except UnicodeDecodeError:
            # å¦‚æœ UTF-8 å¤±æ•—ï¼Œå˜—è©¦å…¶ä»–ç·¨ç¢¼
            df = pd.read_csv(file_path, encoding='utf-8-sig')

        print(f"   è®€å– {len(df)} è¡Œè³‡æ–™")
        print(f"   æ¬„ä½: {list(df.columns)}")

        # æ¬„ä½æ˜ å°„ï¼ˆæ”¯æ´å¤šç¨®æ¬„ä½åç¨±ï¼‰
        question_cols = ['å•é¡Œ', 'question', 'å•é¡Œæ‘˜è¦', 'question_summary', 'title', 'æ¨™é¡Œ']
        answer_cols = ['ç­”æ¡ˆ', 'answer', 'å›è¦†', 'response', 'content', 'å…§å®¹']
        category_cols = ['åˆ†é¡', 'category', 'é¡åˆ¥', 'type']
        audience_cols = ['å°è±¡', 'audience', 'å—çœ¾', 'target_user']
        keywords_cols = ['é—œéµå­—', 'keywords', 'æ¨™ç±¤', 'tags']
        intent_id_cols = ['æ„åœ–ID', 'intent_id', 'intent', 'æ„åœ–']

        # æ‰¾åˆ°å°æ‡‰çš„æ¬„ä½
        question_col = next((col for col in df.columns if col in question_cols), None)
        answer_col = next((col for col in df.columns if col in answer_cols), None)
        category_col = next((col for col in df.columns if col in category_cols), None)
        audience_col = next((col for col in df.columns if col in audience_cols), None)
        keywords_col = next((col for col in df.columns if col in keywords_cols), None)
        intent_id_col = next((col for col in df.columns if col in intent_id_cols), None)

        # å¦‚æœæ‰¾ä¸åˆ°æ¨™æº–æ¬„ä½åç¨±ï¼Œå˜—è©¦ä½¿ç”¨ä½ç½®æ¨æ¸¬
        # help_datas.csv æ ¼å¼: title, title.1, content (åˆ†é¡, å•é¡Œ, ç­”æ¡ˆ)
        if not answer_col and len(df.columns) >= 3:
            # æª¢æŸ¥æ˜¯å¦ç‚º help_datas.csv æ ¼å¼ï¼ˆç¬¬ä¸‰æ¬„é€šå¸¸æ˜¯ç­”æ¡ˆï¼‰
            if 'content' in df.columns:
                category_col = df.columns[0]  # ç¬¬ä¸€æ¬„ï¼šåˆ†é¡
                question_col = df.columns[1]  # ç¬¬äºŒæ¬„ï¼šå•é¡Œ
                answer_col = 'content'        # ç¬¬ä¸‰æ¬„ï¼šç­”æ¡ˆ
                print(f"   åµæ¸¬åˆ°ç‰¹æ®Šæ ¼å¼ CSVï¼Œä½¿ç”¨æ¬„ä½: {category_col}, {question_col}, {answer_col}")

        if not answer_col:
            raise Exception(f"æ‰¾ä¸åˆ°ç­”æ¡ˆæ¬„ä½ã€‚æ”¯æ´çš„æ¬„ä½åç¨±: {', '.join(answer_cols)}\nå¯¦éš›æ¬„ä½: {list(df.columns)}")

        knowledge_list = []
        current_category = None

        for idx, row in df.iterrows():
            try:
                # === 1. è§£æåˆ†é¡ï¼ˆæ”¯æ´ JSON æ ¼å¼ï¼‰ ===
                category = None
                if category_col and pd.notna(row[category_col]):
                    cat_value = str(row[category_col]).strip()
                    # æª¢æŸ¥æ˜¯å¦ç‚º JSON æ ¼å¼
                    if cat_value.startswith('{') and cat_value.endswith('}'):
                        try:
                            cat_json = json.loads(cat_value)
                            category = cat_json.get('zh-TW', cat_json.get('zh-tw', cat_value))
                        except json.JSONDecodeError:
                            category = cat_value
                    else:
                        category = cat_value

                    # éæ¿¾æ‰éåˆ†é¡çš„æè¿°æ€§æ–‡å­—
                    if category and len(category) < 50:
                        current_category = category

                # === 2. è§£æå•é¡Œï¼ˆæ”¯æ´ JSON æ ¼å¼ï¼‰ ===
                question = None
                if question_col and pd.notna(row[question_col]):
                    q_value = str(row[question_col]).strip()
                    # æª¢æŸ¥æ˜¯å¦ç‚º JSON æ ¼å¼
                    if q_value.startswith('{') and q_value.endswith('}'):
                        try:
                            q_json = json.loads(q_value)
                            question = q_json.get('zh-TW', q_json.get('zh-tw'))
                        except json.JSONDecodeError:
                            question = q_value
                    else:
                        question = q_value

                # === 3. è§£æç­”æ¡ˆï¼ˆæ”¯æ´ JSON æ ¼å¼ï¼‰ ===
                answer = None
                if pd.notna(row[answer_col]):
                    a_value = str(row[answer_col]).strip()
                    # æª¢æŸ¥æ˜¯å¦ç‚º JSON æ ¼å¼
                    if a_value.startswith('{') and a_value.endswith('}'):
                        try:
                            a_json = json.loads(a_value)
                            answer = a_json.get('zh-TW', a_json.get('zh-tw'))
                        except json.JSONDecodeError:
                            answer = a_value
                    else:
                        answer = a_value

                # é©—è­‰ç­”æ¡ˆæœ‰æ•ˆæ€§
                if not answer or len(answer.strip()) < 10:
                    continue

                answer = answer.strip()

                # === 4. HTML æ¸…ç†ï¼ˆä½¿ç”¨ BeautifulSoupï¼‰ ===
                answer = self._clean_html(answer)

                # === 5. è§£æå°è±¡ ===
                audience = 'ç§Ÿå®¢'  # é è¨­
                if audience_col and pd.notna(row[audience_col]):
                    audience = str(row[audience_col]).strip()

                # === 6. è§£æé—œéµå­— ===
                keywords = []
                if keywords_col and pd.notna(row[keywords_col]):
                    keywords_str = str(row[keywords_col])
                    keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]

                # === 7. è§£ææ„åœ– ID ===
                intent_id = None
                if intent_id_col and pd.notna(row[intent_id_col]):
                    try:
                        intent_id_value = row[intent_id_col]
                        # è™•ç†ä¸åŒé¡å‹çš„å€¼
                        if isinstance(intent_id_value, (int, float)):
                            intent_id = int(intent_id_value)
                        elif isinstance(intent_id_value, str):
                            intent_id_value = intent_id_value.strip()
                            if intent_id_value.isdigit():
                                intent_id = int(intent_id_value)
                    except (ValueError, TypeError):
                        print(f"   âš ï¸  ç¬¬ {idx + 1} è¡Œæ„åœ– ID æ ¼å¼éŒ¯èª¤: {row[intent_id_col]}")

                # === 8. å»ºç«‹çŸ¥è­˜é …ç›® ===
                knowledge_list.append({
                    'question_summary': question,  # å¯èƒ½ç‚º Noneï¼Œå¾ŒçºŒç”¨ LLM ç”Ÿæˆ
                    'answer': answer,
                    'category': current_category or 'ä¸€èˆ¬å•é¡Œ',
                    'audience': audience,
                    'keywords': keywords,
                    'intent_id': intent_id,  # é è¨­æ„åœ– IDï¼ˆå¯èƒ½ç‚º Noneï¼‰
                    'source_file': Path(file_path).name
                })

            except Exception as e:
                print(f"   âš ï¸  ç¬¬ {idx + 1} è¡Œè§£æå¤±æ•—: {str(e)}")
                continue

        print(f"   âœ… è§£æå‡º {len(knowledge_list)} å€‹æœ‰æ•ˆçŸ¥è­˜é …ç›®")
        return knowledge_list

    async def _parse_txt(self, file_path: str) -> List[Dict]:
        """
        è§£æç´”æ–‡å­—æª”æ¡ˆï¼ˆä½¿ç”¨ LLM æå–çŸ¥è­˜ï¼‰

        Args:
            file_path: æ–‡å­—æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ TXT æª”æ¡ˆ: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        if len(content) < 50:
            raise Exception("æª”æ¡ˆå…§å®¹éçŸ­ï¼Œç„¡æ³•æå–çŸ¥è­˜")

        # ä½¿ç”¨ LLM æå–çŸ¥è­˜
        print("ğŸ¤– ä½¿ç”¨ LLM æå–çŸ¥è­˜...")

        system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åº«åˆ†æå¸«ã€‚
å¾æä¾›çš„æ–‡å­—å…§å®¹ä¸­æå–å®¢æœå•ç­”çŸ¥è­˜ã€‚

âš ï¸ é‡è¦ï¼šæå–çš„çŸ¥è­˜å¿…é ˆæ˜¯ã€Œé€šç”¨ã€çš„ã€å¯é‡è¤‡ä½¿ç”¨çš„çŸ¥è­˜ã€‚

è«‹éµå¾ªä»¥ä¸‹æ³›åŒ–è¦å‰‡ï¼š
1. ç§»é™¤ç‰¹å®šç‰©æ¥­/å»ºç‰©åç¨±ï¼ˆå¦‚ï¼šä¸‰è‘‰å¯“æ‰€ â†’ è©²ç‰©æ¥­/ç§Ÿè™•/å»ºç‰©ï¼‰
2. ç§»é™¤ç‰¹å®šæˆ¿è™Ÿ/å–®ä½è™Ÿç¢¼ï¼ˆå¦‚ï¼š2B5ã€5A2 â†’ è©²æˆ¿é–“/è©²å–®ä½/è©²ç§Ÿè™•ï¼‰
3. ç§»é™¤ç‰¹å®šæ—¥æœŸï¼ˆå¦‚ï¼š113/12/31 â†’ åˆ°æœŸæ—¥/æŒ‡å®šæ—¥æœŸï¼‰
4. ç§»é™¤å€‹äººå§“åã€é›»è©±ã€è¯çµ¡æ–¹å¼ç­‰ç§äººè³‡è¨Š
5. **å…¬å¸åç¨±æ³›åŒ–**ï¼šå°‡ç‰¹å®šå…¬å¸åç¨±ï¼ˆå¦‚ï¼šèˆˆä¸­è³‡ç”¢ã€XXç®¡ç†å…¬å¸ï¼‰æ”¹ç‚ºã€Œç‰©æ¥­ç®¡ç†å…¬å¸ã€
6. ä¿ç•™è™•ç†æµç¨‹ã€è¦å‰‡ã€æ”¿ç­–ã€æ³¨æ„äº‹é …ç­‰é€šç”¨çŸ¥è­˜
7. å¦‚æœæŸæ¢çŸ¥è­˜éæ–¼ç‰¹å®šï¼ˆå¦‚ï¼šåƒ…é©ç”¨æ–¼æŸå€‹æˆ¿é–“çš„ç‰¹æ®Šè¨­å‚™ï¼‰ï¼Œè«‹åœ¨ warnings ä¸­è¨»æ˜

æ³›åŒ–ç¯„ä¾‹ï¼š
âŒ åŸæ–‡ï¼šã€Œä¸‰è‘‰å¯“æ‰€-2B5æœ‰ä½é›»åº¦è­¦å ±ï¼Œè‹¥é è¨ˆå¯ç”¨é›»åº¦æ­¸é›¶å°‡æœƒæ–·é›»ï¼Œç…©è«‹ç®¡ç†å¸«å†è¯ç¹«æé†’ç§Ÿå®¢ç›¡å¿«é€²è¡Œé›»éŒ¶å„²å€¼ã€‚ã€
âœ… æ³›åŒ–ï¼šã€Œç•¶ç§Ÿè™•å‡ºç¾ä½é›»åº¦è­¦å ±æ™‚ï¼Œè‹¥é è¨ˆå¯ç”¨é›»åº¦æ­¸é›¶å°‡æœƒæ–·é›»ï¼Œè«‹ç®¡ç†å¸«è¯ç¹«ç§Ÿå®¢ç›¡å¿«é€²è¡Œé›»éŒ¶å„²å€¼ã€‚ã€
âœ… warningsï¼š["åŸæ–‡åŒ…å«ç‰¹å®šç‰©æ¥­åç¨±å’Œæˆ¿è™Ÿ"]

âŒ åŸæ–‡ï¼šã€Œæˆ¿æ±éœ€è¦å°‡ç®¡ç†è²»æ”¯ä»˜çµ¦èˆˆä¸­è³‡ç”¢å…¬å¸ã€‚ã€
âœ… æ³›åŒ–ï¼šã€Œæˆ¿æ±éœ€è¦å°‡ç®¡ç†è²»æ”¯ä»˜çµ¦ç‰©æ¥­ç®¡ç†å…¬å¸ã€‚ã€
âœ… warningsï¼š["å·²å°‡ç‰¹å®šå…¬å¸åç¨±æ³›åŒ–ç‚ºç‰©æ¥­ç®¡ç†å…¬å¸"]

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼š
{
  "knowledge_list": [
    {
      "question_summary": "å•é¡Œæ‘˜è¦ï¼ˆ15å­—ä»¥å…§ï¼‰",
      "answer": "å®Œæ•´ç­”æ¡ˆï¼ˆå·²æ³›åŒ–ï¼‰",
      "category": "åˆ†é¡ï¼ˆå¦‚ï¼šå¸³å‹™å•é¡Œã€è¨­æ–½ä½¿ç”¨ã€åˆç´„å•é¡Œç­‰ï¼‰",
      "audience": "ç§Ÿå®¢|æˆ¿æ±|ç®¡ç†å¸«",
      "keywords": ["é—œéµå­—1", "é—œéµå­—2"],
      "warnings": ["è­¦å‘Šè¨Šæ¯ï¼ˆå¦‚æœæœ‰ç‰¹å®šå…§å®¹è¢«æ³›åŒ–æˆ–ç„¡æ³•æ³›åŒ–ï¼‰"]
    }
  ]
}

æ³¨æ„ï¼š
- åªæå–æ¸…æ™°ã€å®Œæ•´ã€å¯æ³›åŒ–çš„çŸ¥è­˜
- å¦‚æœæŸæ¢è³‡è¨Šéæ–¼ç‰¹å®šï¼ˆå¦‚ï¼šé€šçŸ¥æŸäººæŸäº‹ï¼‰ï¼Œä¸è¦æå–
- å•é¡Œæ‘˜è¦è¦ç°¡æ½”ï¼ˆ15å­—ä»¥å…§ï¼‰
- ç­”æ¡ˆè¦å®Œæ•´ä¸”å¯¦ç”¨
- warnings ç‚ºé¸å¡«ï¼Œæ²’æœ‰è­¦å‘Šå¯çœç•¥
"""

        try:
            response = await self.openai_client.chat.completions.create(
                model=self.llm_model,
                temperature=0.3,
                max_tokens=2000,  # æå–çŸ¥è­˜åˆ—è¡¨éœ€è¦è¼ƒé•·è¼¸å‡ºï¼ˆå¤šå€‹ Q&A çš„ JSONï¼‰
                response_format={"type": "json_object"},
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è«‹å¾ä»¥ä¸‹å…§å®¹æå–çŸ¥è­˜ï¼š\n\n{content[:4000]}"}
                ]
            )

            result = json.loads(response.choices[0].message.content)
            knowledge_list = result.get('knowledge_list', [])

            # æ·»åŠ ä¾†æºè³‡è¨Šä¸¦æª¢æŸ¥æ³›åŒ–è­¦å‘Š
            generalized_count = 0
            for knowledge in knowledge_list:
                knowledge['source_file'] = Path(file_path).name

                # çµ±è¨ˆæœ‰æ³›åŒ–è­¦å‘Šçš„çŸ¥è­˜
                if knowledge.get('warnings'):
                    generalized_count += 1
                    print(f"   âš ï¸  æ³›åŒ–è­¦å‘Š: {knowledge['question_summary'][:30]}... - {knowledge['warnings']}")

            print(f"   âœ… æå–å‡º {len(knowledge_list)} å€‹çŸ¥è­˜é …ç›®")
            if generalized_count > 0:
                print(f"   ğŸ”„ å…¶ä¸­ {generalized_count} æ¢çŸ¥è­˜å·²è‡ªå‹•æ³›åŒ–ï¼ˆç§»é™¤ç‰¹å®šç‰©æ¥­/æˆ¿è™Ÿ/æ—¥æœŸï¼‰")
            return knowledge_list

        except Exception as e:
            print(f"   âš ï¸ LLM æå–å¤±æ•—: {e}")
            raise Exception(f"ç„¡æ³•å¾æ–‡å­—æª”æ¡ˆæå–çŸ¥è­˜: {e}")

    async def _parse_json(self, file_path: str) -> List[Dict]:
        """
        è§£æ JSON æª”æ¡ˆ

        é æœŸæ ¼å¼ï¼š
        {
          "knowledge": [
            {
              "question": "å•é¡Œ",
              "answer": "ç­”æ¡ˆ",
              "category": "åˆ†é¡",
              "audience": "å°è±¡",
              "keywords": ["é—œéµå­—"]
            }
          ]
        }

        Args:
            file_path: JSON æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ JSON æª”æ¡ˆ: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # æ”¯æ´å¤šç¨®æ ¼å¼
        if 'knowledge' in data:
            raw_list = data['knowledge']
        elif 'knowledge_list' in data:
            raw_list = data['knowledge_list']
        elif isinstance(data, list):
            raw_list = data
        else:
            raise Exception("ç„¡æ³•è­˜åˆ¥ JSON æ ¼å¼ã€‚é æœŸåŒ…å« 'knowledge' æˆ– 'knowledge_list' æ¬„ä½")

        knowledge_list = []
        for item in raw_list:
            # æ¬„ä½æ˜ å°„
            question = item.get('question') or item.get('question_summary') or item.get('title')
            answer = item.get('answer') or item.get('response') or item.get('content')

            if not answer or len(str(answer).strip()) < 10:
                continue

            knowledge_list.append({
                'question_summary': question,
                'answer': str(answer).strip(),
                'category': item.get('category', 'ä¸€èˆ¬å•é¡Œ'),
                'audience': item.get('audience', 'ç§Ÿå®¢'),
                'keywords': item.get('keywords', []),
                'source_file': Path(file_path).name
            })

        print(f"   âœ… è§£æå‡º {len(knowledge_list)} å€‹çŸ¥è­˜é …ç›®")
        return knowledge_list

    async def _parse_pdf(self, file_path: str) -> List[Dict]:
        """
        è§£æ PDF æª”æ¡ˆ

        Args:
            file_path: PDF æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        # TODO: å¯¦ä½œ PDF è§£æï¼ˆéœ€è¦å®‰è£ PyPDF2 æˆ– pdfplumberï¼‰
        raise Exception("PDF æ ¼å¼æš«ä¸æ”¯æ´ï¼Œè«‹å…ˆè½‰æ›ç‚º Excel æˆ– TXT")

    async def _generate_question_summaries(self, knowledge_list: List[Dict]):
        """
        ç‚ºæ²’æœ‰å•é¡Œæ‘˜è¦çš„çŸ¥è­˜ç”Ÿæˆå•é¡Œ

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
        """
        need_generation = [k for k in knowledge_list if not k.get('question_summary')]

        if not need_generation:
            print("âœ… æ‰€æœ‰çŸ¥è­˜éƒ½å·²æœ‰å•é¡Œæ‘˜è¦")
            return

        print(f"ğŸ¤– ç‚º {len(need_generation)} æ¢çŸ¥è­˜ç”Ÿæˆå•é¡Œæ‘˜è¦...")

        for knowledge in need_generation:
            try:
                prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ç­”æ¡ˆï¼Œç”Ÿæˆä¸€å€‹ç°¡æ½”çš„å•é¡Œæ‘˜è¦ï¼ˆ15å­—ä»¥å…§ï¼‰ã€‚

åˆ†é¡ï¼š{knowledge['category']}
ç­”æ¡ˆï¼š{knowledge['answer'][:200]}

åªè¼¸å‡ºå•é¡Œæ‘˜è¦ï¼Œä¸è¦åŠ å…¶ä»–èªªæ˜ã€‚"""

                response = await self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    temperature=0.3,
                    max_tokens=50,
                    messages=[{"role": "user", "content": prompt}]
                )

                question_summary = response.choices[0].message.content.strip()
                knowledge['question_summary'] = question_summary

                # é¿å… rate limit
                await asyncio.sleep(0.1)

            except Exception as e:
                print(f"   âš ï¸ ç”Ÿæˆå•é¡Œå¤±æ•—: {e}")
                # å‚™ç”¨æ–¹æ¡ˆ
                knowledge['question_summary'] = f"{knowledge['category']}ç›¸é—œå•é¡Œ"

        print(f"   âœ… å•é¡Œæ‘˜è¦ç”Ÿæˆå®Œæˆ")

    async def _generate_embeddings(self, knowledge_list: List[Dict]):
        """
        ç‚ºçŸ¥è­˜ç”Ÿæˆå‘é‡åµŒå…¥

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
        """
        print(f"ğŸ”® ç‚º {len(knowledge_list)} æ¢çŸ¥è­˜ç”Ÿæˆå‘é‡åµŒå…¥...")

        for idx, knowledge in enumerate(knowledge_list, 1):
            try:
                # çµ„åˆæ–‡å­—ï¼ˆå•é¡Œ + ç­”æ¡ˆå‰æ®µï¼‰
                text = f"{knowledge['question_summary']} {knowledge['answer'][:200]}"

                response = await self.openai_client.embeddings.create(
                    model=self.embedding_model,
                    input=text
                )

                knowledge['embedding'] = response.data[0].embedding

                if idx % 10 == 0:
                    print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

                # é¿å… rate limit
                await asyncio.sleep(0.05)

            except Exception as e:
                print(f"   âš ï¸ ç”Ÿæˆå‘é‡å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                raise Exception(f"å‘é‡ç”Ÿæˆå¤±æ•—: {e}")

        print(f"   âœ… å‘é‡åµŒå…¥ç”Ÿæˆå®Œæˆ")

    async def _deduplicate_exact_match(self, knowledge_list: List[Dict]) -> List[Dict]:
        """
        å»é™¤æ–‡å­—å®Œå…¨ç›¸åŒçš„çŸ¥è­˜ï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰
        åœ¨ LLM å‰åŸ·è¡Œï¼Œç¯€çœ OpenAI token æˆæœ¬

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨

        Returns:
            å»é‡å¾Œçš„çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ” åŸ·è¡Œæ–‡å­—å»é‡ï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰...")

        async with self.db_pool.acquire() as conn:
            unique_list = []

            for knowledge in knowledge_list:
                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„å•é¡Œå’Œç­”æ¡ˆï¼ˆåŒæ™‚æª¢æŸ¥æ­£å¼çŸ¥è­˜åº«ã€å¯©æ ¸ä½‡åˆ—å’Œæ¸¬è©¦æƒ…å¢ƒï¼‰
                exists = await conn.fetchval("""
                    SELECT COUNT(*) FROM (
                        SELECT 1 FROM knowledge_base
                        WHERE question_summary = $1 AND answer = $2
                        UNION ALL
                        SELECT 1 FROM ai_generated_knowledge_candidates
                        WHERE question = $1 AND generated_answer = $2
                        UNION ALL
                        SELECT 1 FROM test_scenarios
                        WHERE test_question = $1
                        AND status IN ('approved', 'in_testing')
                    ) AS combined
                """, knowledge.get('question_summary'), knowledge['answer'])

                if exists == 0:
                    unique_list.append(knowledge)
                else:
                    print(f"   è·³éé‡è¤‡: {knowledge.get('question_summary', 'ç„¡å•é¡Œ')[:50]}...")

        return unique_list

    async def _deduplicate_by_similarity(
        self,
        knowledge_list: List[Dict],
        threshold: float = 0.85
    ) -> List[Dict]:
        """
        ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦å»é‡ï¼ˆèªæ„å»é‡ï¼‰
        æª¢æŸ¥çŸ¥è­˜åº«ã€å¯©æ ¸ä½‡åˆ—å’Œæ¸¬è©¦æƒ…å¢ƒä¸­æ˜¯å¦å·²æœ‰èªæ„ç›¸ä¼¼çš„çŸ¥è­˜

        é‡ç”¨ unclear_questions çš„ç›¸ä¼¼åº¦æ©Ÿåˆ¶ï¼š
        - é–¾å€¼ï¼š0.85ï¼ˆèˆ‡ unclear_questions ä¸€è‡´ï¼‰
        - ä½¿ç”¨è³‡æ–™åº«å‡½æ•¸ check_knowledge_exists_by_similarity()

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆå¿…é ˆå·²æœ‰ embeddingï¼‰
            threshold: ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.85ï¼‰

        Returns:
            å»é‡å¾Œçš„çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ” åŸ·è¡Œèªæ„å»é‡ï¼ˆç›¸ä¼¼åº¦é–¾å€¼: {threshold}ï¼‰...")

        unique_list = []

        async with self.db_pool.acquire() as conn:
            for idx, knowledge in enumerate(knowledge_list, 1):
                embedding = knowledge.get('embedding')

                if not embedding:
                    print(f"   âš ï¸  çŸ¥è­˜ç¼ºå°‘ embeddingï¼Œè·³éèªæ„æª¢æŸ¥: {knowledge.get('question_summary', 'ç„¡å•é¡Œ')[:50]}")
                    unique_list.append(knowledge)
                    continue

                # å°‡ embedding è½‰æ›ç‚º PostgreSQL vector æ ¼å¼
                vector_str = '[' + ','.join(str(x) for x in embedding) + ']'

                # ä½¿ç”¨è³‡æ–™åº«å‡½æ•¸æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼çŸ¥è­˜
                result = await conn.fetchrow("""
                    SELECT * FROM check_knowledge_exists_by_similarity($1::vector, $2::DECIMAL)
                """, vector_str, threshold)

                if result and (result['exists_in_knowledge_base'] or result['exists_in_review_queue'] or result.get('exists_in_test_scenarios', False)):
                    # æ‰¾åˆ°ç›¸ä¼¼çŸ¥è­˜ï¼Œè·³é
                    source = result['source_table']
                    matched_q = result['matched_question']
                    sim_score = result['similarity_score']

                    print(f"   è·³éèªæ„ç›¸ä¼¼ (ç›¸ä¼¼åº¦: {sim_score:.4f}, ä¾†æº: {source})")
                    print(f"      æ–°å•é¡Œ: {knowledge['question_summary'][:50]}...")
                    print(f"      ç›¸ä¼¼å•é¡Œ: {matched_q[:50]}...")
                else:
                    # æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼çŸ¥è­˜ï¼Œä¿ç•™
                    unique_list.append(knowledge)

                # æ¯è™•ç† 10 æ¢é¡¯ç¤ºé€²åº¦
                if idx % 10 == 0:
                    print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

        return unique_list

    async def _recommend_intents(self, knowledge_list: List[Dict]):
        """
        ç‚ºçŸ¥è­˜æ¨è–¦åˆé©çš„æ„åœ–

        ä½¿ç”¨ LLM æ ¹æ“šå•é¡Œå’Œç­”æ¡ˆå…§å®¹æ¨è–¦æœ€åˆé©çš„æ„åœ–
        æ¨è–¦çµæœå„²å­˜åˆ° knowledge['recommended_intent']

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
        """
        print(f"ğŸ¯ ç‚º {len(knowledge_list)} æ¢çŸ¥è­˜æ¨è–¦æ„åœ–...")

        # 1. å–å¾—æ‰€æœ‰å¯ç”¨çš„æ„åœ–
        async with self.db_pool.acquire() as conn:
            intents = await conn.fetch("""
                SELECT id, name, description
                FROM intents
                ORDER BY id
            """)

        if not intents:
            print("   âš ï¸  æ‰¾ä¸åˆ°ä»»ä½•æ„åœ–ï¼Œè·³éæ¨è–¦")
            return

        # å»ºç«‹æ„åœ–æ¸…å–®æ–‡å­—
        intent_list = "\n".join([
            f"- {intent['id']}: {intent['name']} ({intent['description']})"
            for intent in intents
        ])

        # 2. ç‚ºæ¯æ¢çŸ¥è­˜æ¨è–¦æ„åœ–
        for idx, knowledge in enumerate(knowledge_list, 1):
            try:
                prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹å•ç­”å…§å®¹ï¼Œå¾æ„åœ–æ¸…å–®ä¸­é¸æ“‡æœ€åˆé©çš„æ„åœ–ã€‚

å•é¡Œï¼š{knowledge['question_summary']}
ç­”æ¡ˆï¼š{knowledge['answer'][:200]}
åˆ†é¡ï¼š{knowledge.get('category', 'æœªåˆ†é¡')}

å¯ç”¨çš„æ„åœ–æ¸…å–®ï¼š
{intent_list}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "intent_id": æ¨è–¦çš„æ„åœ– IDï¼ˆæ•¸å­—ï¼‰,
  "intent_name": æ„åœ–åç¨±,
  "confidence": ä¿¡å¿ƒåº¦ï¼ˆ0.0-1.0ï¼‰,
  "reasoning": æ¨è–¦ç†ç”±ï¼ˆç°¡çŸ­èªªæ˜ï¼‰
}}

åªè¼¸å‡º JSONï¼Œä¸è¦åŠ å…¶ä»–èªªæ˜ã€‚"""

                response = await self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    temperature=0.3,
                    max_tokens=500,  # æ„åœ–æ¨è–¦åªéœ€å°é‡è¼¸å‡º
                    response_format={"type": "json_object"},
                    messages=[{"role": "user", "content": prompt}]
                )

                result = json.loads(response.choices[0].message.content)

                # å„²å­˜æ¨è–¦çµæœ
                knowledge['recommended_intent'] = {
                    'intent_id': result.get('intent_id'),
                    'intent_name': result.get('intent_name'),
                    'confidence': result.get('confidence', 0.8),
                    'reasoning': result.get('reasoning', '')
                }

                if idx <= 3:  # åªé¡¯ç¤ºå‰ 3 æ¢çš„æ¨è–¦
                    print(f"   âœ… {knowledge['question_summary'][:40]}... â†’ {result.get('intent_name')} (ä¿¡å¿ƒåº¦: {result.get('confidence', 0):.2f})")

                # é¿å… rate limit
                await asyncio.sleep(0.1)

            except Exception as e:
                print(f"   âš ï¸  æ„åœ–æ¨è–¦å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨é è¨­æ„åœ–
                knowledge['recommended_intent'] = {
                    'intent_id': 4,  # æœå‹™èªªæ˜
                    'intent_name': 'æœå‹™èªªæ˜',
                    'confidence': 0.5,
                    'reasoning': 'ç„¡æ³•è‡ªå‹•æ¨è–¦ï¼Œä½¿ç”¨é è¨­æ„åœ–'
                }

        print(f"   âœ… æ„åœ–æ¨è–¦å®Œæˆ")

    async def _evaluate_quality(self, knowledge_list: List[Dict]):
        """
        è©•ä¼°çŸ¥è­˜ç­”æ¡ˆçš„è³ªé‡

        ä½¿ç”¨ LLM è©•ä¼°ç­”æ¡ˆæ˜¯å¦æœ‰å¯¦ç”¨åƒ¹å€¼ï¼Œé¿å…ç©ºæ³›ã€å¾ªç’°é‚è¼¯æˆ–ç„¡æ„ç¾©çš„å…§å®¹
        è©•ä¼°çµæœå„²å­˜åˆ° knowledge['quality_evaluation']

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
        """
        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨è³ªé‡è©•ä¼°
        if not self.quality_evaluation_enabled:
            print(f"â­ï¸  è³ªé‡è©•ä¼°å·²åœç”¨ï¼ˆQUALITY_EVALUATION_ENABLED=falseï¼‰")
            # æ‰€æœ‰çŸ¥è­˜é è¨­ç‚ºå¯æ¥å—
            for knowledge in knowledge_list:
                knowledge['quality_evaluation'] = {
                    'quality_score': 8,
                    'is_acceptable': True,
                    'issues': [],
                    'reasoning': 'è³ªé‡è©•ä¼°å·²åœç”¨ï¼Œé è¨­ç‚ºå¯æ¥å—'
                }
            return

        print(f"ğŸ” è©•ä¼° {len(knowledge_list)} æ¢çŸ¥è­˜çš„è³ªé‡ï¼ˆé–€æª»: {self.quality_evaluation_threshold}/10ï¼‰...")

        for idx, knowledge in enumerate(knowledge_list, 1):
            try:
                prompt = f"""è«‹è©•ä¼°ä»¥ä¸‹å•ç­”å…§å®¹çš„è³ªé‡ã€‚

å•é¡Œï¼š{knowledge['question_summary']}
ç­”æ¡ˆï¼š{knowledge['answer']}

è©•ä¼°æ¨™æº–ï¼š
1. å…·é«”æ€§ï¼šç­”æ¡ˆæ˜¯å¦åŒ…å«å…·é«”çš„æ“ä½œæ­¥é©Ÿã€ç´°ç¯€æˆ–èªªæ˜ï¼Ÿ
2. å¯¦ç”¨æ€§ï¼šç­”æ¡ˆæ˜¯å¦èƒ½å¯¦éš›å¹«åŠ©ä½¿ç”¨è€…è§£æ±ºå•é¡Œï¼Ÿ
3. å®Œæ•´æ€§ï¼šç­”æ¡ˆæ˜¯å¦å®Œæ•´å›ç­”äº†å•é¡Œï¼Ÿ
4. éå¾ªç’°æ€§ï¼šç­”æ¡ˆæ˜¯å¦é¿å…äº†å¾ªç’°é‚è¼¯ï¼ˆå¦‚ã€Œéœ€è¦åšXæ™‚å°±åšXã€ï¼‰ï¼Ÿ
5. æ·±åº¦ï¼šç­”æ¡ˆæ˜¯å¦æœ‰è¶³å¤ çš„æ·±åº¦ï¼ˆä¸åªæ˜¯é‡è¤‡å•é¡Œæˆ–é¡¯è€Œæ˜“è¦‹çš„å»ºè­°ï¼‰ï¼Ÿ

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "quality_score": è³ªé‡åˆ†æ•¸ï¼ˆ1-10ï¼Œ10 ç‚ºæœ€é«˜ï¼‰,
  "is_acceptable": æ˜¯å¦å¯æ¥å—ï¼ˆtrue/falseï¼Œåˆ†æ•¸ >= {self.quality_evaluation_threshold} ç‚ºå¯æ¥å—ï¼‰,
  "issues": ["å•é¡Œ1", "å•é¡Œ2"],
  "reasoning": "è©•ä¼°ç†ç”±ï¼ˆç°¡çŸ­èªªæ˜ï¼‰"
}}

è©•åˆ†åƒè€ƒï¼š
- 9-10åˆ†ï¼šå…§å®¹è©³å¯¦ã€å…·é«”ã€æœ‰å¯¦ç”¨åƒ¹å€¼ï¼Œæ˜ç¢ºèªªæ˜æ“ä½œæ­¥é©Ÿ
- 8åˆ†ï¼šæœ‰å¯¦ç”¨åƒ¹å€¼ï¼ŒåŒ…å«å¿…è¦ç´°ç¯€å’Œå…·é«”èªªæ˜
- 6-7åˆ†ï¼šæœ‰ä¸€å®šåƒ¹å€¼ï¼Œä½†éæ–¼ç©ºæ³›æˆ–ç¼ºå°‘é—œéµç´°ç¯€
- 4-5åˆ†ï¼šåŸºæœ¬å¯ç”¨ï¼Œä½†å…§å®¹ç©ºæ³›
- 1-3åˆ†ï¼šç„¡å¯¦ç”¨åƒ¹å€¼ï¼Œæœ‰å¾ªç’°é‚è¼¯æˆ–é‡è¤‡å•é¡Œï¼Œæ‡‰è©²æ‹’çµ•

âš ï¸ æ³¨æ„ï¼šåªæœ‰åˆ†æ•¸ >= {self.quality_evaluation_threshold} çš„çŸ¥è­˜æ‰èƒ½é€²å…¥å¯©æ ¸ä½‡åˆ—ã€‚

åªè¼¸å‡º JSONï¼Œä¸è¦åŠ å…¶ä»–èªªæ˜ã€‚"""

                response = await self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    temperature=0.3,
                    max_tokens=500,  # è³ªé‡è©•ä¼°åªéœ€å°é‡è¼¸å‡º
                    response_format={"type": "json_object"},
                    messages=[{"role": "user", "content": prompt}]
                )

                result = json.loads(response.choices[0].message.content)

                # å„²å­˜è©•ä¼°çµæœ
                knowledge['quality_evaluation'] = {
                    'quality_score': result.get('quality_score', 5),
                    'is_acceptable': result.get('is_acceptable', True),
                    'issues': result.get('issues', []),
                    'reasoning': result.get('reasoning', '')
                }

                # é¡¯ç¤ºä½è³ªé‡çš„çŸ¥è­˜
                if not result.get('is_acceptable', True):
                    print(f"   âš ï¸  ä½è³ªé‡ (åˆ†æ•¸: {result.get('quality_score', 0)}): {knowledge['question_summary'][:40]}...")
                    print(f"      ç†ç”±: {result.get('reasoning', '')[:80]}")
                elif idx <= 3:  # é¡¯ç¤ºå‰ 3 æ¢çš„è©•ä¼°
                    print(f"   âœ… {knowledge['question_summary'][:40]}... â†’ åˆ†æ•¸: {result.get('quality_score', 0)}/10")

                # é¿å… rate limit
                await asyncio.sleep(0.1)

            except Exception as e:
                print(f"   âš ï¸  è³ªé‡è©•ä¼°å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                # å‚™ç”¨æ–¹æ¡ˆï¼šé è¨­ç‚ºå¯æ¥å—
                knowledge['quality_evaluation'] = {
                    'quality_score': 6,
                    'is_acceptable': True,
                    'issues': [],
                    'reasoning': 'ç„¡æ³•è‡ªå‹•è©•ä¼°ï¼Œé è¨­ç‚ºå¯æ¥å—'
                }

        # çµ±è¨ˆè³ªé‡åˆ†å¸ƒ
        acceptable_count = sum(1 for k in knowledge_list if k.get('quality_evaluation', {}).get('is_acceptable', True))
        rejected_count = len(knowledge_list) - acceptable_count

        print(f"   âœ… è³ªé‡è©•ä¼°å®Œæˆ")
        print(f"      å¯æ¥å—: {acceptable_count} æ¢")
        if rejected_count > 0:
            print(f"      ä½è³ªé‡: {rejected_count} æ¢ï¼ˆå°‡è‡ªå‹•æ¨™è¨˜ç‚ºå·²æ‹’çµ•ï¼‰")

    async def _clear_vendor_knowledge(self, vendor_id: int):
        """
        æ¸…é™¤æ¥­è€…çš„ç¾æœ‰çŸ¥è­˜ï¼ˆç”¨æ–¼ replace æ¨¡å¼ï¼‰

        Args:
            vendor_id: æ¥­è€… ID
        """
        print(f"ğŸ—‘ï¸  æ¸…é™¤æ¥­è€… {vendor_id} çš„ç¾æœ‰çŸ¥è­˜...")

        async with self.db_pool.acquire() as conn:
            deleted_count = await conn.fetchval("""
                DELETE FROM knowledge_base
                WHERE vendor_id = $1
                RETURNING COUNT(*)
            """, vendor_id)

            print(f"   âœ… å·²åˆªé™¤ {deleted_count or 0} æ¢èˆŠçŸ¥è­˜")

    async def _import_to_database(
        self,
        knowledge_list: List[Dict],
        vendor_id: Optional[int],
        import_mode: str,
        default_priority: int = 0,
        created_by: str = "admin"
    ) -> Dict:
        """
        åŒ¯å…¥çŸ¥è­˜åˆ°è³‡æ–™åº«

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨
            vendor_id: æ¥­è€… ID
            import_mode: åŒ¯å…¥æ¨¡å¼
            default_priority: çµ±ä¸€å„ªå…ˆç´šï¼ˆ0=æœªå•Ÿç”¨ï¼Œ1=å·²å•Ÿç”¨ï¼‰
            created_by: å»ºç«‹è€…

        Returns:
            åŒ¯å…¥çµæœçµ±è¨ˆ
        """
        print(f"ğŸ’¾ åŒ¯å…¥ {len(knowledge_list)} æ¢çŸ¥è­˜åˆ°è³‡æ–™åº«...")

        imported = 0
        skipped = 0
        errors = 0

        async with self.db_pool.acquire() as conn:
            # å–å¾—é è¨­æ„åœ– ID
            default_intent_id = await conn.fetchval("""
                SELECT id FROM intents
                WHERE name IN ('ä¸€èˆ¬çŸ¥è­˜', 'å…¶ä»–', 'general')
                ORDER BY id
                LIMIT 1
            """)

            if not default_intent_id:
                print("âš ï¸ æ‰¾ä¸åˆ°é è¨­æ„åœ–ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹æ„åœ–")
                default_intent_id = await conn.fetchval("SELECT id FROM intents ORDER BY id LIMIT 1")

            for idx, knowledge in enumerate(knowledge_list, 1):
                try:
                    # å°‡ embedding è½‰æ›ç‚º PostgreSQL vector æ ¼å¼
                    embedding = knowledge.get('embedding')
                    embedding_str = None
                    if embedding:
                        embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

                    await conn.execute("""
                        INSERT INTO knowledge_base (
                            intent_id,
                            vendor_id,
                            question_summary,
                            answer,
                            keywords,
                            source_file,
                            source_date,
                            embedding,
                            scope,
                            priority,
                            created_at,
                            updated_at
                        ) VALUES (
                            $1, $2, $3, $4, $5, $6, $7, $8::vector, $9, $10,
                            CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
                        )
                    """,
                        knowledge.get('intent_id') or default_intent_id,  # ğŸ”§ å„ªå…ˆä½¿ç”¨ CSV ä¸­çš„ intent_id
                        vendor_id,
                        knowledge['question_summary'],
                        knowledge['answer'],
                        knowledge['keywords'],
                        knowledge['source_file'],
                        datetime.now().date(),
                        embedding_str,
                        'global' if not vendor_id else 'vendor',
                        default_priority  # ä½¿ç”¨å‚³å…¥çš„ default_priority åƒæ•¸
                    )

                    imported += 1

                    if idx % 10 == 0:
                        print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

                except Exception as e:
                    print(f"   âš ï¸ åŒ¯å…¥å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                    errors += 1

        return {
            "imported": imported,
            "skipped": skipped,
            "errors": errors,
            "total": len(knowledge_list)
        }

    async def _create_test_scenario_suggestions(
        self,
        knowledge_list: List[Dict],
        vendor_id: Optional[int]
    ) -> int:
        """
        ç‚º B2C å°è±¡çš„çŸ¥è­˜å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°ï¼ˆéœ€æ±‚ 2ï¼‰

        B2C å°è±¡åŒ…æ‹¬ï¼šç§Ÿå®¢ã€æˆ¿æ±ï¼ˆæ‰€æœ‰å¤–éƒ¨æ¥­å‹™ç¯„åœï¼‰

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨
            vendor_id: æ¥­è€… ID

        Returns:
            å»ºç«‹çš„æ¸¬è©¦æƒ…å¢ƒæ•¸é‡
        """
        print(f"ğŸ§ª æª¢æŸ¥ B2C çŸ¥è­˜ä¸¦å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°...")

        # B2C å°è±¡åˆ—è¡¨
        b2c_audiences = ['ç§Ÿå®¢', 'æˆ¿æ±', 'tenant', 'landlord']

        created_count = 0

        async with self.db_pool.acquire() as conn:
            for knowledge in knowledge_list:
                audience = knowledge.get('audience', '').lower()

                # æª¢æŸ¥æ˜¯å¦ç‚º B2C å°è±¡
                if not any(b2c in audience.lower() for b2c in b2c_audiences):
                    continue

                question = knowledge['question_summary']

                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼çš„æ¸¬è©¦æƒ…å¢ƒ
                exists = await conn.fetchval("""
                    SELECT COUNT(*)
                    FROM test_scenarios
                    WHERE test_question = $1
                """, question)

                if exists > 0:
                    continue

                # å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°
                try:
                    category_info = knowledge.get('category', 'ä¸€èˆ¬å•é¡Œ')
                    await conn.execute("""
                        INSERT INTO test_scenarios (
                            test_question,
                            difficulty,
                            status,
                            source,
                            notes,
                            created_at
                        ) VALUES ($1, $2, $3, $4, $5, CURRENT_TIMESTAMP)
                    """,
                        question,
                        'medium',  # é è¨­é›£åº¦
                        'pending_review',  # å¾…å¯©æ ¸ç‹€æ…‹
                        'imported',
                        f"å°å…¥çš„çŸ¥è­˜ï¼ˆé¡åˆ¥: {category_info}ï¼‰"
                    )

                    created_count += 1

                except Exception as e:
                    print(f"   âš ï¸ å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå¤±æ•—: {e}")

        if created_count > 0:
            print(f"   âœ… å»ºç«‹äº† {created_count} å€‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°")
        else:
            print(f"   â„¹ï¸ æ²’æœ‰éœ€è¦å»ºç«‹æ¸¬è©¦æƒ…å¢ƒçš„ B2C çŸ¥è­˜")

        return created_count

    async def _import_to_review_queue(
        self,
        knowledge_list: List[Dict],
        vendor_id: Optional[int],
        created_by: str
    ) -> Dict:
        """
        å°‡çŸ¥è­˜åŒ¯å…¥åˆ°å¯©æ ¸ä½‡åˆ—ï¼ˆéœ€æ±‚ 3ï¼šæ··åˆæ¨¡å¼ï¼‰

        çŸ¥è­˜æœƒå…ˆé€²å…¥ ai_generated_knowledge_candidates è¡¨ï¼Œ
        äººå·¥å¯©æ ¸é€šéå¾Œæ‰æœƒåŠ å…¥æ­£å¼çš„ knowledge_base

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨
            vendor_id: æ¥­è€… ID
            created_by: å»ºç«‹è€…

        Returns:
            åŒ¯å…¥çµæœçµ±è¨ˆ
        """
        print(f"ğŸ“‹ å°‡ {len(knowledge_list)} æ¢çŸ¥è­˜åŒ¯å…¥å¯©æ ¸ä½‡åˆ—...")

        imported = 0
        auto_rejected = 0
        errors = 0

        async with self.db_pool.acquire() as conn:
            for idx, knowledge in enumerate(knowledge_list, 1):
                try:
                    question = knowledge['question_summary']
                    answer = knowledge['answer']

                    # 1. å…ˆæª¢æŸ¥æˆ–å»ºç«‹å°æ‡‰çš„æ¸¬è©¦æƒ…å¢ƒ
                    test_scenario_id = await conn.fetchval("""
                        SELECT id FROM test_scenarios
                        WHERE test_question = $1
                        ORDER BY created_at DESC
                        LIMIT 1
                    """, question)

                    # å¦‚æœæ²’æœ‰æ¸¬è©¦æƒ…å¢ƒï¼Œå…ˆå»ºç«‹ä¸€å€‹
                    if not test_scenario_id:
                        category_info = knowledge.get('category', 'ä¸€èˆ¬å•é¡Œ')
                        test_scenario_id = await conn.fetchval("""
                            INSERT INTO test_scenarios (
                                test_question,
                                difficulty,
                                status,
                                source,
                                notes,
                                created_at
                            ) VALUES ($1, $2, $3, $4, $5, CURRENT_TIMESTAMP)
                            RETURNING id
                        """,
                            question,
                            'medium',
                            'pending_review',
                            'imported',
                            f"å°å…¥çš„çŸ¥è­˜ï¼ˆé¡åˆ¥: {category_info}ï¼‰"
                        )

                    # 2. æº–å‚™ generation_reasoningï¼ˆåŒ…å«æ„åœ–æ¨è–¦ã€æ³›åŒ–è­¦å‘Šå’Œè³ªé‡è©•ä¼°ï¼‰
                    recommended_intent = knowledge.get('recommended_intent', {})
                    warnings_list = knowledge.get('warnings', [])
                    quality_eval = knowledge.get('quality_evaluation', {})

                    # æå–æ¨è–¦æ„åœ– ID ä¸¦å»ºç«‹é™£åˆ—
                    intent_ids = []
                    if recommended_intent and recommended_intent.get('intent_id') not in [None, 'æœªæ¨è–¦', 'null']:
                        try:
                            intent_id = int(recommended_intent.get('intent_id'))
                            intent_ids = [intent_id]
                        except (ValueError, TypeError):
                            pass  # å¦‚æœè½‰æ›å¤±æ•—ï¼Œä¿æŒç©ºé™£åˆ—

                    reasoning = f"""åˆ†é¡: {knowledge.get('category')}, å°è±¡: {knowledge.get('audience')}, é—œéµå­—: {', '.join(knowledge.get('keywords', []))}

ã€æ¨è–¦æ„åœ–ã€‘
æ„åœ– ID: {recommended_intent.get('intent_id', 'æœªæ¨è–¦')}
æ„åœ–åç¨±: {recommended_intent.get('intent_name', 'æœªæ¨è–¦')}
ä¿¡å¿ƒåº¦: {recommended_intent.get('confidence', 0)}
æ¨è–¦ç†ç”±: {recommended_intent.get('reasoning', 'ç„¡')}"""

                    # å¦‚æœæœ‰æ³›åŒ–è­¦å‘Šï¼ŒåŠ åˆ° reasoning ä¸­
                    if warnings_list:
                        reasoning += f"\n\nã€æ³›åŒ–è™•ç†ã€‘\n" + "\n".join([f"- {w}" for w in warnings_list])

                    # æ±ºå®šç‹€æ…‹ï¼šæ ¹æ“šè³ªé‡è©•ä¼°çµæœ
                    is_acceptable = quality_eval.get('is_acceptable', True)
                    if is_acceptable:
                        status = 'pending_review'
                    else:
                        status = 'rejected'
                        auto_rejected += 1
                        # åŠ å…¥è³ªé‡è©•ä¼°è³‡è¨Šåˆ° reasoning
                        reasoning += f"\n\nã€è³ªé‡è©•ä¼° - è‡ªå‹•æ‹’çµ•ã€‘\n"
                        reasoning += f"è³ªé‡åˆ†æ•¸: {quality_eval.get('quality_score', 0)}/10\n"
                        reasoning += f"æ‹’çµ•ç†ç”±: {quality_eval.get('reasoning', '')}\n"
                        if quality_eval.get('issues'):
                            reasoning += f"å•é¡Œåˆ—è¡¨: " + ", ".join(quality_eval.get('issues', []))

                    # 3. å°‡ embedding è½‰æ›ç‚º PostgreSQL vector æ ¼å¼
                    embedding = knowledge.get('embedding')
                    embedding_str = None
                    if embedding:
                        embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

                    # 4. å»ºç«‹çŸ¥è­˜å€™é¸è¨˜éŒ„ï¼ˆå« embeddingã€warnings å’Œ intent_idsï¼‰
                    await conn.execute("""
                        INSERT INTO ai_generated_knowledge_candidates (
                            test_scenario_id,
                            question,
                            generated_answer,
                            question_embedding,
                            confidence_score,
                            generation_prompt,
                            ai_model,
                            generation_reasoning,
                            suggested_sources,
                            warnings,
                            intent_ids,
                            status,
                            created_at,
                            updated_at
                        ) VALUES ($1, $2, $3, $4::vector, $5, $6, $7, $8, $9, $10, $11, $12, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                    """,
                        test_scenario_id,
                        question,
                        answer,
                        embedding_str,  # å‘é‡åµŒå…¥ï¼ˆå­—ä¸²æ ¼å¼ï¼‰
                        0.85,  # åŒ¯å…¥çš„çŸ¥è­˜å›ºå®šä¿¡å¿ƒåˆ†æ•¸ 85%
                        f"å¾æª”æ¡ˆåŒ¯å…¥: {knowledge.get('source_file', 'unknown')}",
                        'knowledge_import',  # æ¨™è¨˜ç‚ºçŸ¥è­˜åŒ¯å…¥ä¾†æº
                        reasoning,  # åŒ…å«æ¨è–¦æ„åœ–ã€æ³›åŒ–è­¦å‘Šå’Œè³ªé‡è©•ä¼°çš„è©³ç´°è³‡è¨Š
                        [knowledge.get('source_file', 'imported_file')],
                        warnings_list,  # æ³›åŒ–è­¦å‘Šï¼ˆå¦‚æœæœ‰ï¼‰
                        intent_ids,  # æ¨è–¦æ„åœ– ID é™£åˆ—ï¼ˆè‡ªå‹•å¡«å…¥ï¼‰
                        status  # æ ¹æ“šè³ªé‡è©•ä¼°å‹•æ…‹è¨­å®šçš„ç‹€æ…‹
                    )

                    imported += 1

                    if idx % 10 == 0:
                        print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

                except Exception as e:
                    print(f"   âš ï¸ åŒ¯å…¥åˆ°å¯©æ ¸ä½‡åˆ—å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                    errors += 1

        print(f"\n   âœ… åŒ¯å…¥å®Œæˆ:")
        print(f"      ç¸½å…±: {len(knowledge_list)} æ¢")
        print(f"      å¾…å¯©æ ¸: {imported - auto_rejected} æ¢")
        if auto_rejected > 0:
            print(f"      è‡ªå‹•æ‹’çµ•: {auto_rejected} æ¢ï¼ˆè³ªé‡ä¸è¶³ï¼‰")
        if errors > 0:
            print(f"      éŒ¯èª¤: {errors} æ¢")

        return {
            "imported": imported,
            "auto_rejected": auto_rejected,
            "pending_review": imported - auto_rejected,
            "skipped": 0,
            "errors": errors,
            "total": len(knowledge_list),
            "mode": "review_queue"
        }

    async def update_job_status(
        self,
        job_id: str,
        status: str,
        progress: Optional[Dict] = None,
        result: Optional[Dict] = None,
        error: Optional[str] = None
    ):
        """
        æ›´æ–°ä½œæ¥­ç‹€æ…‹

        æ³¨æ„ï¼šjob è¨˜éŒ„å¿…é ˆåœ¨å‘¼å«æ­¤æ–¹æ³•å‰å·²å­˜åœ¨ï¼ˆç”±ä¸Šå‚³ç«¯é»å»ºç«‹ï¼‰

        Args:
            job_id: ä½œæ¥­ ID
            status: ç‹€æ…‹ï¼ˆprocessing/completed/failedï¼‰
            progress: é€²åº¦è³‡è¨Š
            result: çµæœçµ±è¨ˆ
            error: éŒ¯èª¤è¨Šæ¯
        """
        async with self.db_pool.acquire() as conn:
            import uuid
            # æ›´æ–°ä½œæ¥­ç‹€æ…‹ï¼ˆå‡è¨­ job è¨˜éŒ„å·²å­˜åœ¨ï¼‰
            # å…ˆé€²è¡ŒåŸºæœ¬æ›´æ–°
            updated = await conn.fetchval("""
                UPDATE knowledge_import_jobs
                SET status = $1::varchar,
                    progress = $2::jsonb,
                    result = $3::jsonb,
                    error_message = $4,
                    updated_at = CURRENT_TIMESTAMP,
                    completed_at = CASE WHEN $1::varchar IN ('completed', 'failed')
                                        THEN CURRENT_TIMESTAMP
                                        ELSE completed_at
                                   END
                WHERE job_id = $5
                RETURNING job_id
            """, status, json.dumps(progress) if progress else None,
                json.dumps(result) if result else None, error, uuid.UUID(job_id))

            if not updated:
                raise Exception(f"Job {job_id} not found in database")

            # å¦‚æœæœ‰ result ä¸”ç‹€æ…‹æ˜¯ completedï¼Œæ›´æ–°è¨ˆæ•¸æ¬„ä½
            if result and status == 'completed':
                await conn.execute("""
                    UPDATE knowledge_import_jobs
                    SET imported_count = ($1::jsonb->>'imported')::integer,
                        skipped_count = ($1::jsonb->>'skipped')::integer,
                        error_count = ($1::jsonb->>'errors')::integer
                    WHERE job_id = $2
                """, json.dumps(result), uuid.UUID(job_id))
