"""
çŸ¥è­˜åŒ¯å…¥æœå‹™
çµ±ä¸€è™•ç†å„ç¨®æ ¼å¼çš„çŸ¥è­˜åŒ¯å…¥ï¼ŒåŒ…æ‹¬æª”æ¡ˆè§£æã€å‘é‡ç”Ÿæˆã€è³‡æ–™åº«å„²å­˜

é‡æ§‹æ—¥æœŸï¼š2025-11-21 - æ”¹ç”¨çµ±ä¸€ Job ç³»çµ±
"""
import os
import json
import asyncio
import uuid
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import pandas as pd
import asyncpg
from asyncpg.pool import Pool
from openai import AsyncOpenAI
import time

# å¼•å…¥çµ±ä¸€ Job æœå‹™
from services.unified_job_service import UnifiedJobService


class KnowledgeImportService(UnifiedJobService):
    """çŸ¥è­˜åŒ¯å…¥æœå‹™ï¼ˆå·²æ•´åˆåˆ°çµ±ä¸€ Job ç³»çµ±ï¼‰"""

    def __init__(self, db_pool: Pool):
        """
        åˆå§‹åŒ–çŸ¥è­˜åŒ¯å…¥æœå‹™

        Args:
            db_pool: è³‡æ–™åº«é€£æ¥æ± 
        """
        # åˆå§‹åŒ–çˆ¶é¡ï¼ˆçµ±ä¸€ Job æœå‹™ï¼‰
        super().__init__(db_pool)
        self.openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.embedding_model = "text-embedding-3-small"
        # çŸ¥è­˜åŒ¯å…¥ä½¿ç”¨ DOCUMENT_CONVERTER_MODELï¼ˆéœ€è¦å¤§ context è™•ç†é•·æ–‡æœ¬ï¼‰
        # å„ªå…ˆé †åºï¼šDOCUMENT_CONVERTER_MODEL > KNOWLEDGE_GEN_MODEL > gpt-4o
        self.llm_model = os.getenv("DOCUMENT_CONVERTER_MODEL",
                                   os.getenv("KNOWLEDGE_GEN_MODEL", "gpt-4o"))

        # è³ªé‡è©•ä¼°é…ç½®
        self.quality_evaluation_enabled = os.getenv("QUALITY_EVALUATION_ENABLED", "true").lower() == "true"
        self.quality_evaluation_threshold = int(os.getenv("QUALITY_EVALUATION_THRESHOLD", "6"))

        # ç›®æ¨™ç”¨æˆ¶é…ç½®ç·©å­˜ï¼ˆå¾è³‡æ–™åº«å‹•æ…‹åŠ è¼‰ï¼‰
        self._target_user_config_cache = None
        self._target_user_cache_time = None

    async def process_import_job(
        self,
        job_id: str,
        file_path: str,
        vendor_id: Optional[int],
        import_mode: str,
        enable_deduplication: bool,
        skip_review: bool = False,
        default_priority: int = 0,
        enable_quality_evaluation: bool = True,
        business_types: Optional[List[str]] = None,
        user_id: str = "admin"
    ) -> Dict:
        """
        è™•ç†çŸ¥è­˜åŒ¯å…¥ä½œæ¥­ï¼ˆä¸»è¦å…¥å£ï¼‰

        æ‰€æœ‰åŒ¯å…¥çš„çŸ¥è­˜éƒ½æœƒå…ˆé€²å…¥å¯©æ ¸ä½‡åˆ—ï¼Œ
        ç¶“éäººå·¥å¯©æ ¸é€šéå¾Œæ‰æœƒåŠ å…¥æ­£å¼çŸ¥è­˜åº«ã€‚

        Args:
            job_id: ä½œæ¥­ ID
            file_path: ä¸Šå‚³çš„æª”æ¡ˆè·¯å¾‘
            vendor_id: æ¥­è€… IDï¼ˆå¯é¸ï¼‰
            import_mode: åŒ¯å…¥æ¨¡å¼ï¼ˆappend/replace/mergeï¼‰
            enable_deduplication: æ˜¯å¦å•Ÿç”¨å»é‡
            skip_review: æ˜¯å¦è·³éå¯©æ ¸ç›´æ¥åŠ å…¥çŸ¥è­˜åº«
            default_priority: çµ±ä¸€å„ªå…ˆç´šï¼ˆ0=æœªå•Ÿç”¨ï¼Œ1=å·²å•Ÿç”¨ï¼‰
            enable_quality_evaluation: æ˜¯å¦å•Ÿç”¨è³ªé‡è©•ä¼°ï¼ˆé è¨­ Trueï¼Œé—œé–‰å¯åŠ é€Ÿå¤§é‡åŒ¯å…¥ï¼‰
            user_id: åŸ·è¡Œè€… ID

        Returns:
            åŒ¯å…¥çµæœçµ±è¨ˆ
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ é–‹å§‹è™•ç†çŸ¥è­˜åŒ¯å…¥ä½œæ¥­")
        print(f"   ä½œæ¥­ ID: {job_id}")
        print(f"   æª”æ¡ˆ: {file_path}")
        print(f"   æ¥­è€…: {vendor_id or 'é€šç”¨çŸ¥è­˜'}")
        print(f"   æ¨¡å¼: {import_mode}")
        print(f"{'='*60}\n")

        try:
            # 1. å¾è³‡æ–™åº«ç²å–åŸå§‹æª”åï¼ˆç”¨æ–¼ä¾†æºåµæ¸¬ï¼‰
            async with self.db_pool.acquire() as conn:
                job = await conn.fetchrow("""
                    SELECT file_name FROM unified_jobs WHERE job_id = $1
                """, uuid.UUID(job_id))
                original_filename = job['file_name'] if job else Path(file_path).name

            # 2. æ›´æ–°ä½œæ¥­ç‹€æ…‹ç‚ºè™•ç†ä¸­ï¼ˆuploading éšæ®µç”±å‰ç«¯è™•ç†ï¼Œå¾Œç«¯å¾ extracting é–‹å§‹ï¼‰
            await self.update_status(job_id, "processing", progress={"current": 0, "total": 100, "stage": "extracting"})

            # 3. åµæ¸¬æª”æ¡ˆé¡å‹ä¸¦é¸æ“‡è§£æå™¨
            file_type = self._detect_file_type(file_path)
            print(f"ğŸ“„ æª”æ¡ˆé¡å‹: {file_type}")

            # 3. è§£ææª”æ¡ˆ
            await self.update_status(job_id, "processing", progress={"current": 10, "total": 100, "stage": "extracting"})
            knowledge_list = await self._parse_file(file_path, file_type)

            if not knowledge_list:
                raise Exception("æœªèƒ½å¾æª”æ¡ˆä¸­æå–ä»»ä½•çŸ¥è­˜")

            print(f"âœ… è§£æå‡º {len(knowledge_list)} æ¢çŸ¥è­˜")

            # 3.5 æ‡‰ç”¨æ¥­æ…‹é¡å‹ï¼ˆå¦‚æœæœ‰æŒ‡å®šï¼‰
            if business_types and len(business_types) > 0:
                print(f"ğŸ“‹ å¥—ç”¨æ¥­æ…‹é¡å‹: {business_types}")
                for knowledge in knowledge_list:
                    # å¦‚æœExcelæ²’æœ‰æä¾›æ¥­æ…‹é¡å‹ï¼Œå‰‡ä½¿ç”¨UIé¸æ“‡çš„æ¥­æ…‹é¡å‹
                    if not knowledge.get('business_types'):
                        knowledge['business_types'] = business_types
                    # å¦‚æœExcelæœ‰æä¾›æ¥­æ…‹é¡å‹ï¼Œå‰‡åˆä½µï¼ˆå»é‡ï¼‰
                    else:
                        combined = set(knowledge['business_types'] + business_types)
                        knowledge['business_types'] = list(combined)

            # 3.5. åµæ¸¬åŒ¯å…¥ä¾†æºé¡å‹ï¼ˆä½¿ç”¨åŸå§‹æª”åï¼‰
            source_type, import_source = await self._detect_import_source(original_filename, file_type, knowledge_list)
            print(f"ğŸ“‹ ä¾†æºé¡å‹: {source_type} ({import_source})")

            # ========== ç‰¹æ®Šè™•ç†ï¼šå°è©±è¨˜éŒ„ â†’ ç­‰å¾…ç¢ºèªæ¨¡å¼ ==========
            if source_type == 'line_chat':
                print(f"ğŸ’¬ åµæ¸¬åˆ°å°è©±è¨˜éŒ„ï¼Œè§£ææ¸¬è©¦æƒ…å¢ƒä¸¦ç­‰å¾…ç”¨æˆ¶ç¢ºèª")
                await self.update_status(job_id, "processing", progress={"current": 80, "total": 100, "stage": "parsing"})

                # è§£æå‡ºæ¸¬è©¦æƒ…å¢ƒåˆ—è¡¨ï¼ˆä½†ä¸å‰µå»ºï¼‰
                scenarios = await self._parse_chat_scenarios(knowledge_list, file_name=Path(file_path).name)

                # è¨­ç½®ç‚ºç­‰å¾…ç¢ºèªç‹€æ…‹
                await self.update_status(
                    job_id,
                    status="awaiting_confirmation",
                    progress={"current": 90, "total": 100},
                    result={
                        "mode": "test_scenarios_preview",
                        "total": len(scenarios),
                        "scenarios": scenarios,
                        "message": "è«‹å‹¾é¸è¦å‰µå»ºçš„æ¸¬è©¦æƒ…å¢ƒ"
                    }
                )

                print(f"âœ… å°è©±è¨˜éŒ„è§£æå®Œæˆ: å…± {len(scenarios)} å€‹æ¸¬è©¦æƒ…å¢ƒå¾…ç¢ºèª")
                return {
                    "mode": "test_scenarios_preview",
                    "total": len(scenarios),
                    "scenarios": scenarios
                }

            # æ ¹æ“šä¾†æºé¡å‹æ±ºå®šè™•ç†æµç¨‹
            is_system_export = (import_source == 'system_export')

            # 4. é å…ˆå»é‡ï¼ˆæ–‡å­—å®Œå…¨ç›¸åŒï¼‰- åœ¨ LLM å‰åŸ·è¡Œï¼Œç¯€çœæˆæœ¬
            if enable_deduplication:
                await self.update_status(job_id, "processing", progress={"current": 20, "total": 100, "stage": "extracting"})
                original_count = len(knowledge_list)
                knowledge_list = await self._deduplicate_exact_match(knowledge_list, skip_review=skip_review, vendor_id=vendor_id)
                text_skipped = original_count - len(knowledge_list)
                print(f"ğŸ” æ–‡å­—å»é‡: è·³é {text_skipped} æ¢å®Œå…¨ç›¸åŒçš„é …ç›®ï¼Œå‰©é¤˜ {len(knowledge_list)} æ¢")

            # 5. ç”Ÿæˆå•é¡Œæ‘˜è¦ï¼ˆä½¿ç”¨ LLMï¼‰- åªè™•ç†å»é‡å¾Œçš„çŸ¥è­˜
            await self.update_status(job_id, "processing", progress={"current": 35, "total": 100, "stage": "extracting"})
            await self._generate_question_summaries(knowledge_list)

            # 6. ç”Ÿæˆå‘é‡åµŒå…¥ - åªè™•ç†å»é‡å¾Œçš„çŸ¥è­˜
            await self.update_status(job_id, "processing", progress={"current": 55, "total": 100, "stage": "embedding"})
            await self._generate_embeddings(knowledge_list)

            # 7. èªæ„å»é‡ï¼ˆä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦ï¼‰- äºŒæ¬¡éæ¿¾
            if enable_deduplication:
                await self.update_status(job_id, "processing", progress={"current": 70, "total": 100, "stage": "embedding"})
                semantic_original = len(knowledge_list)
                knowledge_list = await self._deduplicate_by_similarity(knowledge_list, skip_review=skip_review, vendor_id=vendor_id)
                semantic_skipped = semantic_original - len(knowledge_list)
                print(f"ğŸ” èªæ„å»é‡: è·³é {semantic_skipped} æ¢èªæ„ç›¸ä¼¼çš„é …ç›®ï¼Œå‰©é¤˜ {len(knowledge_list)} æ¢")
                print(f"ğŸ“Š ç¸½è¨ˆè·³é: {text_skipped + semantic_skipped} æ¢ï¼ˆæ–‡å­—: {text_skipped}, èªæ„: {semantic_skipped}ï¼‰")

            # 8. æ¨è–¦æ„åœ–ï¼ˆä½¿ç”¨ LLM æˆ–åˆ†é¡å™¨ï¼‰
            await self.update_status(job_id, "processing", progress={"current": 76, "total": 100, "stage": "embedding"})
            await self._recommend_intents(knowledge_list)

            # 8.5. è³ªé‡è©•ä¼°ï¼ˆè‡ªå‹•ç¯©é¸ä½è³ªé‡çŸ¥è­˜ï¼‰
            await self.update_status(job_id, "processing", progress={"current": 77, "total": 100, "stage": "embedding"})
            await self._evaluate_quality(knowledge_list, enable_quality_evaluation=enable_quality_evaluation)

            # 9. å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°ï¼ˆéœ€æ±‚ 2ï¼šé‡å° B2C çŸ¥è­˜ï¼‰
            await self.update_status(job_id, "processing", progress={"current": 78, "total": 100, "stage": "embedding"})
            test_scenario_count = await self._create_test_scenario_suggestions(knowledge_list, vendor_id)

            # 10. æ ¹æ“š skip_review åƒæ•¸æ±ºå®šåŒ¯å…¥ç›®æ¨™
            if skip_review:
                # ç›´æ¥åŒ¯å…¥åˆ°æ­£å¼çŸ¥è­˜åº«
                await self.update_status(job_id, "processing", progress={"current": 85, "total": 100, "stage": "saving"})
                result = await self._import_to_database(
                    knowledge_list,
                    vendor_id=vendor_id,
                    import_mode=import_mode,
                    default_priority=default_priority,
                    created_by=user_id
                )
                result['test_scenarios_created'] = test_scenario_count
                result['mode'] = 'direct'
            else:
                # åŒ¯å…¥åˆ°å¯©æ ¸ä½‡åˆ—ï¼ˆéœ€æ±‚ 3ï¼šæ‰€æœ‰çŸ¥è­˜éƒ½éœ€è¦å¯©æ ¸ï¼‰
                # çŸ¥è­˜æœƒå…ˆé€²å…¥ ai_generated_knowledge_candidates è¡¨
                # äººå·¥å¯©æ ¸é€šéå¾Œæ‰æœƒåŠ å…¥æ­£å¼çš„ knowledge_base è¡¨
                await self.update_status(job_id, "processing", progress={"current": 85, "total": 100, "stage": "saving"})
                result = await self._import_to_review_queue(
                    knowledge_list,
                    vendor_id=vendor_id,
                    created_by=user_id,
                    source_type=source_type,
                    import_source=import_source,
                    file_name=Path(file_path).name
                )
                result['test_scenarios_created'] = test_scenario_count

            # 11. æ›´æ–°ä½œæ¥­ç‹€æ…‹ç‚ºå®Œæˆï¼ˆä½¿ç”¨çµ±ä¸€ Job æœå‹™çš„æ–¹æ³•ï¼‰
            await self.update_status(
                job_id,
                status="completed",
                progress={"current": 100, "total": 100},
                result=result,
                success_records=result.get('imported', 0),
                failed_records=result.get('errors', 0),
                skipped_records=result.get('skipped', 0)
            )

            print(f"\n{'='*60}")
            if skip_review:
                print(f"âœ… åŒ¯å…¥å®Œæˆï¼ˆå·²ç›´æ¥åŠ å…¥æ­£å¼çŸ¥è­˜åº«ï¼‰")
            else:
                print(f"âœ… åŒ¯å…¥å®Œæˆï¼ˆå·²é€²å…¥å¯©æ ¸ä½‡åˆ—ï¼‰")
            print(f"   åŒ¯å…¥çŸ¥è­˜: {result['imported']} æ¢")
            print(f"   è·³é: {result.get('skipped', 0)} æ¢")
            print(f"   éŒ¯èª¤: {result.get('errors', 0)} æ¢")
            if result.get('test_scenarios_created', 0) > 0:
                print(f"   æ¸¬è©¦æƒ…å¢ƒå»ºè­°: {result['test_scenarios_created']} å€‹")
            if not skip_review:
                print(f"   âš ï¸  æ‰€æœ‰çŸ¥è­˜éœ€ç¶“äººå·¥å¯©æ ¸å¾Œæ‰æœƒæ­£å¼åŠ å…¥çŸ¥è­˜åº«")
            print(f"{'='*60}\n")

            return result

        except Exception as e:
            # æ›´æ–°ä½œæ¥­ç‹€æ…‹ç‚ºå¤±æ•—ï¼ˆä½¿ç”¨çµ±ä¸€ Job æœå‹™çš„æ–¹æ³•ï¼‰
            error_message = str(e)
            print(f"\nâŒ åŒ¯å…¥å¤±æ•—: {error_message}")
            await self.update_status(
                job_id,
                status="failed",
                error_message=error_message
            )
            raise

    def _detect_file_type(self, file_path: str) -> str:
        """
        åµæ¸¬æª”æ¡ˆé¡å‹

        Args:
            file_path: æª”æ¡ˆè·¯å¾‘

        Returns:
            æª”æ¡ˆé¡å‹ï¼ˆexcel, csv, pdf, txt, jsonï¼‰
        """
        suffix = Path(file_path).suffix.lower()

        if suffix in ['.xlsx', '.xls']:
            return 'excel'
        elif suffix == '.csv':
            return 'csv'
        elif suffix == '.pdf':
            return 'pdf'
        elif suffix == '.txt':
            return 'txt'
        elif suffix == '.json':
            return 'json'
        else:
            return 'unknown'

    async def _detect_import_source(
        self,
        original_filename: str,
        file_type: str,
        knowledge_list: List[Dict]
    ) -> Tuple[str, str]:
        """
        åµæ¸¬åŒ¯å…¥ä¾†æºé¡å‹

        Args:
            original_filename: åŸå§‹æª”æ¡ˆåç¨±ï¼ˆéè‡¨æ™‚è·¯å¾‘ï¼‰
            file_type: æª”æ¡ˆé¡å‹ï¼ˆexcel, csv, json, txt, pdfï¼‰
            knowledge_list: è§£æå¾Œçš„çŸ¥è­˜åˆ—è¡¨

        Returns:
            (source_type, import_source) tuple:
            - source_type: 'ai_generated' | 'spec_import' | 'external_file' | 'line_chat'
            - import_source: 'system_export' | 'external_excel' | 'external_json' | 'spec_docx' | 'spec_pdf' | 'line_chat_txt'
        """
        file_name = original_filename.lower()

        # 1. æª¢æŸ¥æ˜¯å¦ç‚ºç³»çµ±åŒ¯å‡ºæª”æ¡ˆ
        if file_type == 'excel' and knowledge_list:
            # ç³»çµ±åŒ¯å‡ºæª”æ¡ˆæœ‰ç‰¹å®šçš„æ¬„ä½çµæ§‹ï¼ˆ9 å€‹å›ºå®šæ¬„ä½ï¼‰
            expected_fields = {
                'question_summary', 'answer', 'scope', 'vendor_id',
                'business_types', 'target_user', 'intent_names',
                'keywords', 'priority'
            }
            first_item_fields = set(knowledge_list[0].keys())

            # å¦‚æœåŒ…å«æ‰€æœ‰é æœŸæ¬„ä½ï¼Œåˆ¤å®šç‚ºç³»çµ±åŒ¯å‡º
            if expected_fields.issubset(first_item_fields):
                print("ğŸ” åµæ¸¬åˆ°ç³»çµ±åŒ¯å‡ºæª”æ¡ˆï¼ˆåŒ…å« 9 å€‹æ¨™æº–æ¬„ä½ï¼‰")
                return ('external_file', 'system_export')

        # 2. æª¢æŸ¥æ˜¯å¦ç‚ºå°è©±è¨˜éŒ„
        # LINE å°è©±è¨˜éŒ„çš„ä¸»è¦ç›®çš„æ˜¯æå–æ¸¬è©¦æƒ…å¢ƒï¼Œè€Œä¸æ˜¯æå–çŸ¥è­˜
        if file_type == 'txt' and ('èŠå¤©' in file_name or 'chat' in file_name.lower()):
            print("ğŸ” åµæ¸¬åˆ°å°è©±è¨˜éŒ„æª”æ¡ˆ")
            return ('line_chat', 'line_chat_txt')

        # 3. æª¢æŸ¥æ˜¯å¦ç‚ºè¦æ ¼æ›¸
        if file_type == 'pdf' or 'è¦æ ¼' in file_name or 'spec' in file_name or 'specification' in file_name:
            if file_type == 'pdf':
                print("ğŸ” åµæ¸¬åˆ°è¦æ ¼æ›¸ PDF æª”æ¡ˆ")
                return ('spec_import', 'spec_pdf')
            else:
                print("ğŸ” åµæ¸¬åˆ°è¦æ ¼æ›¸ Word æª”æ¡ˆ")
                return ('spec_import', 'spec_docx')

        # 4. å…¶ä»–å¤–éƒ¨æª”æ¡ˆ
        if file_type == 'excel':
            print("ğŸ” åµæ¸¬åˆ°å¤–éƒ¨ Excel æª”æ¡ˆ")
            return ('external_file', 'external_excel')
        elif file_type == 'json':
            print("ğŸ” åµæ¸¬åˆ°å¤–éƒ¨ JSON æª”æ¡ˆ")
            return ('external_file', 'external_json')
        elif file_type == 'csv':
            print("ğŸ” åµæ¸¬åˆ°å¤–éƒ¨ CSV æª”æ¡ˆ")
            return ('external_file', 'external_csv')
        else:
            print(f"ğŸ” åµæ¸¬åˆ°æœªçŸ¥é¡å‹æª”æ¡ˆï¼ˆ{file_type}ï¼‰ï¼Œé è¨­ç‚ºå¤–éƒ¨æª”æ¡ˆ")
            return ('external_file', 'external_unknown')

    async def _load_target_user_config(self) -> Dict[str, str]:
        """
        å¾è³‡æ–™åº«åŠ è¼‰ç›®æ¨™ç”¨æˆ¶é…ç½®

        Returns:
            æ˜ å°„å­—å…¸ {ä¸­æ–‡é¡¯ç¤ºåç¨±/è‹±æ–‡å€¼: è‹±æ–‡å€¼}
            ä¾‹å¦‚: {'ç§Ÿå®¢': 'tenant', 'tenant': 'tenant', 'æˆ¿æ±': 'landlord', ...}
        """
        # ä½¿ç”¨ 5 åˆ†é˜ç·©å­˜
        if self._target_user_config_cache is not None:
            if self._target_user_cache_time is not None:
                cache_age = time.time() - self._target_user_cache_time
                if cache_age < 300:  # 5 åˆ†é˜å…§ä½¿ç”¨ç·©å­˜
                    return self._target_user_config_cache

        try:
            async with self.db_pool.acquire() as conn:
                rows = await conn.fetch("""
                    SELECT user_value, display_name
                    FROM target_user_config
                    WHERE is_active = true
                    ORDER BY id
                """)

                # å»ºç«‹é›™å‘æ˜ å°„ï¼ˆä¸­æ–‡ -> è‹±æ–‡ï¼Œè‹±æ–‡ -> è‹±æ–‡ï¼‰
                mapping = {}
                for row in rows:
                    user_value = row['user_value']
                    display_name = row['display_name']

                    # è‹±æ–‡å€¼å°æ‡‰è‡ªå·±
                    mapping[user_value.lower()] = user_value

                    # ä¸­æ–‡é¡¯ç¤ºåç¨±å°æ‡‰è‹±æ–‡å€¼
                    if display_name:
                        mapping[display_name.lower()] = user_value

                # æ›´æ–°ç·©å­˜
                self._target_user_config_cache = mapping
                self._target_user_cache_time = time.time()

                print(f"âœ… å·²åŠ è¼‰ {len(rows)} å€‹ç›®æ¨™ç”¨æˆ¶é…ç½®")
                return mapping

        except Exception as e:
            print(f"âš ï¸  åŠ è¼‰ç›®æ¨™ç”¨æˆ¶é…ç½®å¤±æ•—: {e}")
            # è¿”å›æœ€å°é»˜èªé…ç½®
            return {
                'tenant': 'tenant',
                'ç§Ÿå®¢': 'tenant',
                'landlord': 'landlord',
                'æˆ¿æ±': 'landlord',
                'property_manager': 'property_manager',
                'ç‰©æ¥­ç®¡ç†å¸«': 'property_manager',
                'system_admin': 'system_admin',
                'ç³»çµ±ç®¡ç†å“¡': 'system_admin',
            }

    async def _normalize_target_user(self, audience: str) -> str:
        """
        å°‡ä¸­æ–‡æˆ–è‹±æ–‡ audience è½‰æ›ç‚ºæ¨™æº–çš„è‹±æ–‡ target_user å€¼

        å¾è³‡æ–™åº« target_user_config è¡¨å‹•æ…‹åŠ è¼‰é…ç½®
        æ”¯æ´ä¸­æ–‡é¡¯ç¤ºåç¨±ï¼ˆå¦‚ã€Œç§Ÿå®¢ã€ï¼‰å’Œè‹±æ–‡å€¼ï¼ˆå¦‚ã€Œtenantã€ï¼‰

        Args:
            audience: ä¸­æ–‡æˆ–è‹±æ–‡çš„å°è±¡æè¿°

        Returns:
            æ¨™æº–åŒ–çš„è‹±æ–‡å€¼ï¼ˆå¾è³‡æ–™åº« target_user_config.user_value å–å¾—ï¼‰
        """
        if not audience:
            return 'tenant'  # é»˜èªå€¼

        # å¾è³‡æ–™åº«åŠ è¼‰é…ç½®ï¼ˆå¸¶ç·©å­˜ï¼‰
        mapping = await self._load_target_user_config()

        # è½‰æ›ç‚ºå°å¯«ä¸¦å»é™¤ç©ºç™½
        key = audience.strip().lower()

        # æŸ¥æ‰¾æ˜ å°„
        if key in mapping:
            return mapping[key]

        # å¦‚æœæ²’æœ‰åŒ¹é…ï¼Œé»˜èªè¿”å› tenant
        print(f"   âš ï¸  æœªçŸ¥çš„ç›®æ¨™ç”¨æˆ¶å€¼: {audience}ï¼Œä½¿ç”¨é»˜èªå€¼ tenant")
        return 'tenant'

    def _clean_html(self, html_text: str) -> str:
        """
        æ¸…ç† HTML æ¨™ç±¤ï¼Œä¿ç•™æ–‡å­—å…§å®¹ä¸¦ç¶­æŒé©ç•¶æ ¼å¼

        ä½¿ç”¨ BeautifulSoup é€²è¡Œæ™ºèƒ½ HTML æ¸…ç†ï¼š
        - ç§»é™¤æ‰€æœ‰ style å±¬æ€§
        - ç§»é™¤ script å’Œ style æ¨™ç±¤
        - ä¿ç•™åŸºæœ¬æ®µè½çµæ§‹ï¼ˆ<p>ã€<br> è½‰æ›ç‚ºæ›è¡Œï¼‰
        - ä¿ç•™åˆ—è¡¨çµæ§‹ï¼ˆ<li> æ·»åŠ é …ç›®ç¬¦è™Ÿï¼‰
        - ç§»é™¤æ‰€æœ‰å…¶ä»– HTML æ¨™ç±¤
        - æ¸…ç†å¤šé¤˜ç©ºç™½

        Args:
            html_text: åŒ…å« HTML æ¨™ç±¤çš„æ–‡å­—

        Returns:
            æ¸…ç†å¾Œçš„ç´”æ–‡å­—
        """
        # å¦‚æœä¸åŒ…å« HTML æ¨™ç±¤ï¼Œç›´æ¥è¿”å›
        if '<' not in html_text or '>' not in html_text:
            return html_text

        try:
            from bs4 import BeautifulSoup

            # è§£æ HTML
            soup = BeautifulSoup(html_text, 'lxml')

            # ç§»é™¤ script å’Œ style æ¨™ç±¤
            for tag in soup(['script', 'style']):
                tag.decompose()

            # ç§»é™¤æ‰€æœ‰ style å±¬æ€§
            for tag in soup.find_all(True):
                if 'style' in tag.attrs:
                    del tag.attrs['style']

            # è™•ç†æ®µè½å’Œæ›è¡Œ
            for p in soup.find_all('p'):
                p.insert_after(soup.new_string('\n\n'))

            for br in soup.find_all('br'):
                br.replace_with(soup.new_string('\n'))

            # è™•ç†åˆ—è¡¨é …ç›®
            for li in soup.find_all('li'):
                li.insert_before(soup.new_string('â€¢ '))
                li.insert_after(soup.new_string('\n'))

            # æå–ç´”æ–‡å­—
            text = soup.get_text()

            # æ¸…ç†å¤šé¤˜ç©ºç™½
            import re
            # ç§»é™¤æ¯è¡Œå‰å¾Œçš„ç©ºç™½
            lines = [line.strip() for line in text.split('\n')]
            # ç§»é™¤ç©ºè¡Œï¼ˆä½†ä¿ç•™å–®å€‹æ›è¡Œï¼‰
            text = '\n'.join(lines)
            # å°‡é€£çºŒ 3 å€‹ä»¥ä¸Šçš„æ›è¡Œç¬¦ç¸®æ¸›ç‚º 2 å€‹
            text = re.sub(r'\n{3,}', '\n\n', text)

            return text.strip()

        except Exception as e:
            print(f"   âš ï¸  HTML æ¸…ç†å¤±æ•—: {str(e)}ï¼Œä½¿ç”¨åŸå§‹æ–‡å­—")
            return html_text

    async def _parse_file(self, file_path: str, file_type: str) -> List[Dict]:
        """
        è§£ææª”æ¡ˆ

        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            file_type: æª”æ¡ˆé¡å‹

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        if file_type == 'excel':
            return await self._parse_excel(file_path)
        elif file_type == 'csv':
            return await self._parse_csv(file_path)
        elif file_type == 'txt':
            return await self._parse_txt(file_path)
        elif file_type == 'json':
            return await self._parse_json(file_path)
        elif file_type == 'pdf':
            return await self._parse_pdf(file_path)
        else:
            raise Exception(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {file_type}")

    async def _parse_excel(self, file_path: str) -> List[Dict]:
        """
        è§£æ Excel æª”æ¡ˆ

        æ”¯æ´æ ¼å¼ï¼š
        1. ä¸€èˆ¬æ ¼å¼ï¼šç¬¬ 1 è¡Œç‚ºæ¨™é¡Œ
           - æ¬„ä½: å•é¡Œ / question / å•é¡Œæ‘˜è¦
           - æ¬„ä½: ç­”æ¡ˆ / answer / å›è¦†
        2. ç§Ÿç®¡æ¥­æ ¼å¼ï¼šç¬¬ 1 è¡Œç‚ºæ¥­è€…æ¨™ç±¤ï¼ˆç‰©æ¥­ | æ¥­è€…åç¨±ï¼‰ï¼Œç¬¬ 2 è¡Œç‚ºæ¨™é¡Œ
           - ç¬¬ 1 è¡Œ: ç‰©æ¥­ | xxx
           - ç¬¬ 2 è¡Œ: å•é¡Œ | å›ç­” | ...

        Args:
            file_path: Excel æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ Excel æª”æ¡ˆ: {file_path}")

        # å…ˆè®€å–ç¬¬ä¸€è¡Œï¼Œæª¢æŸ¥æ˜¯å¦ç‚ºç§Ÿç®¡æ¥­æ ¼å¼
        df_first_row = pd.read_excel(file_path, engine='openpyxl', header=None, nrows=1)

        has_vendor_label = False
        vendor_label = None
        if pd.notna(df_first_row.iloc[0, 0]) and 'ç‰©æ¥­' in str(df_first_row.iloc[0, 0]):
            has_vendor_label = True
            if pd.notna(df_first_row.iloc[0, 1]):
                vendor_label = str(df_first_row.iloc[0, 1]).strip()
            print(f"   ğŸ¢ åµæ¸¬åˆ°ç§Ÿç®¡æ¥­æ ¼å¼ï¼ˆæ¥­è€…: {vendor_label}ï¼‰")

        # æ ¹æ“šæ ¼å¼é¸æ“‡ header è¡Œ
        if has_vendor_label:
            df = pd.read_excel(file_path, engine='openpyxl', header=1)  # ç¬¬ 2 è¡Œä½œç‚ºæ¨™é¡Œ
        else:
            df = pd.read_excel(file_path, engine='openpyxl')  # ç¬¬ 1 è¡Œä½œç‚ºæ¨™é¡Œ

        print(f"   è®€å– {len(df)} è¡Œè³‡æ–™")
        print(f"   æ¬„ä½: {list(df.columns)}")

        # æ¬„ä½æ˜ å°„ï¼ˆæ”¯æ´å¤šç¨®æ¬„ä½åç¨±ï¼‰
        id_cols = ['id', 'ID', 'çŸ¥è­˜ID', 'knowledge_id']  # ID æ¬„ä½ï¼ˆç”¨æ–¼æ›´æ–°ï¼‰
        question_cols = ['å•é¡Œ', 'question', 'å•é¡Œæ‘˜è¦', 'question_summary', 'title', 'æ¨™é¡Œ', 'ç§Ÿå®¢å¸¸å•Q', 'ç§Ÿå®¢å¸¸å•Q', 'å¸¸å•å•é¡Œ']
        answer_cols = ['ç­”æ¡ˆ', 'answer', 'å›ç­”', 'å›è¦†', 'response', 'content', 'å…§å®¹', 'ä¼æ¥­å¸Œæœ›çš„æ¨™æº–A', 'æ¨™æº–A', 'æ¨™æº–ç­”æ¡ˆ']
        audience_cols = ['å°è±¡', 'audience', 'å—çœ¾']
        keywords_cols = ['é—œéµå­—', 'keywords', 'æ¨™ç±¤', 'tags']
        intent_cols = ['æ„åœ–', 'intent', 'åˆ†é¡', 'category', 'åˆ†é¡åˆ¥', 'åˆ†é¡åˆ¥ (å¯è‡ªè¨‚åˆ†é¡)']  # æ–°å¢ï¼šæ„åœ–æ¬„ä½
        subcategory_cols = ['æ¬¡åˆ†é¡', 'subcategory', 'æ¬¡é¡åˆ¥', 'æ¬¡é¡åˆ¥ (å¯è‡ªè¨‚åˆ†é¡)']  # æ–°å¢ï¼šæ¬¡åˆ†é¡æ¬„ä½
        business_type_cols = ['æ¥­æ…‹é¡å‹', 'business_type', 'business_types', 'æ¥­æ…‹', 'è¡Œæ¥­é¡å‹']  # æ–°å¢ï¼šæ¥­æ…‹é¡å‹æ¬„ä½

        # æ‰¾åˆ°å°æ‡‰çš„æ¬„ä½
        id_col = next((col for col in df.columns if col in id_cols), None)  # ID æ¬„ä½ï¼ˆå¯é¸ï¼‰
        question_col = next((col for col in df.columns if col in question_cols), None)
        answer_col = next((col for col in df.columns if col in answer_cols), None)
        audience_col = next((col for col in df.columns if col in audience_cols), None)
        keywords_col = next((col for col in df.columns if col in keywords_cols), None)
        intent_col = next((col for col in df.columns if col in intent_cols), None)  # æ–°å¢
        subcategory_col = next((col for col in df.columns if col in subcategory_cols), None)  # æ–°å¢
        business_type_col = next((col for col in df.columns if col in business_type_cols), None)  # æ–°å¢

        # é »ç‡æ¬„ä½ï¼ˆç§Ÿç®¡æ¥­æ ¼å¼ï¼šå¯èƒ½åŒ…å«æ›è¡Œç¬¦ï¼‰
        frequency_col = next((col for col in df.columns if 'é »ç‡' in col or 'frequency' in col.lower()), None)

        if not answer_col:
            raise Exception(f"æ‰¾ä¸åˆ°ç­”æ¡ˆæ¬„ä½ã€‚æ”¯æ´çš„æ¬„ä½åç¨±: {', '.join(answer_cols)}")

        knowledge_list = []

        for idx, row in df.iterrows():
            # è§£æ IDï¼ˆå¯é¸ï¼Œç”¨æ–¼æ›´æ–°ç¾æœ‰çŸ¥è­˜ï¼‰
            knowledge_id = None
            if id_col and pd.notna(row[id_col]):
                try:
                    knowledge_id = int(row[id_col])
                except (ValueError, TypeError):
                    pass  # ID ç„¡æ•ˆï¼Œè¦–ç‚ºæ–°å¢

            # è§£æç­”æ¡ˆï¼ˆå¿…å¡«ï¼‰
            answer = row.get(answer_col)
            if pd.isna(answer) or not str(answer).strip() or len(str(answer).strip()) < 10:
                continue

            answer = str(answer).strip()

            # HTML æ¸…ç†ï¼ˆä½¿ç”¨ BeautifulSoupï¼‰
            answer = self._clean_html(answer)

            # è§£æå•é¡Œï¼ˆå¯é¸ï¼Œå¦‚æœæ²’æœ‰æœƒç”¨ LLM ç”Ÿæˆï¼‰
            question = None
            if question_col and pd.notna(row[question_col]):
                question = str(row[question_col]).strip()

            # è§£æå°è±¡ï¼ˆè½‰æ›ç‚ºæ¨™æº–è‹±æ–‡ target_userï¼‰
            audience = 'tenant'  # é è¨­è‹±æ–‡å€¼
            if audience_col and pd.notna(row[audience_col]):
                audience = str(row[audience_col]).strip()
                audience = await self._normalize_target_user(audience)
            else:
                audience = await self._normalize_target_user(audience)

            # è§£æé—œéµå­—
            keywords = []
            if keywords_col and pd.notna(row[keywords_col]):
                keywords_str = str(row[keywords_col])
                keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]

            # è§£ææ„åœ–ï¼ˆå¦‚æœ Excel æœ‰æä¾›ï¼‰
            intent = None
            if intent_col and pd.notna(row[intent_col]):
                intent = str(row[intent_col]).strip()

            # è§£ææ¬¡åˆ†é¡ï¼ˆå¯ä½œç‚º keywordsï¼‰
            if subcategory_col and pd.notna(row[subcategory_col]):
                subcategory = str(row[subcategory_col]).strip()
                if subcategory and subcategory not in keywords:
                    keywords.append(subcategory)

            # è§£ææ¥­æ…‹é¡å‹ï¼ˆæ”¯æ´é€—è™Ÿåˆ†éš”å¤šå€‹æ¥­æ…‹ï¼‰
            business_types = []
            if business_type_col and pd.notna(row[business_type_col]):
                business_types_str = str(row[business_type_col])
                business_types = [bt.strip() for bt in business_types_str.split(',') if bt.strip()]

            knowledge_list.append({
                'id': knowledge_id,  # IDï¼ˆç”¨æ–¼æ›´æ–°ï¼ŒNone è¡¨ç¤ºæ–°å¢ï¼‰
                'question_summary': question,  # å¯èƒ½ç‚º Noneï¼Œå¾ŒçºŒç”¨ LLM ç”Ÿæˆ
                'answer': answer,
                'target_user': audience,  # ä½¿ç”¨æ¨™æº–åŒ–çš„è‹±æ–‡å€¼
                'keywords': keywords,
                'intent': intent,  # æ–°å¢ï¼šä¾†è‡ª Excel çš„æ„åœ–
                'business_types': business_types,  # æ–°å¢ï¼šä¾†è‡ª Excel çš„æ¥­æ…‹é¡å‹
                'source_file': Path(file_path).name
            })

        print(f"   âœ… è§£æå‡º {len(knowledge_list)} å€‹æœ‰æ•ˆçŸ¥è­˜é …ç›®")
        return knowledge_list

    async def _parse_csv(self, file_path: str) -> List[Dict]:
        """
        è§£æ CSV æª”æ¡ˆï¼ˆåŠ å¼·ç‰ˆï¼šæ”¯æ´ JSON æ¬„ä½æ ¼å¼ï¼‰

        æ”¯æ´æ ¼å¼ï¼š
        1. æ¨™æº– CSV æ ¼å¼ï¼š
           - æ¬„ä½: å•é¡Œ / question / å•é¡Œæ‘˜è¦ / title
           - æ¬„ä½: ç­”æ¡ˆ / answer / å›è¦† / content
           - æ¬„ä½: å°è±¡ / audience (å¯é¸)
           - æ¬„ä½: é—œéµå­— / keywords (å¯é¸)

        2. JSON æ¬„ä½æ ¼å¼ï¼ˆå¦‚ help_datas.csvï¼‰ï¼š
           - æ¬„ä½å€¼ç‚º JSON å­—ä¸²ï¼Œè‡ªå‹•æå– zh-TW èªç³»
           - ä¾‹å¦‚: {"zh-TW":"ç‰©ä»¶","en-US":"Property"}

        Args:
            file_path: CSV æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ CSV æª”æ¡ˆ: {file_path}")

        # è®€å– CSVï¼Œpandas æœƒè‡ªå‹•è™•ç†ç·¨ç¢¼
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
        except UnicodeDecodeError:
            # å¦‚æœ UTF-8 å¤±æ•—ï¼Œå˜—è©¦å…¶ä»–ç·¨ç¢¼
            df = pd.read_csv(file_path, encoding='utf-8-sig')

        print(f"   è®€å– {len(df)} è¡Œè³‡æ–™")
        print(f"   æ¬„ä½: {list(df.columns)}")

        # æ¬„ä½æ˜ å°„ï¼ˆæ”¯æ´å¤šç¨®æ¬„ä½åç¨±ï¼‰
        question_cols = ['å•é¡Œ', 'question', 'å•é¡Œæ‘˜è¦', 'question_summary', 'title', 'æ¨™é¡Œ']
        answer_cols = ['ç­”æ¡ˆ', 'answer', 'å›è¦†', 'response', 'content', 'å…§å®¹']
        audience_cols = ['å°è±¡', 'audience', 'å—çœ¾', 'target_user']
        keywords_cols = ['é—œéµå­—', 'keywords', 'æ¨™ç±¤', 'tags']
        intent_id_cols = ['æ„åœ–ID', 'intent_id', 'intent', 'æ„åœ–']

        # æ‰¾åˆ°å°æ‡‰çš„æ¬„ä½
        question_col = next((col for col in df.columns if col in question_cols), None)
        answer_col = next((col for col in df.columns if col in answer_cols), None)
        audience_col = next((col for col in df.columns if col in audience_cols), None)
        keywords_col = next((col for col in df.columns if col in keywords_cols), None)
        intent_id_col = next((col for col in df.columns if col in intent_id_cols), None)

        # å¦‚æœæ‰¾ä¸åˆ°æ¨™æº–æ¬„ä½åç¨±ï¼Œå˜—è©¦ä½¿ç”¨ä½ç½®æ¨æ¸¬
        # help_datas.csv æ ¼å¼: title, title.1, content (å•é¡Œ, ç­”æ¡ˆ)
        if not answer_col and len(df.columns) >= 2:
            # æª¢æŸ¥æ˜¯å¦ç‚º help_datas.csv æ ¼å¼ï¼ˆæœ€å¾Œä¸€æ¬„é€šå¸¸æ˜¯ç­”æ¡ˆï¼‰
            if 'content' in df.columns:
                question_col = df.columns[0] if len(df.columns) > 1 else None  # ç¬¬ä¸€æ¬„ï¼šå•é¡Œ
                answer_col = 'content'        # ç­”æ¡ˆæ¬„
                print(f"   åµæ¸¬åˆ°ç‰¹æ®Šæ ¼å¼ CSVï¼Œä½¿ç”¨æ¬„ä½: {question_col}, {answer_col}")

        if not answer_col:
            raise Exception(f"æ‰¾ä¸åˆ°ç­”æ¡ˆæ¬„ä½ã€‚æ”¯æ´çš„æ¬„ä½åç¨±: {', '.join(answer_cols)}\nå¯¦éš›æ¬„ä½: {list(df.columns)}")

        knowledge_list = []

        for idx, row in df.iterrows():
            try:
                # === 1. è§£æå•é¡Œï¼ˆæ”¯æ´ JSON æ ¼å¼ï¼‰ ===
                question = None
                if question_col and pd.notna(row[question_col]):
                    q_value = str(row[question_col]).strip()
                    # æª¢æŸ¥æ˜¯å¦ç‚º JSON æ ¼å¼
                    if q_value.startswith('{') and q_value.endswith('}'):
                        try:
                            q_json = json.loads(q_value)
                            question = q_json.get('zh-TW', q_json.get('zh-tw'))
                        except json.JSONDecodeError:
                            question = q_value
                    else:
                        question = q_value

                # === 3. è§£æç­”æ¡ˆï¼ˆæ”¯æ´ JSON æ ¼å¼ï¼‰ ===
                answer = None
                if pd.notna(row[answer_col]):
                    a_value = str(row[answer_col]).strip()
                    # æª¢æŸ¥æ˜¯å¦ç‚º JSON æ ¼å¼
                    if a_value.startswith('{') and a_value.endswith('}'):
                        try:
                            a_json = json.loads(a_value)
                            answer = a_json.get('zh-TW', a_json.get('zh-tw'))
                        except json.JSONDecodeError:
                            answer = a_value
                    else:
                        answer = a_value

                # é©—è­‰ç­”æ¡ˆæœ‰æ•ˆæ€§
                if not answer or len(answer.strip()) < 10:
                    continue

                answer = answer.strip()

                # === 4. HTML æ¸…ç†ï¼ˆä½¿ç”¨ BeautifulSoupï¼‰ ===
                answer = self._clean_html(answer)

                # === 5. è§£æå°è±¡ï¼ˆè½‰æ›ç‚ºæ¨™æº–è‹±æ–‡ target_userï¼‰ ===
                audience = 'tenant'  # é è¨­è‹±æ–‡å€¼
                if audience_col and pd.notna(row[audience_col]):
                    audience = str(row[audience_col]).strip()
                    audience = await self._normalize_target_user(audience)
                else:
                    audience = await self._normalize_target_user(audience)

                # === 6. è§£æé—œéµå­— ===
                keywords = []
                if keywords_col and pd.notna(row[keywords_col]):
                    keywords_str = str(row[keywords_col])
                    keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]

                # === 7. è§£ææ„åœ– ID ===
                intent_id = None
                if intent_id_col and pd.notna(row[intent_id_col]):
                    try:
                        intent_id_value = row[intent_id_col]
                        # è™•ç†ä¸åŒé¡å‹çš„å€¼
                        if isinstance(intent_id_value, (int, float)):
                            intent_id = int(intent_id_value)
                        elif isinstance(intent_id_value, str):
                            intent_id_value = intent_id_value.strip()
                            if intent_id_value.isdigit():
                                intent_id = int(intent_id_value)
                    except (ValueError, TypeError):
                        print(f"   âš ï¸  ç¬¬ {idx + 1} è¡Œæ„åœ– ID æ ¼å¼éŒ¯èª¤: {row[intent_id_col]}")

                # === 8. å»ºç«‹çŸ¥è­˜é …ç›® ===
                knowledge_list.append({
                    'question_summary': question,  # å¯èƒ½ç‚º Noneï¼Œå¾ŒçºŒç”¨ LLM ç”Ÿæˆ
                    'answer': answer,
                    'target_user': audience,  # ä½¿ç”¨æ¨™æº–åŒ–çš„è‹±æ–‡å€¼
                    'keywords': keywords,
                    'intent_id': intent_id,  # é è¨­æ„åœ– IDï¼ˆå¯èƒ½ç‚º Noneï¼‰
                    'source_file': Path(file_path).name
                })

            except Exception as e:
                print(f"   âš ï¸  ç¬¬ {idx + 1} è¡Œè§£æå¤±æ•—: {str(e)}")
                continue

        print(f"   âœ… è§£æå‡º {len(knowledge_list)} å€‹æœ‰æ•ˆçŸ¥è­˜é …ç›®")
        return knowledge_list

    async def _parse_txt(self, file_path: str) -> List[Dict]:
        """
        è§£æç´”æ–‡å­—æª”æ¡ˆï¼ˆä½¿ç”¨ LLM æå–çŸ¥è­˜ï¼‰

        æ”¯æ´æ™ºèƒ½åˆ†æ®µè™•ç†ï¼š
        - < 50KB: å®Œæ•´è™•ç†
        - 50KB - 200KB: å–®æ¬¡è™•ç†ï¼ˆå–å‰ 40,000 å­—å…ƒï¼‰
        - > 200KB: åˆ†æ®µè™•ç†ï¼ˆæ¯æ®µ 40,000 å­—å…ƒï¼Œé‡ç–Š 2,000ï¼‰

        Args:
            file_path: æ–‡å­—æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ TXT æª”æ¡ˆ: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        if len(content) < 50:
            raise Exception("æª”æ¡ˆå…§å®¹éçŸ­ï¼Œç„¡æ³•æå–çŸ¥è­˜")

        # æ™ºèƒ½é¸æ“‡è™•ç†ç­–ç•¥
        file_size = len(content)
        file_size_kb = file_size / 1024

        print(f"   æª”æ¡ˆå¤§å°: {file_size_kb:.1f} KB")

        # ç­–ç•¥é¸æ“‡
        if file_size > 200000:  # å¤§æ–¼ 200KB
            print(f"   ğŸ“Š æ¡ç”¨åˆ†æ®µè™•ç†ç­–ç•¥ï¼ˆæª”æ¡ˆè¼ƒå¤§ï¼‰")
            return await self._parse_txt_with_chunking(file_path, content)

        elif file_size > 50000:  # 50KB - 200KB
            print(f"   ğŸ“Š æ¡ç”¨å–®æ¬¡è™•ç†ç­–ç•¥ï¼ˆå–å‰ 40,000 å­—å…ƒï¼‰")
            content_to_process = content[:40000]  # gpt-4o å¯ä»¥è™•ç†
            max_tokens = 4000

        else:  # å°æ–¼ 50KB
            print(f"   ğŸ“Š æ¡ç”¨å®Œæ•´è™•ç†ç­–ç•¥ï¼ˆæª”æ¡ˆè¼ƒå°ï¼‰")
            content_to_process = content
            max_tokens = 4000

        # ä½¿ç”¨ LLM æå–çŸ¥è­˜ï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰
        print("ğŸ¤– ä½¿ç”¨ LLM æå–çŸ¥è­˜...")

        max_retries = 3
        for retry in range(max_retries):
            try:
                response = await self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    temperature=0,  # æ”¹ç‚º 0ï¼Œç¢ºä¿ä¸€è‡´æ€§
                    max_tokens=max_tokens,  # å‹•æ…‹è¨­å®š
                    response_format={"type": "json_object"},
                    messages=[
                        {"role": "system", "content": self._get_extraction_prompt()},
                        {"role": "user", "content": f"è«‹å¾ä»¥ä¸‹å…§å®¹æå–çŸ¥è­˜ï¼š\n\n{content_to_process}"}
                    ]
                )

                result = json.loads(response.choices[0].message.content)
                knowledge_list = result.get('knowledge_list', [])
                break  # æˆåŠŸå‰‡è·³å‡º

            except Exception as e:
                error_str = str(e)
                if 'rate_limit' in error_str.lower() or '429' in error_str:
                    wait_time = 10 * (retry + 1)
                    if retry < max_retries - 1:
                        print(f"   âš ï¸ é€Ÿç‡é™åˆ¶ï¼Œ{wait_time}ç§’å¾Œé‡è©¦ ({retry + 1}/{max_retries})...")
                        import asyncio
                        await asyncio.sleep(wait_time)
                    else:
                        print(f"   âŒ LLM æå–å¤±æ•—ï¼ˆå·²é‡è©¦{max_retries}æ¬¡ï¼‰: {e}")
                        raise Exception(f"ç„¡æ³•å¾æ–‡å­—æª”æ¡ˆæå–çŸ¥è­˜: {e}")
                else:
                    print(f"   âš ï¸ LLM æå–å¤±æ•—: {e}")
                    raise Exception(f"ç„¡æ³•å¾æ–‡å­—æª”æ¡ˆæå–çŸ¥è­˜: {e}")

        try:

            # èª¿è©¦ï¼šé¡¯ç¤º LLM è§£æçš„å®Œæ•´å…§å®¹
            print(f"\nğŸ“‹ LLM è§£æçµæœ:")
            for idx, k in enumerate(knowledge_list, 1):
                print(f"   {idx}. å•é¡Œ: {k.get('question_summary', 'æœªæä¾›')}")
                print(f"      ç­”æ¡ˆ: {k.get('answer', 'æœªæä¾›')[:50]}...")
                if k.get('warnings'):
                    print(f"      è­¦å‘Š: {', '.join(k['warnings'])}")

            # æ·»åŠ ä¾†æºè³‡è¨Šä¸¦æª¢æŸ¥æ³›åŒ–è­¦å‘Š
            generalized_count = 0
            for knowledge in knowledge_list:
                knowledge['source_file'] = Path(file_path).name

                # çµ±è¨ˆæœ‰æ³›åŒ–è­¦å‘Šçš„çŸ¥è­˜
                if knowledge.get('warnings'):
                    generalized_count += 1
                    print(f"   âš ï¸  æ³›åŒ–è­¦å‘Š: {knowledge['question_summary'][:30]}... - {knowledge['warnings']}")

            print(f"   âœ… æå–å‡º {len(knowledge_list)} å€‹çŸ¥è­˜é …ç›®")
            if generalized_count > 0:
                print(f"   ğŸ”„ å…¶ä¸­ {generalized_count} æ¢çŸ¥è­˜å·²è‡ªå‹•æ³›åŒ–ï¼ˆç§»é™¤ç‰¹å®šç‰©æ¥­/æˆ¿è™Ÿ/æ—¥æœŸï¼‰")
            return knowledge_list

        except Exception as e:
            print(f"   âš ï¸ LLM æå–å¤±æ•—: {e}")
            raise Exception(f"ç„¡æ³•å¾æ–‡å­—æª”æ¡ˆæå–çŸ¥è­˜: {e}")

    def _get_extraction_prompt(self) -> str:
        """
        ç²å–çŸ¥è­˜æå–çš„ system promptï¼ˆçµ±ä¸€ç®¡ç†ï¼‰

        Returns:
            system prompt å…§å®¹
        """
        return """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åº«åˆ†æå¸«ã€‚
å¾æä¾›çš„æ–‡å­—å…§å®¹ä¸­æå–å®¢æœå•ç­”çŸ¥è­˜ã€‚

âš ï¸ é‡è¦ï¼šæå–çš„çŸ¥è­˜å¿…é ˆæ˜¯ã€Œé€šç”¨ã€çš„ã€å¯é‡è¤‡ä½¿ç”¨çš„çŸ¥è­˜ã€‚

è«‹éµå¾ªä»¥ä¸‹æ³›åŒ–è¦å‰‡ï¼š
1. ç§»é™¤ç‰¹å®šç‰©æ¥­/å»ºç‰©åç¨±ï¼ˆå¦‚ï¼šä¸‰è‘‰å¯“æ‰€ â†’ è©²ç‰©æ¥­/ç§Ÿè™•/å»ºç‰©ï¼‰
2. ç§»é™¤ç‰¹å®šæˆ¿è™Ÿ/å–®ä½è™Ÿç¢¼ï¼ˆå¦‚ï¼š2B5ã€5A2 â†’ è©²æˆ¿é–“/è©²å–®ä½/è©²ç§Ÿè™•ï¼‰
3. ç§»é™¤ç‰¹å®šæ—¥æœŸï¼ˆå¦‚ï¼š113/12/31 â†’ åˆ°æœŸæ—¥/æŒ‡å®šæ—¥æœŸï¼‰
4. ç§»é™¤å€‹äººå§“åã€é›»è©±ã€è¯çµ¡æ–¹å¼ç­‰ç§äººè³‡è¨Š
5. **å…¬å¸åç¨±æ³›åŒ–**ï¼šå°‡ç‰¹å®šå…¬å¸åç¨±ï¼ˆå¦‚ï¼šèˆˆä¸­è³‡ç”¢ã€XXç®¡ç†å…¬å¸ï¼‰æ”¹ç‚ºã€Œç‰©æ¥­ç®¡ç†å…¬å¸ã€
6. ä¿ç•™è™•ç†æµç¨‹ã€è¦å‰‡ã€æ”¿ç­–ã€æ³¨æ„äº‹é …ç­‰é€šç”¨çŸ¥è­˜
7. å¦‚æœæŸæ¢çŸ¥è­˜éæ–¼ç‰¹å®šï¼ˆå¦‚ï¼šåƒ…é©ç”¨æ–¼æŸå€‹æˆ¿é–“çš„ç‰¹æ®Šè¨­å‚™ï¼‰ï¼Œè«‹åœ¨ warnings ä¸­è¨»æ˜

æ³›åŒ–ç¯„ä¾‹ï¼š
âŒ åŸæ–‡ï¼šã€Œä¸‰è‘‰å¯“æ‰€-2B5æœ‰ä½é›»åº¦è­¦å ±ï¼Œè‹¥é è¨ˆå¯ç”¨é›»åº¦æ­¸é›¶å°‡æœƒæ–·é›»ï¼Œç…©è«‹ç®¡ç†å¸«å†è¯ç¹«æé†’ç§Ÿå®¢ç›¡å¿«é€²è¡Œé›»éŒ¶å„²å€¼ã€‚ã€
âœ… æ³›åŒ–ï¼šã€Œç•¶ç§Ÿè™•å‡ºç¾ä½é›»åº¦è­¦å ±æ™‚ï¼Œè‹¥é è¨ˆå¯ç”¨é›»åº¦æ­¸é›¶å°‡æœƒæ–·é›»ï¼Œè«‹ç®¡ç†å¸«è¯ç¹«ç§Ÿå®¢ç›¡å¿«é€²è¡Œé›»éŒ¶å„²å€¼ã€‚ã€
âœ… warningsï¼š["åŸæ–‡åŒ…å«ç‰¹å®šç‰©æ¥­åç¨±å’Œæˆ¿è™Ÿ"]

âŒ åŸæ–‡ï¼šã€Œæˆ¿æ±éœ€è¦å°‡ç®¡ç†è²»æ”¯ä»˜çµ¦èˆˆä¸­è³‡ç”¢å…¬å¸ã€‚ã€
âœ… æ³›åŒ–ï¼šã€Œæˆ¿æ±éœ€è¦å°‡ç®¡ç†è²»æ”¯ä»˜çµ¦ç‰©æ¥­ç®¡ç†å…¬å¸ã€‚ã€
âœ… warningsï¼š["å·²å°‡ç‰¹å®šå…¬å¸åç¨±æ³›åŒ–ç‚ºç‰©æ¥­ç®¡ç†å…¬å¸"]

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼š
{
  "knowledge_list": [
    {
      "question_summary": "å•é¡Œæ‘˜è¦ï¼ˆ15å­—ä»¥å…§ï¼‰",
      "answer": "å®Œæ•´ç­”æ¡ˆï¼ˆå·²æ³›åŒ–ï¼‰",
      "target_user": "tenant|landlord|property_manager",
      "keywords": ["é—œéµå­—1", "é—œéµå­—2"],
      "warnings": ["è­¦å‘Šè¨Šæ¯ï¼ˆå¦‚æœæœ‰ç‰¹å®šå…§å®¹è¢«æ³›åŒ–æˆ–ç„¡æ³•æ³›åŒ–ï¼‰"]
    }
  ]
}

æ³¨æ„ï¼š
- åªæå–æ¸…æ™°ã€å®Œæ•´ã€å¯æ³›åŒ–çš„çŸ¥è­˜
- å¦‚æœæŸæ¢è³‡è¨Šéæ–¼ç‰¹å®šï¼ˆå¦‚ï¼šé€šçŸ¥æŸäººæŸäº‹ï¼‰ï¼Œä¸è¦æå–
- å•é¡Œæ‘˜è¦è¦ç°¡æ½”ï¼ˆ15å­—ä»¥å…§ï¼‰
- ç­”æ¡ˆè¦å®Œæ•´ä¸”å¯¦ç”¨
- target_user å¿…é ˆä½¿ç”¨è‹±æ–‡å€¼ï¼ˆtenant=ç§Ÿå®¢, landlord=æˆ¿æ±, property_manager=ç®¡ç†å¸«ï¼‰
- warnings ç‚ºé¸å¡«ï¼Œæ²’æœ‰è­¦å‘Šå¯çœç•¥
"""

    def _deduplicate_knowledge(self, knowledge_list: List[Dict]) -> List[Dict]:
        """
        çŸ¥è­˜å»é‡ï¼ˆåŸºæ–¼ question_summaryï¼‰

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨

        Returns:
            å»é‡å¾Œçš„çŸ¥è­˜åˆ—è¡¨
        """
        seen_questions = set()
        unique_knowledge = []

        for knowledge in knowledge_list:
            question = knowledge.get('question_summary', '')

            # åŸºæ–¼å•é¡Œæ‘˜è¦å»é‡
            if question and question not in seen_questions:
                seen_questions.add(question)
                unique_knowledge.append(knowledge)
            else:
                print(f"   â­ï¸ è·³éé‡è¤‡å•é¡Œ: {question}")

        return unique_knowledge

    async def _parse_txt_with_chunking(self, file_path: str, content: str) -> List[Dict]:
        """
        åˆ†æ®µè§£æé•·æ–‡æœ¬ï¼ˆç”¨æ–¼è¶…é 200KB çš„å°è©±è¨˜éŒ„ï¼‰

        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            content: å®Œæ•´æ–‡å­—å…§å®¹

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“„ æª”æ¡ˆè¼ƒå¤§ ({len(content)} å­—å…ƒ)ï¼Œæ¡ç”¨åˆ†æ®µè™•ç†...")

        # é…ç½®ï¼ˆä½¿ç”¨ gpt-4oï¼Œä¸Šä¸‹æ–‡é™åˆ¶ï¼š128000 tokensï¼‰
        # system_prompt â‰ˆ 800 tokens, max_tokens=4000
        # å¯ç”¨è¼¸å…¥ tokens: 128000 - 800 - 4000 = 123200 tokens
        # ä¸­æ–‡ 1 å­— â‰ˆ 2 tokensï¼Œæ‰€ä»¥: 123200 / 2 â‰ˆ 61600 å­—å…ƒ
        # ä¿å®ˆè¨­å®šç‚º 40000 å­—å…ƒï¼ˆè¶³å¤ å®‰å…¨ï¼‰
        chunk_size = 40000  # æ¯æ®µ 40,000 å­—å…ƒï¼ˆâ‰ˆ80,000 tokensï¼‰
        overlap = 2000      # é‡ç–Š 2,000 å­—å…ƒï¼Œé¿å…åˆ‡æ–·ä¸Šä¸‹æ–‡

        # åˆ†æ®µ
        chunks = []
        for i in range(0, len(content), chunk_size - overlap):
            chunk = content[i:i + chunk_size]
            if len(chunk) > 1000:  # å¿½ç•¥éçŸ­çš„ç‰‡æ®µ
                chunks.append(chunk)

        print(f"   åˆ†ç‚º {len(chunks)} æ®µè™•ç†")

        # é€æ®µæå–çŸ¥è­˜
        all_knowledge = []
        for idx, chunk in enumerate(chunks, 1):
            print(f"   è™•ç†ç¬¬ {idx}/{len(chunks)} æ®µ...")

            # é€Ÿç‡é™åˆ¶é‡è©¦æ©Ÿåˆ¶
            max_retries = 3
            for retry in range(max_retries):
                try:
                    response = await self.openai_client.chat.completions.create(
                        model=self.llm_model,
                        temperature=0,  # ç¢ºä¿ä¸€è‡´æ€§
                        max_tokens=4000,  # æé«˜åˆ° 4000
                        response_format={"type": "json_object"},
                        messages=[
                            {"role": "system", "content": self._get_extraction_prompt()},
                            {"role": "user", "content": f"è«‹å¾ä»¥ä¸‹å…§å®¹æå–çŸ¥è­˜ï¼š\n\n{chunk}"}
                        ]
                    )

                    result = json.loads(response.choices[0].message.content)
                    knowledge_list = result.get('knowledge_list', [])

                    print(f"      æå– {len(knowledge_list)} å€‹çŸ¥è­˜")
                    all_knowledge.extend(knowledge_list)

                    # æˆåŠŸå¾Œæ·»åŠ å°å»¶é²ï¼Œé¿å…é€Ÿç‡é™åˆ¶
                    if idx < len(chunks):
                        import asyncio
                        await asyncio.sleep(2)

                    break  # æˆåŠŸå‰‡è·³å‡ºé‡è©¦å¾ªç’°

                except Exception as e:
                    error_str = str(e)
                    if 'rate_limit' in error_str.lower() or '429' in error_str:
                        # é€Ÿç‡é™åˆ¶éŒ¯èª¤ï¼Œç­‰å¾…å¾Œé‡è©¦
                        wait_time = 10 * (retry + 1)  # éå¢ç­‰å¾…æ™‚é–“
                        if retry < max_retries - 1:
                            print(f"      âš ï¸ é€Ÿç‡é™åˆ¶ï¼Œ{wait_time}ç§’å¾Œé‡è©¦ ({retry + 1}/{max_retries})...")
                            import asyncio
                            await asyncio.sleep(wait_time)
                        else:
                            print(f"      âŒ ç¬¬ {idx} æ®µæå–å¤±æ•—ï¼ˆå·²é‡è©¦{max_retries}æ¬¡ï¼‰: {e}")
                    else:
                        # å…¶ä»–éŒ¯èª¤ï¼Œä¸é‡è©¦
                        print(f"      âš ï¸ ç¬¬ {idx} æ®µæå–å¤±æ•—: {e}")
                        break

        # å»é‡ï¼ˆåŸºæ–¼ question_summaryï¼‰
        unique_knowledge = self._deduplicate_knowledge(all_knowledge)

        print(f"âœ… å…±æå– {len(all_knowledge)} å€‹çŸ¥è­˜ï¼Œå»é‡å¾Œ {len(unique_knowledge)} å€‹")

        # æ·»åŠ ä¾†æºè³‡è¨Š
        for knowledge in unique_knowledge:
            knowledge['source_file'] = Path(file_path).name

        return unique_knowledge

    async def _parse_json(self, file_path: str) -> List[Dict]:
        """
        è§£æ JSON æª”æ¡ˆ

        é æœŸæ ¼å¼ï¼š
        {
          "knowledge": [
            {
              "question": "å•é¡Œ",
              "answer": "ç­”æ¡ˆ",
              "audience": "å°è±¡",
              "keywords": ["é—œéµå­—"]
            }
          ]
        }

        Args:
            file_path: JSON æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        print(f"ğŸ“– è§£æ JSON æª”æ¡ˆ: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # æ”¯æ´å¤šç¨®æ ¼å¼
        if 'knowledge' in data:
            raw_list = data['knowledge']
        elif 'knowledge_list' in data:
            raw_list = data['knowledge_list']
        elif isinstance(data, list):
            raw_list = data
        else:
            raise Exception("ç„¡æ³•è­˜åˆ¥ JSON æ ¼å¼ã€‚é æœŸåŒ…å« 'knowledge' æˆ– 'knowledge_list' æ¬„ä½")

        knowledge_list = []
        for item in raw_list:
            # æ¬„ä½æ˜ å°„
            question = item.get('question') or item.get('question_summary') or item.get('title')
            answer = item.get('answer') or item.get('response') or item.get('content')

            if not answer or len(str(answer).strip()) < 10:
                continue

            # ç²å–ä¸¦æ¨™æº–åŒ– target_user
            raw_audience = item.get('audience') or item.get('target_user') or 'tenant'
            normalized_target_user = await self._normalize_target_user(raw_audience)

            knowledge_list.append({
                'question_summary': question,
                'answer': str(answer).strip(),
                'target_user': normalized_target_user,  # ä½¿ç”¨æ¨™æº–åŒ–çš„è‹±æ–‡å€¼
                'keywords': item.get('keywords', []),
                'source_file': Path(file_path).name
            })

        print(f"   âœ… è§£æå‡º {len(knowledge_list)} å€‹çŸ¥è­˜é …ç›®")
        return knowledge_list

    async def _parse_pdf(self, file_path: str) -> List[Dict]:
        """
        è§£æ PDF æª”æ¡ˆ

        Args:
            file_path: PDF æª”æ¡ˆè·¯å¾‘

        Returns:
            çŸ¥è­˜åˆ—è¡¨
        """
        # TODO: å¯¦ä½œ PDF è§£æï¼ˆéœ€è¦å®‰è£ PyPDF2 æˆ– pdfplumberï¼‰
        raise Exception("PDF æ ¼å¼æš«ä¸æ”¯æ´ï¼Œè«‹å…ˆè½‰æ›ç‚º Excel æˆ– TXT")

    async def _generate_question_summaries(self, knowledge_list: List[Dict]):
        """
        ç‚ºæ²’æœ‰å•é¡Œæ‘˜è¦çš„çŸ¥è­˜ç”Ÿæˆå•é¡Œ

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
        """
        need_generation = [k for k in knowledge_list if not k.get('question_summary')]

        if not need_generation:
            print("âœ… æ‰€æœ‰çŸ¥è­˜éƒ½å·²æœ‰å•é¡Œæ‘˜è¦")
            return

        print(f"ğŸ¤– ç‚º {len(need_generation)} æ¢çŸ¥è­˜ç”Ÿæˆå•é¡Œæ‘˜è¦...")

        for knowledge in need_generation:
            try:
                prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ç­”æ¡ˆï¼Œç”Ÿæˆä¸€å€‹ç°¡æ½”çš„å•é¡Œæ‘˜è¦ï¼ˆ15å­—ä»¥å…§ï¼‰ã€‚

ç­”æ¡ˆï¼š{knowledge['answer'][:200]}

åªè¼¸å‡ºå•é¡Œæ‘˜è¦ï¼Œä¸è¦åŠ å…¶ä»–èªªæ˜ã€‚"""

                response = await self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    temperature=0.3,
                    max_tokens=50,
                    messages=[{"role": "user", "content": prompt}]
                )

                question_summary = response.choices[0].message.content.strip()
                knowledge['question_summary'] = question_summary

                # é¿å… rate limit
                await asyncio.sleep(0.1)

            except Exception as e:
                print(f"   âš ï¸ ç”Ÿæˆå•é¡Œå¤±æ•—: {e}")
                # å‚™ç”¨æ–¹æ¡ˆï¼šä¿æŒ question_summary ç‚º Noneï¼Œå¾ŒçºŒè™•ç†

        print(f"   âœ… å•é¡Œæ‘˜è¦ç”Ÿæˆå®Œæˆ")

    async def _generate_embeddings(self, knowledge_list: List[Dict]):
        """
        ç‚ºçŸ¥è­˜ç”Ÿæˆå‘é‡åµŒå…¥

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
        """
        print(f"ğŸ”® ç‚º {len(knowledge_list)} æ¢çŸ¥è­˜ç”Ÿæˆå‘é‡åµŒå…¥...")

        for idx, knowledge in enumerate(knowledge_list, 1):
            try:
                # çµ„åˆæ–‡å­—ï¼ˆå•é¡Œ + ç­”æ¡ˆå‰æ®µï¼‰
                text = f"{knowledge['question_summary']} {knowledge['answer'][:200]}"

                response = await self.openai_client.embeddings.create(
                    model=self.embedding_model,
                    input=text
                )

                knowledge['embedding'] = response.data[0].embedding

                if idx % 10 == 0:
                    print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

                # é¿å… rate limit
                await asyncio.sleep(0.05)

            except Exception as e:
                print(f"   âš ï¸ ç”Ÿæˆå‘é‡å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                raise Exception(f"å‘é‡ç”Ÿæˆå¤±æ•—: {e}")

        print(f"   âœ… å‘é‡åµŒå…¥ç”Ÿæˆå®Œæˆ")

    async def _deduplicate_exact_match(self, knowledge_list: List[Dict], skip_review: bool = False, vendor_id: Optional[int] = None) -> List[Dict]:
        """
        å»é™¤æ–‡å­—å®Œå…¨ç›¸åŒçš„çŸ¥è­˜ï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰
        åœ¨ LLM å‰åŸ·è¡Œï¼Œç¯€çœ OpenAI token æˆæœ¬

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨
            skip_review: æ˜¯å¦è·³éå¯©æ ¸ï¼ˆå¦‚æœ Trueï¼Œåªæª¢æŸ¥æ­£å¼çŸ¥è­˜åº«ï¼›å¦‚æœ Falseï¼ŒåŒæ™‚æª¢æŸ¥å¯©æ ¸ä½‡åˆ—ï¼‰
            vendor_id: æ¥­è€… IDï¼ˆé™åˆ¶æª¢æŸ¥ç¯„åœåœ¨åŒä¸€æ¥­è€…å…§ï¼‰

        Returns:
            å»é‡å¾Œçš„çŸ¥è­˜åˆ—è¡¨
        """
        check_scope = "æ­£å¼çŸ¥è­˜åº«" if skip_review else "æ­£å¼çŸ¥è­˜åº« + å¯©æ ¸ä½‡åˆ— + æ¸¬è©¦æƒ…å¢ƒ"
        vendor_scope = f"æ¥­è€… {vendor_id}" if vendor_id else "é€šç”¨çŸ¥è­˜"
        print(f"ğŸ” åŸ·è¡Œæ–‡å­—å»é‡ï¼ˆç²¾ç¢ºåŒ¹é…ï¼Œç¯„åœ: {check_scope}ï¼Œ{vendor_scope}ï¼‰...")

        async with self.db_pool.acquire() as conn:
            unique_list = []

            for knowledge in knowledge_list:
                # æ ¹æ“š skip_review æ±ºå®šæª¢æŸ¥ç¯„åœ
                if skip_review:
                    # è·³éå¯©æ ¸æ¨¡å¼ï¼šåªæª¢æŸ¥æ­£å¼çŸ¥è­˜åº«ï¼ˆç”¨æˆ¶æƒ³è¦ç›´æ¥è¦†è“‹å¯©æ ¸ä½‡åˆ—ä¸­çš„è³‡æ–™ï¼‰
                    if vendor_id is not None:
                        exists = await conn.fetchval("""
                            SELECT COUNT(*) FROM knowledge_base
                            WHERE question_summary = $1 AND answer = $2 AND vendor_id = $3
                        """, knowledge.get('question_summary'), knowledge['answer'], vendor_id)
                    else:
                        exists = await conn.fetchval("""
                            SELECT COUNT(*) FROM knowledge_base
                            WHERE question_summary = $1 AND answer = $2 AND vendor_id IS NULL
                        """, knowledge.get('question_summary'), knowledge['answer'])
                else:
                    # å¯©æ ¸æ¨¡å¼ï¼šæª¢æŸ¥æ­£å¼çŸ¥è­˜åº«ã€å¯©æ ¸ä½‡åˆ—å’Œæ¸¬è©¦æƒ…å¢ƒï¼ˆé¿å…é‡è¤‡é€å¯©ï¼‰
                    if vendor_id is not None:
                        exists = await conn.fetchval("""
                            SELECT COUNT(*) FROM (
                                SELECT 1 FROM knowledge_base
                                WHERE question_summary = $1 AND answer = $2 AND vendor_id = $3
                                UNION ALL
                                SELECT 1 FROM ai_generated_knowledge_candidates
                                WHERE question = $1 AND generated_answer = $2 AND vendor_id = $3
                                UNION ALL
                                SELECT 1 FROM test_scenarios
                                WHERE test_question = $1 AND vendor_id = $3
                                AND status IN ('approved', 'in_testing')
                            ) AS combined
                        """, knowledge.get('question_summary'), knowledge['answer'], vendor_id)
                    else:
                        exists = await conn.fetchval("""
                            SELECT COUNT(*) FROM (
                                SELECT 1 FROM knowledge_base
                                WHERE question_summary = $1 AND answer = $2 AND vendor_id IS NULL
                                UNION ALL
                                SELECT 1 FROM ai_generated_knowledge_candidates
                                WHERE question = $1 AND generated_answer = $2 AND vendor_id IS NULL
                                UNION ALL
                                SELECT 1 FROM test_scenarios
                                WHERE test_question = $1 AND vendor_id IS NULL
                                AND status IN ('approved', 'in_testing')
                            ) AS combined
                        """, knowledge.get('question_summary'), knowledge['answer'])

                if exists == 0:
                    unique_list.append(knowledge)
                else:
                    print(f"   è·³éé‡è¤‡: {knowledge.get('question_summary', 'ç„¡å•é¡Œ')[:50]}...")

        return unique_list

    async def _deduplicate_by_similarity(
        self,
        knowledge_list: List[Dict],
        threshold: float = 0.85,
        skip_review: bool = False,
        vendor_id: Optional[int] = None
    ) -> List[Dict]:
        """
        ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦å»é‡ï¼ˆèªæ„å»é‡ï¼‰
        æª¢æŸ¥çŸ¥è­˜åº«ã€å¯©æ ¸ä½‡åˆ—å’Œæ¸¬è©¦æƒ…å¢ƒä¸­æ˜¯å¦å·²æœ‰èªæ„ç›¸ä¼¼çš„çŸ¥è­˜

        é‡ç”¨ unclear_questions çš„ç›¸ä¼¼åº¦æ©Ÿåˆ¶ï¼š
        - é–¾å€¼ï¼š0.85ï¼ˆèˆ‡ unclear_questions ä¸€è‡´ï¼‰
        - ä½¿ç”¨è³‡æ–™åº«å‡½æ•¸ check_knowledge_exists_by_similarity()

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆå¿…é ˆå·²æœ‰ embeddingï¼‰
            threshold: ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.85ï¼‰
            skip_review: æ˜¯å¦è·³éå¯©æ ¸ï¼ˆå¦‚æœ Trueï¼Œåªæª¢æŸ¥æ­£å¼çŸ¥è­˜åº«ï¼›å¦‚æœ Falseï¼ŒåŒæ™‚æª¢æŸ¥å¯©æ ¸ä½‡åˆ—ï¼‰

        Returns:
            å»é‡å¾Œçš„çŸ¥è­˜åˆ—è¡¨
        """
        check_scope = "æ­£å¼çŸ¥è­˜åº«" if skip_review else "æ­£å¼çŸ¥è­˜åº« + å¯©æ ¸ä½‡åˆ— + æ¸¬è©¦æƒ…å¢ƒ"
        print(f"ğŸ” åŸ·è¡Œèªæ„å»é‡ï¼ˆç›¸ä¼¼åº¦é–¾å€¼: {threshold}ï¼Œç¯„åœ: {check_scope}ï¼‰...")

        unique_list = []

        async with self.db_pool.acquire() as conn:
            for idx, knowledge in enumerate(knowledge_list, 1):
                embedding = knowledge.get('embedding')

                if not embedding:
                    print(f"   âš ï¸  çŸ¥è­˜ç¼ºå°‘ embeddingï¼Œè·³éèªæ„æª¢æŸ¥: {knowledge.get('question_summary', 'ç„¡å•é¡Œ')[:50]}")
                    unique_list.append(knowledge)
                    continue

                # å°‡ embedding è½‰æ›ç‚º PostgreSQL vector æ ¼å¼
                vector_str = '[' + ','.join(str(x) for x in embedding) + ']'

                # ä½¿ç”¨è³‡æ–™åº«å‡½æ•¸æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼çŸ¥è­˜
                result = await conn.fetchrow("""
                    SELECT * FROM check_knowledge_exists_by_similarity($1::vector, $2::DECIMAL)
                """, vector_str, threshold)

                # æ ¹æ“š skip_review æ±ºå®šæª¢æŸ¥ç¯„åœ
                if skip_review:
                    # è·³éå¯©æ ¸æ¨¡å¼ï¼šåªæª¢æŸ¥æ­£å¼çŸ¥è­˜åº«
                    is_duplicate = result and result['exists_in_knowledge_base']
                else:
                    # å¯©æ ¸æ¨¡å¼ï¼šæª¢æŸ¥æ­£å¼çŸ¥è­˜åº«ã€å¯©æ ¸ä½‡åˆ—å’Œæ¸¬è©¦æƒ…å¢ƒ
                    is_duplicate = result and (result['exists_in_knowledge_base'] or result['exists_in_review_queue'] or result.get('exists_in_test_scenarios', False))

                if is_duplicate:
                    # æ‰¾åˆ°ç›¸ä¼¼çŸ¥è­˜ï¼Œè·³é
                    source = result['source_table']
                    matched_q = result['matched_question']
                    sim_score = result['similarity_score']

                    print(f"   è·³éèªæ„ç›¸ä¼¼ (ç›¸ä¼¼åº¦: {sim_score:.4f}, ä¾†æº: {source})")
                    print(f"      æ–°å•é¡Œ: {knowledge['question_summary'][:50]}...")
                    print(f"      ç›¸ä¼¼å•é¡Œ: {matched_q[:50]}...")
                else:
                    # æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼çŸ¥è­˜ï¼Œä¿ç•™
                    unique_list.append(knowledge)

                # æ¯è™•ç† 10 æ¢é¡¯ç¤ºé€²åº¦
                if idx % 10 == 0:
                    print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

        return unique_list

    async def _recommend_intents(self, knowledge_list: List[Dict]):
        """
        ç‚ºçŸ¥è­˜æ¨è–¦åˆé©çš„æ„åœ–

        ä½¿ç”¨ LLM æ ¹æ“šå•é¡Œå’Œç­”æ¡ˆå…§å®¹æ¨è–¦æœ€åˆé©çš„æ„åœ–
        å¦‚æœ Excel å·²ç¶“æä¾›æ„åœ–ï¼Œå‰‡ç›´æ¥ä½¿ç”¨ï¼Œä¸èª¿ç”¨ LLM
        æ¨è–¦çµæœå„²å­˜åˆ° knowledge['recommended_intent']

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
        """
        print(f"ğŸ¯ ç‚º {len(knowledge_list)} æ¢çŸ¥è­˜æ¨è–¦æ„åœ–...")

        # 1. å–å¾—æ‰€æœ‰å¯ç”¨çš„æ„åœ–
        async with self.db_pool.acquire() as conn:
            intents = await conn.fetch("""
                SELECT id, name, description
                FROM intents
                ORDER BY id
            """)

        if not intents:
            print("   âš ï¸  æ‰¾ä¸åˆ°ä»»ä½•æ„åœ–ï¼Œè·³éæ¨è–¦")
            return

        # å»ºç«‹æ„åœ–æ¸…å–®æ–‡å­—
        intent_list = "\n".join([
            f"- {intent['id']}: {intent['name']} ({intent['description']})"
            for intent in intents
        ])

        # å»ºç«‹æ„åœ–åç¨±åˆ° ID çš„æ˜ å°„ï¼ˆç”¨æ–¼ Excel æä¾›çš„æ„åœ–åç¨±ï¼‰
        intent_name_to_id = {intent['name']: intent['id'] for intent in intents}

        # å»ºç«‹æ¨¡ç³ŠåŒ¹é…æ˜ å°„ï¼ˆæ”¯æ´éƒ¨åˆ†åŒ¹é…ï¼‰
        # ä¾‹å¦‚ï¼šExcel çš„ã€Œå¸³å‹™ã€å¯ä»¥åŒ¹é…åˆ°ã€Œå¸³å‹™æŸ¥è©¢ã€
        intent_fuzzy_match = {}
        for intent in intents:
            # å®Œæ•´åç¨±ä½œç‚º key
            intent_fuzzy_match[intent['name']] = intent['id']
            # å¦‚æœåç¨±åŒ…å«ã€Œ/ã€ï¼Œåˆ†å‰²å¾Œçš„æ¯å€‹éƒ¨åˆ†ä¹Ÿå¯ä»¥åŒ¹é…
            if '/' in intent['name']:
                for part in intent['name'].split('/'):
                    part = part.strip()
                    if part and part not in intent_fuzzy_match:
                        intent_fuzzy_match[part] = intent['id']

        # 2. è™•ç†æ¯æ¢çŸ¥è­˜
        for idx, knowledge in enumerate(knowledge_list, 1):
            # å¦‚æœ Excel å·²æä¾›æ„åœ–ï¼Œç›´æ¥ä½¿ç”¨
            if knowledge.get('intent'):
                excel_intent = knowledge['intent']

                # 1) å˜—è©¦ç²¾ç¢ºåŒ¹é…
                matched_id = intent_name_to_id.get(excel_intent)
                match_type = "ç²¾ç¢ºåŒ¹é…"

                # 2) å¦‚æœç²¾ç¢ºåŒ¹é…å¤±æ•—ï¼Œå˜—è©¦æ¨¡ç³ŠåŒ¹é…ï¼ˆæŸ¥æ‰¾åŒ…å«è©²é—œéµå­—çš„æ„åœ–ï¼‰
                if not matched_id:
                    for intent in intents:
                        # å¦‚æœè³‡æ–™åº«æ„åœ–åç¨±åŒ…å« Excel çš„åˆ†é¡ï¼Œæˆ–åä¹‹
                        if excel_intent in intent['name'] or intent['name'].startswith(excel_intent):
                            matched_id = intent['id']
                            match_type = "æ¨¡ç³ŠåŒ¹é…"
                            break

                # 3) å¦‚æœé‚„æ˜¯æ²’æœ‰åŒ¹é…ï¼Œæª¢æŸ¥éƒ¨åˆ†åŒ¹é…
                if not matched_id and excel_intent in intent_fuzzy_match:
                    matched_id = intent_fuzzy_match[excel_intent]
                    match_type = "éƒ¨åˆ†åŒ¹é…"

                knowledge['recommended_intent'] = {
                    'intent_id': matched_id,
                    'intent_name': excel_intent,
                    'confidence': 1.0 if matched_id else 0.5,  # æœ‰åŒ¹é…åˆ° ID æ™‚ä¿¡å¿ƒåº¦ 100%
                    'reasoning': f'ä¾†è‡ª Excel åˆ†é¡åˆ¥æ¬„ä½: {excel_intent}ï¼ˆ{match_type}ï¼‰' if matched_id else f'ä¾†è‡ª Excel åˆ†é¡åˆ¥æ¬„ä½: {excel_intent}ï¼ˆæœªåŒ¹é…åˆ°è³‡æ–™åº«æ„åœ–ï¼‰'
                }
                if idx <= 3:  # åªé¡¯ç¤ºå‰ 3 æ¢
                    match_status = f"{match_type}â†’ID:{matched_id}" if matched_id else "æœªåŒ¹é…"
                    print(f"   âœ… {knowledge['question_summary'][:40]}... â†’ {excel_intent} ({match_status})")
                continue

            # æ²’æœ‰æ„åœ–ï¼Œéœ€è¦ LLM æ¨è–¦
            try:
                prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹å•ç­”å…§å®¹ï¼Œå¾æ„åœ–æ¸…å–®ä¸­é¸æ“‡æœ€åˆé©çš„æ„åœ–ã€‚

å•é¡Œï¼š{knowledge['question_summary']}
ç­”æ¡ˆï¼š{knowledge['answer'][:200]}


å¯ç”¨çš„æ„åœ–æ¸…å–®ï¼š
{intent_list}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "intent_id": æ¨è–¦çš„æ„åœ– IDï¼ˆæ•¸å­—ï¼‰,
  "intent_name": æ„åœ–åç¨±,
  "confidence": ä¿¡å¿ƒåº¦ï¼ˆ0.0-1.0ï¼‰,
  "reasoning": æ¨è–¦ç†ç”±ï¼ˆç°¡çŸ­èªªæ˜ï¼‰
}}

åªè¼¸å‡º JSONï¼Œä¸è¦åŠ å…¶ä»–èªªæ˜ã€‚"""

                response = await self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    temperature=0.3,
                    max_tokens=500,  # æ„åœ–æ¨è–¦åªéœ€å°é‡è¼¸å‡º
                    response_format={"type": "json_object"},
                    messages=[{"role": "user", "content": prompt}]
                )

                result = json.loads(response.choices[0].message.content)

                # å„²å­˜æ¨è–¦çµæœ
                knowledge['recommended_intent'] = {
                    'intent_id': result.get('intent_id'),
                    'intent_name': result.get('intent_name'),
                    'confidence': result.get('confidence', 0.8),
                    'reasoning': result.get('reasoning', '')
                }

                if idx <= 3:  # åªé¡¯ç¤ºå‰ 3 æ¢çš„æ¨è–¦
                    print(f"   âœ… {knowledge['question_summary'][:40]}... â†’ {result.get('intent_name')} (ä¿¡å¿ƒåº¦: {result.get('confidence', 0):.2f})")

                # é¿å… rate limit
                await asyncio.sleep(0.1)

            except Exception as e:
                print(f"   âš ï¸  æ„åœ–æ¨è–¦å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨é è¨­æ„åœ–
                knowledge['recommended_intent'] = {
                    'intent_id': 4,  # æœå‹™èªªæ˜
                    'intent_name': 'æœå‹™èªªæ˜',
                    'confidence': 0.5,
                    'reasoning': 'ç„¡æ³•è‡ªå‹•æ¨è–¦ï¼Œä½¿ç”¨é è¨­æ„åœ–'
                }

        # çµ±è¨ˆæ¨è–¦çµæœ
        excel_intent_count = sum(1 for k in knowledge_list if k.get('intent'))
        llm_recommended_count = len(knowledge_list) - excel_intent_count

        print(f"   âœ… æ„åœ–æ¨è–¦å®Œæˆ")
        if excel_intent_count > 0:
            print(f"      ä¾†è‡ª Excel: {excel_intent_count} æ¢")
        if llm_recommended_count > 0:
            print(f"      LLM æ¨è–¦: {llm_recommended_count} æ¢")

    async def _evaluate_quality(self, knowledge_list: List[Dict], enable_quality_evaluation: bool = True):
        """
        è©•ä¼°çŸ¥è­˜ç­”æ¡ˆçš„è³ªé‡

        ä½¿ç”¨ LLM è©•ä¼°ç­”æ¡ˆæ˜¯å¦æœ‰å¯¦ç”¨åƒ¹å€¼ï¼Œé¿å…ç©ºæ³›ã€å¾ªç’°é‚è¼¯æˆ–ç„¡æ„ç¾©çš„å…§å®¹
        è©•ä¼°çµæœå„²å­˜åˆ° knowledge['quality_evaluation']

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨ï¼ˆæœƒç›´æ¥ä¿®æ”¹ï¼‰
            enable_quality_evaluation: æ˜¯å¦å•Ÿç”¨è³ªé‡è©•ä¼°ï¼ˆé è¨­ Trueï¼Œé—œé–‰å¯åŠ é€Ÿå¤§é‡åŒ¯å…¥ï¼‰
        """
        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨è³ªé‡è©•ä¼°ï¼ˆAPI åƒæ•¸å„ªå…ˆæ–¼ç’°å¢ƒè®Šæ•¸ï¼‰
        if not enable_quality_evaluation or not self.quality_evaluation_enabled:
            reason = "API åƒæ•¸é—œé–‰" if not enable_quality_evaluation else "ç’°å¢ƒè®Šæ•¸åœç”¨ (QUALITY_EVALUATION_ENABLED=false)"
            print(f"â­ï¸  è³ªé‡è©•ä¼°å·²åœç”¨ï¼ˆ{reason}ï¼‰")
            # æ‰€æœ‰çŸ¥è­˜é è¨­ç‚ºå¯æ¥å—
            for knowledge in knowledge_list:
                knowledge['quality_evaluation'] = {
                    'quality_score': 8,
                    'is_acceptable': True,
                    'issues': [],
                    'reasoning': f'è³ªé‡è©•ä¼°å·²åœç”¨ï¼ˆ{reason}ï¼‰ï¼Œé è¨­ç‚ºå¯æ¥å—'
                }
            return

        print(f"ğŸ” è©•ä¼° {len(knowledge_list)} æ¢çŸ¥è­˜çš„è³ªé‡ï¼ˆé–€æª»: {self.quality_evaluation_threshold}/10ï¼‰...")

        for idx, knowledge in enumerate(knowledge_list, 1):
            try:
                prompt = f"""è«‹è©•ä¼°ä»¥ä¸‹å•ç­”å…§å®¹çš„è³ªé‡ã€‚

å•é¡Œï¼š{knowledge['question_summary']}
ç­”æ¡ˆï¼š{knowledge['answer']}

è©•ä¼°æ¨™æº–ï¼š
1. å…·é«”æ€§ï¼šç­”æ¡ˆæ˜¯å¦åŒ…å«å…·é«”çš„æ“ä½œæ­¥é©Ÿã€ç´°ç¯€æˆ–èªªæ˜ï¼Ÿ
2. å¯¦ç”¨æ€§ï¼šç­”æ¡ˆæ˜¯å¦èƒ½å¯¦éš›å¹«åŠ©ä½¿ç”¨è€…è§£æ±ºå•é¡Œï¼Ÿ
3. å®Œæ•´æ€§ï¼šç­”æ¡ˆæ˜¯å¦å®Œæ•´å›ç­”äº†å•é¡Œï¼Ÿ
4. éå¾ªç’°æ€§ï¼šç­”æ¡ˆæ˜¯å¦é¿å…äº†å¾ªç’°é‚è¼¯ï¼ˆå¦‚ã€Œéœ€è¦åšXæ™‚å°±åšXã€ï¼‰ï¼Ÿ
5. æ·±åº¦ï¼šç­”æ¡ˆæ˜¯å¦æœ‰è¶³å¤ çš„æ·±åº¦ï¼ˆä¸åªæ˜¯é‡è¤‡å•é¡Œæˆ–é¡¯è€Œæ˜“è¦‹çš„å»ºè­°ï¼‰ï¼Ÿ

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "quality_score": è³ªé‡åˆ†æ•¸ï¼ˆ1-10ï¼Œ10 ç‚ºæœ€é«˜ï¼‰,
  "is_acceptable": æ˜¯å¦å¯æ¥å—ï¼ˆtrue/falseï¼Œåˆ†æ•¸ >= {self.quality_evaluation_threshold} ç‚ºå¯æ¥å—ï¼‰,
  "issues": ["å•é¡Œ1", "å•é¡Œ2"],
  "reasoning": "è©•ä¼°ç†ç”±ï¼ˆç°¡çŸ­èªªæ˜ï¼‰"
}}

è©•åˆ†åƒè€ƒï¼š
- 9-10åˆ†ï¼šå…§å®¹è©³å¯¦ã€å…·é«”ã€æœ‰å¯¦ç”¨åƒ¹å€¼ï¼Œæ˜ç¢ºèªªæ˜æ“ä½œæ­¥é©Ÿ
- 8åˆ†ï¼šæœ‰å¯¦ç”¨åƒ¹å€¼ï¼ŒåŒ…å«å¿…è¦ç´°ç¯€å’Œå…·é«”èªªæ˜
- 6-7åˆ†ï¼šæœ‰ä¸€å®šåƒ¹å€¼ï¼Œä½†éæ–¼ç©ºæ³›æˆ–ç¼ºå°‘é—œéµç´°ç¯€
- 4-5åˆ†ï¼šåŸºæœ¬å¯ç”¨ï¼Œä½†å…§å®¹ç©ºæ³›
- 1-3åˆ†ï¼šç„¡å¯¦ç”¨åƒ¹å€¼ï¼Œæœ‰å¾ªç’°é‚è¼¯æˆ–é‡è¤‡å•é¡Œï¼Œæ‡‰è©²æ‹’çµ•

âš ï¸ æ³¨æ„ï¼šåªæœ‰åˆ†æ•¸ >= {self.quality_evaluation_threshold} çš„çŸ¥è­˜æ‰èƒ½é€²å…¥å¯©æ ¸ä½‡åˆ—ã€‚

åªè¼¸å‡º JSONï¼Œä¸è¦åŠ å…¶ä»–èªªæ˜ã€‚"""

                response = await self.openai_client.chat.completions.create(
                    model=self.llm_model,
                    temperature=0.3,
                    max_tokens=500,  # è³ªé‡è©•ä¼°åªéœ€å°é‡è¼¸å‡º
                    response_format={"type": "json_object"},
                    messages=[{"role": "user", "content": prompt}]
                )

                result = json.loads(response.choices[0].message.content)

                # å„²å­˜è©•ä¼°çµæœ
                knowledge['quality_evaluation'] = {
                    'quality_score': result.get('quality_score', 5),
                    'is_acceptable': result.get('is_acceptable', True),
                    'issues': result.get('issues', []),
                    'reasoning': result.get('reasoning', '')
                }

                # é¡¯ç¤ºä½è³ªé‡çš„çŸ¥è­˜
                if not result.get('is_acceptable', True):
                    print(f"   âš ï¸  ä½è³ªé‡ (åˆ†æ•¸: {result.get('quality_score', 0)}): {knowledge['question_summary'][:40]}...")
                    print(f"      ç†ç”±: {result.get('reasoning', '')[:80]}")
                elif idx <= 3:  # é¡¯ç¤ºå‰ 3 æ¢çš„è©•ä¼°
                    print(f"   âœ… {knowledge['question_summary'][:40]}... â†’ åˆ†æ•¸: {result.get('quality_score', 0)}/10")

                # é¿å… rate limit
                await asyncio.sleep(0.1)

            except Exception as e:
                print(f"   âš ï¸  è³ªé‡è©•ä¼°å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                # å‚™ç”¨æ–¹æ¡ˆï¼šé è¨­ç‚ºå¯æ¥å—
                knowledge['quality_evaluation'] = {
                    'quality_score': 6,
                    'is_acceptable': True,
                    'issues': [],
                    'reasoning': 'ç„¡æ³•è‡ªå‹•è©•ä¼°ï¼Œé è¨­ç‚ºå¯æ¥å—'
                }

        # çµ±è¨ˆè³ªé‡åˆ†å¸ƒ
        acceptable_count = sum(1 for k in knowledge_list if k.get('quality_evaluation', {}).get('is_acceptable', True))
        rejected_count = len(knowledge_list) - acceptable_count

        print(f"   âœ… è³ªé‡è©•ä¼°å®Œæˆ")
        print(f"      å¯æ¥å—: {acceptable_count} æ¢")
        if rejected_count > 0:
            print(f"      ä½è³ªé‡: {rejected_count} æ¢ï¼ˆå°‡è‡ªå‹•æ¨™è¨˜ç‚ºå·²æ‹’çµ•ï¼‰")

    async def _clear_vendor_knowledge(self, vendor_id: int):
        """
        æ¸…é™¤æ¥­è€…çš„ç¾æœ‰çŸ¥è­˜ï¼ˆç”¨æ–¼ replace æ¨¡å¼ï¼‰

        Args:
            vendor_id: æ¥­è€… ID
        """
        print(f"ğŸ—‘ï¸  æ¸…é™¤æ¥­è€… {vendor_id} çš„ç¾æœ‰çŸ¥è­˜...")

        async with self.db_pool.acquire() as conn:
            deleted_count = await conn.fetchval("""
                DELETE FROM knowledge_base
                WHERE vendor_id = $1
                RETURNING COUNT(*)
            """, vendor_id)

            print(f"   âœ… å·²åˆªé™¤ {deleted_count or 0} æ¢èˆŠçŸ¥è­˜")

    async def _import_to_database(
        self,
        knowledge_list: List[Dict],
        vendor_id: Optional[int],
        import_mode: str,
        default_priority: int = 0,
        created_by: str = "admin"
    ) -> Dict:
        """
        åŒ¯å…¥çŸ¥è­˜åˆ°è³‡æ–™åº«

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨
            vendor_id: æ¥­è€… ID
            import_mode: åŒ¯å…¥æ¨¡å¼
            default_priority: çµ±ä¸€å„ªå…ˆç´šï¼ˆ0=æœªå•Ÿç”¨ï¼Œ1=å·²å•Ÿç”¨ï¼‰
            created_by: å»ºç«‹è€…

        Returns:
            åŒ¯å…¥çµæœçµ±è¨ˆ
        """
        print(f"ğŸ’¾ åŒ¯å…¥ {len(knowledge_list)} æ¢çŸ¥è­˜åˆ°è³‡æ–™åº«...")

        imported = 0
        skipped = 0
        errors = 0

        async with self.db_pool.acquire() as conn:
            # å–å¾—é è¨­æ„åœ– ID
            default_intent_id = await conn.fetchval("""
                SELECT id FROM intents
                WHERE name IN ('ä¸€èˆ¬çŸ¥è­˜', 'å…¶ä»–', 'general')
                ORDER BY id
                LIMIT 1
            """)

            if not default_intent_id:
                print("âš ï¸ æ‰¾ä¸åˆ°é è¨­æ„åœ–ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹æ„åœ–")
                default_intent_id = await conn.fetchval("SELECT id FROM intents ORDER BY id LIMIT 1")

            for idx, knowledge in enumerate(knowledge_list, 1):
                try:
                    # å°‡ embedding è½‰æ›ç‚º PostgreSQL vector æ ¼å¼
                    embedding = knowledge.get('embedding')
                    embedding_str = None
                    if embedding:
                        embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

                    # æº–å‚™ target_userï¼ˆknowledge_base ä½¿ç”¨é™£åˆ—ï¼Œéœ€è¦è½‰æ›ï¼‰
                    target_user_value = knowledge.get('target_user', 'tenant')
                    target_user_array = [target_user_value] if target_user_value else ['tenant']

                    # å¾ recommended_intent å–å¾—æ„åœ– ID
                    intent_id = None
                    recommended_intent = knowledge.get('recommended_intent')
                    if recommended_intent:
                        intent_id = recommended_intent.get('intent_id')

                    if intent_id is None:  # ä½¿ç”¨ is None è€Œä¸æ˜¯ not
                        intent_id = default_intent_id

                    # å–å¾—æ¥­æ…‹é¡å‹ï¼ˆå¦‚æœæœ‰ï¼‰
                    business_types = knowledge.get('business_types', [])

                    # ğŸ”§ UPSERT é‚è¼¯ï¼šæª¢æŸ¥æ˜¯å¦æœ‰ IDï¼ˆç”¨æ–¼æ›´æ–°ï¼‰
                    knowledge_id = knowledge.get('id')

                    if knowledge_id:
                        # æª¢æŸ¥ ID æ˜¯å¦å­˜åœ¨
                        exists = await conn.fetchval(
                            "SELECT EXISTS(SELECT 1 FROM knowledge_base WHERE id = $1)",
                            knowledge_id
                        )

                        if exists:
                            # æ›´æ–°ç¾æœ‰çŸ¥è­˜
                            await conn.execute("""
                                UPDATE knowledge_base SET
                                    intent_id = $1,
                                    vendor_id = $2,
                                    question_summary = $3,
                                    answer = $4,
                                    keywords = $5,
                                    business_types = $6,
                                    target_user = $7,
                                    source_file = $8,
                                    source_date = $9,
                                    embedding = $10::vector,
                                    scope = $11,
                                    priority = $12,
                                    updated_at = CURRENT_TIMESTAMP
                                WHERE id = $13
                            """,
                                intent_id,
                                vendor_id,
                                knowledge['question_summary'],
                                knowledge['answer'],
                                knowledge['keywords'],
                                business_types,
                                target_user_array,
                                knowledge['source_file'],
                                datetime.now().date(),
                                embedding_str,
                                'global' if not vendor_id else 'vendor',
                                default_priority,
                                knowledge_id
                            )
                            print(f"   âœï¸  æ›´æ–°çŸ¥è­˜ ID: {knowledge_id}")
                        else:
                            # ID ä¸å­˜åœ¨ï¼Œæ–°å¢ï¼ˆå¿½ç•¥æä¾›çš„ IDï¼Œä½¿ç”¨è‡ªå‹•ç”Ÿæˆï¼‰
                            await conn.execute("""
                                INSERT INTO knowledge_base (
                                    intent_id,
                                    vendor_id,
                                    question_summary,
                                    answer,
                                    keywords,
                                    business_types,
                                    target_user,
                                    source_file,
                                    source_date,
                                    embedding,
                                    scope,
                                    priority,
                                    created_at,
                                    updated_at
                                ) VALUES (
                                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10::vector, $11, $12,
                                    CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
                                )
                            """,
                                intent_id,
                                vendor_id,
                                knowledge['question_summary'],
                                knowledge['answer'],
                                knowledge['keywords'],
                                business_types,
                                target_user_array,
                                knowledge['source_file'],
                                datetime.now().date(),
                                embedding_str,
                                'global' if not vendor_id else 'vendor',
                                default_priority
                            )
                            print(f"   âš ï¸  ID {knowledge_id} ä¸å­˜åœ¨ï¼Œæ–°å¢ç‚ºæ–°çŸ¥è­˜")
                    else:
                        # æ²’æœ‰ IDï¼Œæ–°å¢çŸ¥è­˜
                        await conn.execute("""
                            INSERT INTO knowledge_base (
                                intent_id,
                                vendor_id,
                                question_summary,
                                answer,
                                keywords,
                                business_types,
                                target_user,
                                source_file,
                                source_date,
                                embedding,
                                scope,
                                priority,
                                created_at,
                                updated_at
                            ) VALUES (
                                $1, $2, $3, $4, $5, $6, $7, $8, $9, $10::vector, $11, $12,
                                CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
                            )
                        """,
                            intent_id,
                            vendor_id,
                            knowledge['question_summary'],
                            knowledge['answer'],
                            knowledge['keywords'],
                            business_types,
                            target_user_array,
                            knowledge['source_file'],
                            datetime.now().date(),
                            embedding_str,
                            'global' if not vendor_id else 'vendor',
                            default_priority
                        )

                    imported += 1

                    if idx % 10 == 0:
                        print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

                except Exception as e:
                    print(f"   âš ï¸ åŒ¯å…¥å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                    errors += 1

        return {
            "imported": imported,
            "skipped": skipped,
            "errors": errors,
            "total": len(knowledge_list)
        }

    async def _create_test_scenario_suggestions(
        self,
        knowledge_list: List[Dict],
        vendor_id: Optional[int]
    ) -> int:
        """
        ç‚º B2C å°è±¡çš„çŸ¥è­˜å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°ï¼ˆéœ€æ±‚ 2ï¼‰

        B2C å°è±¡åŒ…æ‹¬ï¼štenantï¼ˆç§Ÿå®¢ï¼‰ã€landlordï¼ˆæˆ¿æ±ï¼‰ï¼ˆæ‰€æœ‰å¤–éƒ¨æ¥­å‹™ç¯„åœï¼‰

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨
            vendor_id: æ¥­è€… ID

        Returns:
            å»ºç«‹çš„æ¸¬è©¦æƒ…å¢ƒæ•¸é‡
        """
        print(f"ğŸ§ª æª¢æŸ¥ B2C çŸ¥è­˜ä¸¦å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°...")

        # B2C å°è±¡åˆ—è¡¨ï¼ˆä½¿ç”¨è‹±æ–‡æ¨™æº–å€¼ï¼‰
        b2c_target_users = ['tenant', 'landlord']

        created_count = 0

        async with self.db_pool.acquire() as conn:
            for knowledge in knowledge_list:
                target_user = knowledge.get('target_user', '').lower()

                # æª¢æŸ¥æ˜¯å¦ç‚º B2C å°è±¡
                if target_user not in b2c_target_users:
                    continue

                question = knowledge['question_summary']

                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼çš„æ¸¬è©¦æƒ…å¢ƒ
                exists = await conn.fetchval("""
                    SELECT COUNT(*)
                    FROM test_scenarios
                    WHERE test_question = $1
                """, question)

                if exists > 0:
                    continue

                # å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°
                try:
                    await conn.execute("""
                        INSERT INTO test_scenarios (
                            test_question,
                            difficulty,
                            status,
                            source,
                            notes,
                            created_at
                        ) VALUES ($1, $2, $3, $4, $5, CURRENT_TIMESTAMP)
                    """,
                        question,
                        'medium',  # é è¨­é›£åº¦
                        'pending_review',  # å¾…å¯©æ ¸ç‹€æ…‹
                        'imported',
                        f"å°å…¥çš„çŸ¥è­˜"
                    )

                    created_count += 1

                except Exception as e:
                    print(f"   âš ï¸ å»ºç«‹æ¸¬è©¦æƒ…å¢ƒå¤±æ•—: {e}")

        if created_count > 0:
            print(f"   âœ… å»ºç«‹äº† {created_count} å€‹æ¸¬è©¦æƒ…å¢ƒå»ºè­°")
        else:
            print(f"   â„¹ï¸ æ²’æœ‰éœ€è¦å»ºç«‹æ¸¬è©¦æƒ…å¢ƒçš„ B2C çŸ¥è­˜")

        return created_count

    async def _parse_chat_scenarios(
        self,
        knowledge_list: List[Dict],
        file_name: str
    ) -> List[Dict]:
        """
        è§£æå°è©±è¨˜éŒ„ä¸­çš„æ¸¬è©¦æƒ…å¢ƒï¼ˆä¸å‰µå»ºåˆ°è³‡æ–™åº«ï¼‰

        Args:
            knowledge_list: å¾å°è©±ä¸­æå–çš„å•ç­”åˆ—è¡¨
            file_name: ä¾†æºæª”æ¡ˆåç¨±

        Returns:
            æ¸¬è©¦æƒ…å¢ƒåˆ—è¡¨ï¼Œæ¯å€‹åŒ…å« {index, question, difficulty, notes}
        """
        print(f"ğŸ’¬ è§£æ {len(knowledge_list)} æ¢å°è©±ç‚ºæ¸¬è©¦æƒ…å¢ƒ...")

        scenarios = []

        for idx, knowledge in enumerate(knowledge_list):
            question = knowledge.get('question_summary') or knowledge.get('question', '')

            if not question:
                print(f"   âš ï¸ è·³éç¬¬ {idx} æ¢ï¼šç„¡å•é¡Œå…§å®¹")
                continue

            scenarios.append({
                "index": idx,
                "question": question,
                "difficulty": "medium",  # é è¨­é›£åº¦
                "notes": f"å¾å°è©±è¨˜éŒ„åŒ¯å…¥: {file_name}",
                "selected": True  # é è¨­å…¨é¸
            })

        print(f"âœ… è§£æå®Œæˆï¼Œå…± {len(scenarios)} å€‹æ¸¬è©¦æƒ…å¢ƒ")
        return scenarios

    async def _create_selected_scenarios(
        self,
        scenarios: List[Dict],
        selected_indices: List[int],
        created_by: str
    ) -> Dict:
        """
        å‰µå»ºç”¨æˆ¶é¸ä¸­çš„æ¸¬è©¦æƒ…å¢ƒ

        Args:
            scenarios: æ¸¬è©¦æƒ…å¢ƒåˆ—è¡¨ï¼ˆå¾ _parse_chat_scenarios è¿”å›ï¼‰
            selected_indices: ç”¨æˆ¶é¸ä¸­çš„ç´¢å¼•åˆ—è¡¨
            created_by: å»ºç«‹è€…

        Returns:
            å‰µå»ºçµæœçµ±è¨ˆ
        """
        print(f"ğŸ’¬ å‰µå»º {len(selected_indices)}/{len(scenarios)} å€‹é¸ä¸­çš„æ¸¬è©¦æƒ…å¢ƒ...")

        created = 0
        skipped = 0
        errors = 0
        created_items = []

        async with self.db_pool.acquire() as conn:
            for idx in selected_indices:
                if idx < 0 or idx >= len(scenarios):
                    print(f"   âš ï¸ ç´¢å¼• {idx} è¶…å‡ºç¯„åœï¼Œè·³é")
                    errors += 1
                    continue

                scenario = scenarios[idx]
                question = scenario['question']

                try:
                    # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æ¸¬è©¦å•é¡Œ
                    existing = await conn.fetchval("""
                        SELECT id FROM test_scenarios
                        WHERE test_question = $1
                        LIMIT 1
                    """, question)

                    if existing:
                        print(f"   â­ï¸  è·³éé‡è¤‡: {question[:30]}...")
                        skipped += 1
                        continue

                    # å‰µå»ºæ¸¬è©¦æƒ…å¢ƒï¼ˆç‹€æ…‹ç‚º approvedï¼Œç›´æ¥å¯ç”¨ï¼‰
                    test_scenario_id = await conn.fetchval("""
                        INSERT INTO test_scenarios (
                            test_question,
                            difficulty,
                            status,
                            source,
                            notes,
                            created_at
                        ) VALUES ($1, $2, $3, $4, $5, CURRENT_TIMESTAMP)
                        RETURNING id
                    """,
                        question,
                        scenario.get('difficulty', 'medium'),
                        'approved',  # ç”¨æˆ¶å·²ç¢ºèªï¼Œç›´æ¥æ‰¹å‡†
                        'imported',
                        scenario.get('notes', '')
                    )

                    created += 1
                    created_items.append({
                        "id": test_scenario_id,
                        "question": question
                    })

                except Exception as e:
                    print(f"   âš ï¸ å‰µå»ºæ¸¬è©¦æƒ…å¢ƒå¤±æ•—: {e}")
                    errors += 1

        print(f"\n   âœ… æ¸¬è©¦æƒ…å¢ƒå‰µå»ºå®Œæˆ:")
        print(f"      æ–°å»º: {created} å€‹")
        print(f"      è·³é: {skipped} å€‹ï¼ˆé‡è¤‡ï¼‰")
        print(f"      å¤±æ•—: {errors} å€‹")

        return {
            "created": created,
            "skipped": skipped,
            "errors": errors,
            "total": len(selected_indices),
            "mode": "test_scenarios_created",
            "items": created_items
        }

    async def _import_chat_as_test_scenarios(
        self,
        knowledge_list: List[Dict],
        vendor_id: Optional[int],
        file_name: str,
        created_by: str
    ) -> Dict:
        """
        å°‡å°è©±è¨˜éŒ„åŒ¯å…¥ç‚ºæ¸¬è©¦æƒ…å¢ƒï¼ˆæ¨¡å¼ Aï¼šç´”æ¸¬è©¦æƒ…å¢ƒæ¨¡å¼ï¼‰

        å°è©±è¨˜éŒ„ä¸å‰µå»ºçŸ¥è­˜ï¼Œåªå‰µå»ºæ¸¬è©¦æƒ…å¢ƒä¾›å¾ŒçºŒæ¸¬è©¦ä½¿ç”¨

        Args:
            knowledge_list: å¾å°è©±ä¸­æå–çš„å•ç­”åˆ—è¡¨
            vendor_id: æ¥­è€… ID
            file_name: ä¾†æºæª”æ¡ˆåç¨±
            created_by: å»ºç«‹è€…

        Returns:
            åŒ¯å…¥çµæœçµ±è¨ˆ
        """
        print(f"ğŸ’¬ å°‡ {len(knowledge_list)} æ¢å°è©±åŒ¯å…¥ç‚ºæ¸¬è©¦æƒ…å¢ƒ...")

        created = 0
        skipped = 0
        errors = 0
        created_items = []  # è¨˜éŒ„å‰µå»ºçš„æ¸¬è©¦æƒ…å¢ƒ

        async with self.db_pool.acquire() as conn:
            for idx, knowledge in enumerate(knowledge_list, 1):
                try:
                    question = knowledge.get('question_summary') or knowledge.get('question', '')

                    if not question:
                        print(f"   âš ï¸ è·³éç¬¬ {idx} æ¢ï¼šç„¡å•é¡Œå…§å®¹")
                        skipped += 1
                        continue

                    # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æ¸¬è©¦å•é¡Œ
                    existing = await conn.fetchval("""
                        SELECT id FROM test_scenarios
                        WHERE test_question = $1
                        LIMIT 1
                    """, question)

                    if existing:
                        print(f"   â­ï¸  è·³éé‡è¤‡: {question[:30]}...")
                        skipped += 1
                        continue

                    # å‰µå»ºæ¸¬è©¦æƒ…å¢ƒï¼ˆtest_scenarios è¡¨æ˜¯å…¨åŸŸçš„ï¼Œä¸éœ€è¦ vendor_idï¼‰
                    test_scenario_id = await conn.fetchval("""
                        INSERT INTO test_scenarios (
                            test_question,
                            difficulty,
                            status,
                            source,
                            notes,
                            created_at
                        ) VALUES ($1, $2, $3, $4, $5, CURRENT_TIMESTAMP)
                        RETURNING id
                    """,
                        question,
                        'medium',  # é è¨­é›£åº¦
                        'pending_review',  # å¾…å¯©æ ¸ç‹€æ…‹ï¼Œé€²å…¥å¯©æ ¸ä¸­å¿ƒ
                        'imported',  # ä¾†æºï¼šåŒ¯å…¥
                        f"å¾å°è©±è¨˜éŒ„åŒ¯å…¥: {file_name}"
                    )

                    created += 1
                    created_items.append({
                        "id": test_scenario_id,
                        "question": question
                    })

                    if idx % 10 == 0:
                        print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

                except Exception as e:
                    print(f"   âš ï¸ å‰µå»ºæ¸¬è©¦æƒ…å¢ƒå¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                    errors += 1

        print(f"\n   âœ… æ¸¬è©¦æƒ…å¢ƒå‰µå»ºå®Œæˆ:")
        print(f"      ç¸½å…±: {len(knowledge_list)} æ¢å°è©±")
        print(f"      æ–°å»º: {created} å€‹æ¸¬è©¦æƒ…å¢ƒ")
        print(f"      è·³é: {skipped} å€‹ï¼ˆé‡è¤‡ï¼‰")
        if errors > 0:
            print(f"      éŒ¯èª¤: {errors} å€‹")

        return {
            "created": created,
            "skipped": skipped,
            "errors": errors,
            "total": len(knowledge_list),
            "mode": "test_scenarios_draft",  # è‰ç¨¿æ¨¡å¼
            "items": created_items,  # å‰µå»ºçš„æ¸¬è©¦æƒ…å¢ƒåˆ—è¡¨
            "message": "æ¸¬è©¦æƒ…å¢ƒå·²å‰µå»ºç‚ºè‰ç¨¿ç‹€æ…‹ï¼Œè«‹å‰å¾€ã€Œæ¸¬è©¦æƒ…å¢ƒç®¡ç†ã€é é¢å¯©æ ¸"
        }

    async def _import_to_review_queue(
        self,
        knowledge_list: List[Dict],
        vendor_id: Optional[int],
        created_by: str,
        source_type: str = 'external_file',
        import_source: str = 'external_unknown',
        file_name: str = 'unknown'
    ) -> Dict:
        """
        å°‡çŸ¥è­˜åŒ¯å…¥åˆ°å¯©æ ¸ä½‡åˆ—ï¼ˆæ”¯æ´å¤šç¨®ä¾†æºé¡å‹ï¼‰

        çŸ¥è­˜æœƒå…ˆé€²å…¥ ai_generated_knowledge_candidates è¡¨ï¼Œ
        äººå·¥å¯©æ ¸é€šéå¾Œæ‰æœƒåŠ å…¥æ­£å¼çš„ knowledge_base

        Args:
            knowledge_list: çŸ¥è­˜åˆ—è¡¨
            vendor_id: æ¥­è€… ID
            created_by: å»ºç«‹è€…
            source_type: ä¾†æºé¡å‹ï¼ˆ'ai_generated', 'spec_import', 'external_file', 'line_chat'ï¼‰
            import_source: åŒ¯å…¥ä¾†æºï¼ˆ'system_export', 'external_excel', 'spec_pdf', 'line_chat_txt'ç­‰ï¼‰
            file_name: ä¾†æºæª”æ¡ˆåç¨±

        Returns:
            åŒ¯å…¥çµæœçµ±è¨ˆ
        """
        print(f"ğŸ“‹ å°‡ {len(knowledge_list)} æ¢çŸ¥è­˜åŒ¯å…¥å¯©æ ¸ä½‡åˆ—...")
        print(f"   ä¾†æºé¡å‹: {source_type}")
        print(f"   åŒ¯å…¥ä¾†æº: {import_source}")

        imported = 0
        auto_rejected = 0
        errors = 0

        async with self.db_pool.acquire() as conn:
            for idx, knowledge in enumerate(knowledge_list, 1):
                try:
                    question = knowledge['question_summary']
                    answer = knowledge['answer']

                    # 1. æ¢ä»¶å¼å‰µå»ºæ¸¬è©¦æƒ…å¢ƒï¼ˆåªæœ‰å°è©±è¨˜éŒ„éœ€è¦ï¼‰
                    test_scenario_id = None
                    if source_type == 'line_chat':
                        # å°è©±è¨˜éŒ„ â†’ å‰µå»ºæ¸¬è©¦æƒ…å¢ƒ
                        test_scenario_id = await conn.fetchval("""
                            SELECT id FROM test_scenarios
                            WHERE test_question = $1
                            ORDER BY created_at DESC
                            LIMIT 1
                        """, question)

                        # å¦‚æœæ²’æœ‰æ¸¬è©¦æƒ…å¢ƒï¼Œå…ˆå»ºç«‹ä¸€å€‹
                        if not test_scenario_id:
                            test_scenario_id = await conn.fetchval("""
                                INSERT INTO test_scenarios (
                                    test_question,
                                    difficulty,
                                    status,
                                    source,
                                    notes,
                                    created_at
                                ) VALUES ($1, $2, $3, $4, $5, CURRENT_TIMESTAMP)
                                RETURNING id
                            """,
                                question,
                                'medium',
                                'pending_review',
                                'imported',
                                f"å¾å°è©±è¨˜éŒ„åŒ¯å…¥: {file_name}"
                            )
                    # è¦æ ¼æ›¸/å¤–éƒ¨æª”æ¡ˆ â†’ ä¸å‰µå»ºæ¸¬è©¦æƒ…å¢ƒï¼ˆtest_scenario_id = NULLï¼‰

                    # 2. æº–å‚™ generation_reasoningï¼ˆåŒ…å«æ„åœ–æ¨è–¦ã€æ³›åŒ–è­¦å‘Šå’Œè³ªé‡è©•ä¼°ï¼‰
                    recommended_intent = knowledge.get('recommended_intent', {})
                    warnings_list = knowledge.get('warnings', [])
                    quality_eval = knowledge.get('quality_evaluation', {})

                    # æå–æ¨è–¦æ„åœ– ID ä¸¦å»ºç«‹é™£åˆ—
                    intent_ids = []
                    if recommended_intent and recommended_intent.get('intent_id') not in [None, 'æœªæ¨è–¦', 'null']:
                        try:
                            intent_id = int(recommended_intent.get('intent_id'))
                            intent_ids = [intent_id]
                        except (ValueError, TypeError):
                            pass  # å¦‚æœè½‰æ›å¤±æ•—ï¼Œä¿æŒç©ºé™£åˆ—

                    reasoning = f"""å°è±¡: {knowledge.get('target_user', '')}, é—œéµå­—: {', '.join(knowledge.get('keywords', []))}

ã€æ¨è–¦æ„åœ–ã€‘
æ„åœ– ID: {recommended_intent.get('intent_id', 'æœªæ¨è–¦')}
æ„åœ–åç¨±: {recommended_intent.get('intent_name', 'æœªæ¨è–¦')}
ä¿¡å¿ƒåº¦: {recommended_intent.get('confidence', 0)}
æ¨è–¦ç†ç”±: {recommended_intent.get('reasoning', 'ç„¡')}"""

                    # å¦‚æœæœ‰æ³›åŒ–è­¦å‘Šï¼ŒåŠ åˆ° reasoning ä¸­
                    if warnings_list:
                        reasoning += f"\n\nã€æ³›åŒ–è™•ç†ã€‘\n" + "\n".join([f"- {w}" for w in warnings_list])

                    # æ±ºå®šç‹€æ…‹ï¼šæ ¹æ“šè³ªé‡è©•ä¼°çµæœ
                    is_acceptable = quality_eval.get('is_acceptable', True)
                    if is_acceptable:
                        status = 'pending_review'
                    else:
                        status = 'rejected'
                        auto_rejected += 1
                        # åŠ å…¥è³ªé‡è©•ä¼°è³‡è¨Šåˆ° reasoning
                        reasoning += f"\n\nã€è³ªé‡è©•ä¼° - è‡ªå‹•æ‹’çµ•ã€‘\n"
                        reasoning += f"è³ªé‡åˆ†æ•¸: {quality_eval.get('quality_score', 0)}/10\n"
                        reasoning += f"æ‹’çµ•ç†ç”±: {quality_eval.get('reasoning', '')}\n"
                        if quality_eval.get('issues'):
                            reasoning += f"å•é¡Œåˆ—è¡¨: " + ", ".join(quality_eval.get('issues', []))

                    # 3. å°‡ embedding è½‰æ›ç‚º PostgreSQL vector æ ¼å¼
                    embedding = knowledge.get('embedding')
                    embedding_str = None
                    if embedding:
                        embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

                    # 4. æº–å‚™æ–°æ¬„ä½è³‡æ–™
                    keywords = knowledge.get('keywords', [])
                    priority = knowledge.get('priority', 0)
                    scope = knowledge.get('scope', 'global')
                    business_types = knowledge.get('business_types', [])
                    target_user = knowledge.get('target_user')

                    # 5. å»ºç«‹çŸ¥è­˜å€™é¸è¨˜éŒ„ï¼ˆå«æ–°æ¬„ä½ï¼‰
                    await conn.execute("""
                        INSERT INTO ai_generated_knowledge_candidates (
                            test_scenario_id,
                            source_type,
                            import_source,
                            source_file_name,
                            question,
                            generated_answer,
                            question_embedding,
                            confidence_score,
                            generation_prompt,
                            ai_model,
                            generation_reasoning,
                            suggested_sources,
                            warnings,
                            intent_ids,
                            keywords,
                            priority,
                            scope,
                            vendor_id,
                            business_types,
                            target_user,
                            status,
                            created_at,
                            updated_at
                        ) VALUES (
                            $1, $2, $3, $4, $5, $6, $7::vector, $8, $9, $10, $11, $12, $13, $14,
                            $15, $16, $17, $18, $19, $20, $21, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
                        )
                    """,
                        test_scenario_id,           # $1  - NULLï¼ˆè¦æ ¼æ›¸ï¼‰æˆ–æœ‰å€¼ï¼ˆå°è©±è¨˜éŒ„ï¼‰
                        source_type,                # $2  - 'spec_import', 'external_file', 'line_chat'
                        import_source,              # $3  - 'spec_pdf', 'external_excel', 'line_chat_txt'
                        file_name,                  # $4  - ä¾†æºæª”å
                        question,                   # $5
                        answer,                     # $6
                        embedding_str,              # $7  - å‘é‡åµŒå…¥ï¼ˆå­—ä¸²æ ¼å¼ï¼‰
                        0.85,                       # $8  - åŒ¯å…¥çŸ¥è­˜å›ºå®šä¿¡å¿ƒåˆ†æ•¸ 85%
                        f"å¾æª”æ¡ˆåŒ¯å…¥: {file_name}",  # $9
                        'knowledge_import',         # $10 - æ¨™è¨˜ç‚ºçŸ¥è­˜åŒ¯å…¥
                        reasoning,                  # $11 - åŒ…å«æ¨è–¦æ„åœ–ã€æ³›åŒ–è­¦å‘Šå’Œè³ªé‡è©•ä¼°
                        [file_name],                # $12 - suggested_sources
                        warnings_list,              # $13 - æ³›åŒ–è­¦å‘Š
                        intent_ids,                 # $14 - æ¨è–¦æ„åœ– ID é™£åˆ—
                        keywords,                   # $15 - é—œéµå­—
                        priority,                   # $16 - å„ªå…ˆç´š
                        scope,                      # $17 - é©ç”¨ç¯„åœ
                        vendor_id,                  # $18 - å» å•† ID
                        business_types,             # $19 - æ¥­å‹™é¡å‹
                        target_user,                # $20 - ç›®æ¨™ç”¨æˆ¶
                        status                      # $21 - æ ¹æ“šè³ªé‡è©•ä¼°å‹•æ…‹è¨­å®š
                    )

                    imported += 1

                    if idx % 10 == 0:
                        print(f"   é€²åº¦: {idx}/{len(knowledge_list)}")

                except Exception as e:
                    print(f"   âš ï¸ åŒ¯å…¥åˆ°å¯©æ ¸ä½‡åˆ—å¤±æ•— (ç¬¬ {idx} æ¢): {e}")
                    errors += 1

        print(f"\n   âœ… åŒ¯å…¥å®Œæˆ:")
        print(f"      ç¸½å…±: {len(knowledge_list)} æ¢")
        print(f"      å¾…å¯©æ ¸: {imported - auto_rejected} æ¢")
        if auto_rejected > 0:
            print(f"      è‡ªå‹•æ‹’çµ•: {auto_rejected} æ¢ï¼ˆè³ªé‡ä¸è¶³ï¼‰")
        if errors > 0:
            print(f"      éŒ¯èª¤: {errors} æ¢")

        return {
            "imported": imported,
            "auto_rejected": auto_rejected,
            "pending_review": imported - auto_rejected,
            "skipped": 0,
            "errors": errors,
            "total": len(knowledge_list),
            "mode": "review_queue"
        }

    # âœ… update_job_status æ–¹æ³•å·²ç§»é™¤ï¼Œæ”¹ç”¨çˆ¶é¡ UnifiedJobService çš„ update_status() æ–¹æ³•
    # æ–°çš„èª¿ç”¨æ–¹å¼ï¼š
    # await self.update_status(
    #     job_id=job_id,
    #     status=status,
    #     progress=progress,
    #     result=result,
    #     error_message=error,
    #     success_records=result.get('imported'),
    #     failed_records=result.get('errors'),
    #     skipped_records=result.get('skipped')
    # )
