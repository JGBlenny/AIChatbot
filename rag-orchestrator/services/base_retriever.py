"""
åŸºç¤æª¢ç´¢å™¨ (Base Retriever)
æä¾› SOP å’ŒçŸ¥è­˜åº«å…±ç”¨çš„æª¢ç´¢é‚è¼¯
Date: 2026-02-11
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Optional, Any
import psycopg2
import psycopg2.extras
from services.db_utils import get_db_config
from services.embedding_utils import get_embedding_client
import jieba
import os


class BaseRetriever(ABC):
    """
    çµ±ä¸€çš„æª¢ç´¢å™¨åŸºé¡
    æä¾›å…±ç”¨çš„æª¢ç´¢ç­–ç•¥ï¼šå‘é‡æª¢ç´¢ + é—œéµå­—å‚™é¸ + Reranker
    """

    def __init__(self):
        """åˆå§‹åŒ–åŸºç¤æª¢ç´¢å™¨"""
        # è³‡æ–™åº«é…ç½®
        self.db_config = get_db_config()

        # Embedding å®¢æˆ¶ç«¯
        self.embedding_client = get_embedding_client()

        # Reranker (å¦‚æœå•Ÿç”¨)
        self.reranker = None
        if os.getenv("ENABLE_RERANKER", "false").lower() == "true":
            try:
                from FlagEmbedding import FlagReranker
                model_path = os.getenv("RERANKER_MODEL_PATH", "/app/models/bge-reranker-v2-m3")
                self.reranker = FlagReranker(model_path, use_fp16=True)
                print("âœ… Reranker å·²å•Ÿç”¨")
            except Exception as e:
                print(f"âš ï¸ Reranker è¼‰å…¥å¤±æ•—: {e}")

        # æª¢ç´¢é…ç½®
        self.default_top_k = 5
        self.default_similarity_threshold = 0.6
        self.keyword_fallback_enabled = True
        self.keyword_boost_enabled = True

    def _get_db_connection(self):
        """å»ºç«‹è³‡æ–™åº«é€£æ¥"""
        return psycopg2.connect(**self.db_config)

    async def _get_embedding(self, text: str) -> Optional[List[float]]:
        """ç”Ÿæˆæ–‡å­—å‘é‡"""
        return await self.embedding_client.get_embedding(text, verbose=False)

    # ==================== æŠ½è±¡æ–¹æ³•ï¼ˆå­é¡å¿…é ˆå¯¦ä½œï¼‰ ====================

    @abstractmethod
    async def _vector_search(
        self,
        query_embedding: List[float],
        vendor_id: int,
        top_k: int,
        similarity_threshold: float,
        **kwargs
    ) -> List[Dict]:
        """
        å‘é‡æª¢ç´¢ï¼ˆå­é¡å¯¦ä½œï¼‰

        Args:
            query_embedding: æŸ¥è©¢å‘é‡
            vendor_id: æ¥­è€… ID
            top_k: è¿”å›æ•¸é‡
            similarity_threshold: ç›¸ä¼¼åº¦é–¾å€¼
            **kwargs: å…¶ä»–åƒæ•¸

        Returns:
            æª¢ç´¢çµæœåˆ—è¡¨
        """
        pass

    @abstractmethod
    async def _keyword_search(
        self,
        query: str,
        vendor_id: int,
        limit: int,
        **kwargs
    ) -> List[Dict]:
        """
        é—œéµå­—æª¢ç´¢ï¼ˆå­é¡å¯¦ä½œï¼‰

        Args:
            query: æŸ¥è©¢æ–‡å­—
            vendor_id: æ¥­è€… ID
            limit: è¿”å›æ•¸é‡
            **kwargs: å…¶ä»–åƒæ•¸

        Returns:
            æª¢ç´¢çµæœåˆ—è¡¨
        """
        pass

    @abstractmethod
    def _format_result(self, row: Dict) -> Dict:
        """
        æ ¼å¼åŒ–çµæœï¼ˆå­é¡å¯¦ä½œï¼‰
        å°‡è³‡æ–™åº«è¨˜éŒ„è½‰æ›ç‚ºçµ±ä¸€æ ¼å¼
        """
        pass

    # ==================== å…±ç”¨é‚è¼¯ ====================

    async def retrieve(
        self,
        query: str,
        vendor_id: int,
        top_k: int = None,
        similarity_threshold: float = None,
        enable_keyword_fallback: bool = None,
        enable_keyword_boost: bool = None,
        **kwargs
    ) -> List[Dict]:
        """
        çµ±ä¸€æª¢ç´¢ä»‹é¢
        å¯¦ä½œå‘é‡æª¢ç´¢ + é—œéµå­—å‚™é¸ + Reranker ç­–ç•¥

        Args:
            query: æŸ¥è©¢æ–‡å­—
            vendor_id: æ¥­è€… ID
            top_k: è¿”å›æ•¸é‡
            similarity_threshold: ç›¸ä¼¼åº¦é–¾å€¼
            enable_keyword_fallback: æ˜¯å¦å•Ÿç”¨é—œéµå­—å‚™é¸
            enable_keyword_boost: æ˜¯å¦å•Ÿç”¨é—œéµå­—åŠ æˆ
            **kwargs: å‚³éçµ¦å­é¡çš„é¡å¤–åƒæ•¸

        Returns:
            æª¢ç´¢çµæœåˆ—è¡¨
        """
        # ä½¿ç”¨é è¨­å€¼
        top_k = top_k or self.default_top_k
        similarity_threshold = similarity_threshold or self.default_similarity_threshold
        enable_keyword_fallback = enable_keyword_fallback if enable_keyword_fallback is not None else self.keyword_fallback_enabled
        enable_keyword_boost = enable_keyword_boost if enable_keyword_boost is not None else self.keyword_boost_enabled

        print(f"\nğŸ” [çµ±ä¸€æª¢ç´¢] æŸ¥è©¢: {query}")
        print(f"   æ¥­è€…: {vendor_id}, Top-K: {top_k}, é–¾å€¼: {similarity_threshold}")
        print(f"   é—œéµå­—å‚™é¸: {enable_keyword_fallback}, é—œéµå­—åŠ æˆ: {enable_keyword_boost}")

        # Step 1: ç”ŸæˆæŸ¥è©¢å‘é‡
        query_embedding = await self._get_embedding(query)
        if not query_embedding:
            print("âš ï¸ å‘é‡ç”Ÿæˆå¤±æ•—ï¼Œé™ç´šç‚ºç´”é—œéµå­—æª¢ç´¢")
            if enable_keyword_fallback:
                return await self._keyword_search(query, vendor_id, top_k, **kwargs)
            return []

        # Step 2: å‘é‡æª¢ç´¢
        results = await self._vector_search(
            query_embedding, vendor_id, top_k, similarity_threshold, **kwargs
        )
        print(f"   å‘é‡æª¢ç´¢: æ‰¾åˆ° {len(results)} å€‹çµæœ")

        # Step 3: é—œéµå­—å‚™é¸ï¼ˆå¦‚æœçµæœä¸è¶³ï¼‰
        if enable_keyword_fallback and len(results) < top_k:
            print(f"   å•Ÿå‹•é—œéµå­—å‚™é¸ï¼ˆéœ€è¦è£œå…… {top_k - len(results)} å€‹ï¼‰")
            keyword_results = await self._keyword_search(
                query, vendor_id, top_k - len(results), **kwargs
            )

            # åˆä½µçµæœï¼ˆå»é‡ï¼‰
            existing_ids = {r.get('id') for r in results}
            added = 0
            for kr in keyword_results:
                if kr.get('id') not in existing_ids:
                    kr['search_method'] = 'keyword_fallback'
                    results.append(kr)
                    added += 1

            if added > 0:
                print(f"   é—œéµå­—å‚™é¸: æ–°å¢ {added} å€‹çµæœ")

        # Step 4: é—œéµå­—åŠ æˆ
        if enable_keyword_boost and results:
            results = await self._apply_keyword_boost(results, query)
            print(f"   é—œéµå­—åŠ æˆ: å·²æ‡‰ç”¨")

        # Step 5: Reranker
        if self.reranker and len(results) > 0:
            results = self._apply_reranker(query, results)
            print(f"   Reranker: å·²é‡æ’åº")

        print(f"   æœ€çµ‚çµæœ: {len(results)} å€‹")
        return results

    async def _apply_keyword_boost(self, results: List[Dict], query: str) -> List[Dict]:
        """
        æ‡‰ç”¨é—œéµå­—åŠ æˆ

        Args:
            results: æª¢ç´¢çµæœ
            query: åŸå§‹æŸ¥è©¢

        Returns:
            åŠ æˆå¾Œçš„çµæœ
        """
        query_tokens = set(jieba.cut(query.lower()))

        for result in results:
            keywords = result.get('keywords', [])
            if not keywords:
                continue

            # è¨ˆç®—é—œéµå­—åŒ¹é…
            matched_keywords = []
            for keyword in keywords:
                keyword_tokens = set(jieba.cut(keyword.lower()))
                if query_tokens & keyword_tokens:  # æœ‰äº¤é›†
                    matched_keywords.append(keyword)

            # æ‡‰ç”¨åŠ æˆ
            if matched_keywords:
                boost = min(0.3, len(matched_keywords) * 0.1)  # æœ€å¤š 30% åŠ æˆ
                original_score = result.get('similarity', 0)
                result['similarity'] = min(1.0, original_score * (1 + boost))
                result['keyword_matches'] = matched_keywords
                result['keyword_boost'] = boost

        # é‡æ–°æ’åº
        results.sort(key=lambda x: x.get('similarity', 0), reverse=True)
        return results

    def _apply_reranker(self, query: str, candidates: List[Dict]) -> List[Dict]:
        """
        ä½¿ç”¨ Reranker é‡æ’åº

        Args:
            query: æŸ¥è©¢æ–‡å­—
            candidates: å€™é¸çµæœ

        Returns:
            é‡æ’åºå¾Œçš„çµæœ
        """
        if not self.reranker or not candidates:
            return candidates

        try:
            # æº–å‚™ Reranker è¼¸å…¥
            pairs = []
            for candidate in candidates:
                # æ ¹æ“šçµæœé¡å‹é¸æ“‡æ–‡å­—
                text = candidate.get('content') or candidate.get('answer', '')
                pairs.append([query, text])

            # è¨ˆç®— rerank åˆ†æ•¸
            scores = self.reranker.compute_score(pairs, normalize=True)
            if not isinstance(scores, list):
                scores = [scores]

            # æ›´æ–°åˆ†æ•¸ï¼ˆ10% åŸå§‹ + 90% rerankï¼‰
            for i, candidate in enumerate(candidates):
                original_score = candidate.get('similarity', 0)
                rerank_score = scores[i] if i < len(scores) else 0

                candidate['original_similarity'] = original_score
                candidate['rerank_score'] = rerank_score
                candidate['similarity'] = original_score * 0.1 + rerank_score * 0.9

            # é‡æ–°æ’åº
            candidates.sort(key=lambda x: x['similarity'], reverse=True)

            return candidates

        except Exception as e:
            print(f"âš ï¸ Reranker åŸ·è¡Œå¤±æ•—: {e}")
            return candidates

    def _tokenize_chinese(self, text: str) -> set:
        """ä¸­æ–‡åˆ†è©"""
        return set(jieba.cut(text.lower()))