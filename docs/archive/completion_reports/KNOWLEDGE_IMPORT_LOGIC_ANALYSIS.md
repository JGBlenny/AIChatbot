# çŸ¥è­˜åŒ¯å…¥åŠŸèƒ½ - å®Œæ•´é‚è¼¯åˆ†æ

## æ¦‚è¿°

æœ¬æ–‡æª”è©³ç´°åˆ†æ **çŸ¥è­˜åŒ¯å…¥åŠŸèƒ½**ï¼ˆhttp://localhost:8080/knowledge-importï¼‰çš„å®Œæ•´é‚è¼¯ï¼ŒåŒ…æ‹¬å‰ç«¯ä»‹é¢ã€å¾Œç«¯ APIã€çŸ¥è­˜æå–ã€å‘é‡ç”Ÿæˆèˆ‡å„²å­˜æµç¨‹ã€‚

**èª¿æŸ¥æ—¥æœŸ**: 2025-10-12
**åŠŸèƒ½ç‹€æ…‹**: âš ï¸ **éƒ¨åˆ†å¯¦ä½œ**ï¼ˆå‰ç«¯å®Œæ•´ã€å¾Œç«¯éª¨æ¶ã€æ ¸å¿ƒé‚è¼¯å¾…æ•´åˆï¼‰

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### æ•´é«”æµç¨‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å‰ç«¯ (Vue.js)                           â”‚
â”‚                   KnowledgeImportView.vue                        â”‚
â”‚                                                                  â”‚
â”‚  Step 1: ä¸Šå‚³æª”æ¡ˆ    Step 2: é è¦½      Step 3: è™•ç†ä¸­            â”‚
â”‚  Step 4: å®Œæˆ                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ HTTP API Calls
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å¾Œç«¯ API (FastAPI)                          â”‚
â”‚                    knowledge_import.py                           â”‚
â”‚                                                                  â”‚
â”‚  POST /upload    â†’ é–‹å§‹åŒ¯å…¥ä½œæ¥­                                   â”‚
â”‚  GET /jobs/{id}  â†’ è¼ªè©¢ä½œæ¥­ç‹€æ…‹                                   â”‚
â”‚  POST /preview   â†’ é è¦½æª”æ¡ˆå…§å®¹ï¼ˆä¸æ¶ˆè€— tokenï¼‰                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ TODO: æ•´åˆçŸ¥è­˜æå–é‚è¼¯ âš ï¸
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  çŸ¥è­˜æå–èˆ‡è™•ç† (Scripts)                         â”‚
â”‚                                                                  â”‚
â”‚  â€¢ extract_knowledge_and_tests.py    â† LINE èŠå¤©è¨˜éŒ„æå–         â”‚
â”‚  â€¢ import_excel_to_kb.py             â† Excel åŒ¯å…¥ + å‘é‡ç”Ÿæˆ     â”‚
â”‚  â€¢ import_extracted_to_db.py         â† è³‡æ–™åº«åŒ¯å…¥                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å‘é‡ç”Ÿæˆèˆ‡å„²å­˜                                 â”‚
â”‚                                                                  â”‚
â”‚  OpenAI API                PostgreSQL                           â”‚
â”‚  text-embedding-3-small â†’ knowledge_base.embedding (vector)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“± å‰ç«¯å¯¦ä½œåˆ†æ

### æª”æ¡ˆä½ç½®
**`knowledge-admin/frontend/src/views/KnowledgeImportView.vue`** (883 è¡Œ)

### æ ¸å¿ƒåŠŸèƒ½

#### 1. å››æ­¥é©Ÿå‘å°ä»‹é¢

```javascript
data() {
  return {
    currentStep: 1,  // 1=ä¸Šå‚³, 2=é è¦½, 3=è™•ç†ä¸­, 4=å®Œæˆ
    uploadedFile: null,
    previewData: null,
    jobId: null,
    jobStatus: null,
    pollingInterval: null
  };
}
```

#### 2. æª”æ¡ˆä¸Šå‚³ (Step 1)

**æ”¯æ´åŠŸèƒ½**:
- æ‹–æ”¾ä¸Šå‚³ (Drag & Drop)
- æª”æ¡ˆé»æ“Šé¸æ“‡
- æª”æ¡ˆé¡å‹é©—è­‰ï¼ˆExcel, PDF, TXTï¼‰
- æª”æ¡ˆå¤§å°é™åˆ¶ï¼ˆ50MBï¼‰

**é—œéµç¨‹å¼ç¢¼**:
```javascript
async uploadFile() {
  const formData = new FormData();
  formData.append('file', this.uploadedFile);
  formData.append('vendor_id', this.selectedVendor);
  formData.append('import_mode', this.importOptions.mode);
  formData.append('enable_deduplication', this.importOptions.deduplication);

  const response = await axios.post(
    `${RAG_API}/knowledge-import/upload`,
    formData,
    { headers: { 'Content-Type': 'multipart/form-data' } }
  );

  this.jobId = response.data.job_id;
  this.currentStep = 3;  // é€²å…¥è™•ç†ä¸­éšæ®µ
  this.startPolling();   // é–‹å§‹è¼ªè©¢ä½œæ¥­ç‹€æ…‹
}
```

#### 3. æª”æ¡ˆé è¦½ (Step 2)

**åŠŸèƒ½**:
- é¡¯ç¤ºæª”æ¡ˆå…§å®¹é è¦½
- å±•ç¤ºå°‡è¦æå–çš„çŸ¥è­˜æ•¸é‡ä¼°è¨ˆ
- å…è¨±èª¿æ•´åŒ¯å…¥é¸é …

**åŒ¯å…¥é¸é …**:
```javascript
importOptions: {
  mode: 'append',         // append | replace | merge
  deduplication: true,    // å•Ÿç”¨å»é‡
  autoClassify: true      // è‡ªå‹•åˆ†é¡
}
```

#### 4. è™•ç†ä¸­ (Step 3) - è¼ªè©¢æ©Ÿåˆ¶

**ç‹€æ…‹è¼ªè©¢**:
```javascript
startPolling() {
  this.pollingInterval = setInterval(async () => {
    const response = await axios.get(
      `${RAG_API}/knowledge-import/jobs/${this.jobId}`
    );
    this.jobStatus = response.data;

    if (response.data.status === 'completed') {
      clearInterval(this.pollingInterval);
      this.currentStep = 4;  // é€²å…¥å®Œæˆéšæ®µ
    } else if (response.data.status === 'failed') {
      clearInterval(this.pollingInterval);
      this.showError(response.data.error);
    }
  }, 2000);  // æ¯ 2 ç§’è¼ªè©¢ä¸€æ¬¡
}
```

**é€²åº¦é¡¯ç¤º**:
- è®€å–é€²åº¦æ¢
- è™•ç†ç‹€æ…‹æ–‡å­—
- å·²è™•ç† / ç¸½æ•¸
- é ä¼°å‰©é¤˜æ™‚é–“

#### 5. å®Œæˆ (Step 4)

**é¡¯ç¤ºè³‡è¨Š**:
- æˆåŠŸåŒ¯å…¥çš„çŸ¥è­˜æ•¸é‡
- è·³éçš„é‡è¤‡é …
- éŒ¯èª¤é …ç›®
- è™•ç†æ™‚é–“
- æ“ä½œæŒ‰éˆ•ï¼ˆé‡æ–°åŒ¯å…¥ã€æŸ¥çœ‹çŸ¥è­˜åº«ï¼‰

---

## ğŸ”§ å¾Œç«¯ API å¯¦ä½œåˆ†æ

### æª”æ¡ˆä½ç½®
**`rag-orchestrator/routers/knowledge_import.py`** (306 è¡Œ)

### API ç«¯é»

#### 1. POST `/api/v1/knowledge-import/upload`

**åŠŸèƒ½**: é–‹å§‹çŸ¥è­˜åŒ¯å…¥ä½œæ¥­

**è«‹æ±‚åƒæ•¸**:
```python
class UploadFileRequest:
    file: UploadFile              # ä¸Šå‚³çš„æª”æ¡ˆ
    vendor_id: Optional[int]      # æ¥­è€… ID
    import_mode: str              # append | replace | merge
    enable_deduplication: bool    # å•Ÿç”¨å»é‡
```

**å›æ‡‰**:
```json
{
  "job_id": "uuid-string",
  "status": "processing",
  "message": "çŸ¥è­˜åŒ¯å…¥ä½œæ¥­å·²é–‹å§‹"
}
```

**å¯¦ä½œç‹€æ…‹**: âš ï¸ **éª¨æ¶å¯¦ä½œ**

```python
@router.post("/upload")
async def upload_knowledge_file(
    file: UploadFile = File(...),
    vendor_id: Optional[int] = Form(None),
    import_mode: str = Form("append"),
    enable_deduplication: bool = Form(True),
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    # 1. å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„
    job_id = str(uuid.uuid4())
    file_path = save_uploaded_file(file, job_id)

    # 2. å»ºç«‹ä½œæ¥­è¨˜éŒ„ï¼ˆå„²å­˜åˆ°è³‡æ–™åº«æˆ–è¨˜æ†¶é«”ï¼‰
    job_record = {
        "job_id": job_id,
        "status": "processing",
        "file_name": file.filename,
        "vendor_id": vendor_id,
        "import_mode": import_mode,
        "created_at": datetime.now()
    }

    # 3. ä½¿ç”¨èƒŒæ™¯ä»»å‹™è™•ç†
    background_tasks.add_task(
        process_import_job,
        job_id=job_id,
        file_path=file_path,
        vendor_id=vendor_id,
        import_mode=import_mode,
        enable_deduplication=enable_deduplication
    )

    return {"job_id": job_id, "status": "processing"}
```

**ç¬¬ 100 è¡Œé‡è¦è¨»è§£**:
```python
# TODO: æ•´åˆ extract_knowledge_and_tests.py çš„é‚è¼¯
```

#### 2. GET `/api/v1/knowledge-import/jobs/{job_id}`

**åŠŸèƒ½**: æŸ¥è©¢ä½œæ¥­ç‹€æ…‹ï¼ˆç”¨æ–¼å‰ç«¯è¼ªè©¢ï¼‰

**å›æ‡‰**:
```json
{
  "job_id": "uuid",
  "status": "processing | completed | failed",
  "progress": {
    "current": 45,
    "total": 100,
    "percentage": 45
  },
  "result": {
    "imported": 80,
    "skipped": 15,
    "errors": 5
  },
  "error": null,
  "created_at": "2025-10-12T10:30:00Z",
  "completed_at": null
}
```

#### 3. POST `/api/v1/knowledge-import/preview`

**åŠŸèƒ½**: é è¦½æª”æ¡ˆå…§å®¹ï¼ˆä¸å¯¦éš›åŒ¯å…¥ï¼Œä¸æ¶ˆè€— OpenAI tokenï¼‰

**å¯¦ä½œç‹€æ…‹**: âš ï¸ **æœªå¯¦ä½œ**

```python
@router.post("/preview")
async def preview_knowledge_file(file: UploadFile = File(...)):
    # TODO: å¯¦ä½œæª”æ¡ˆé è¦½é‚è¼¯
    #   - è®€å–æª”æ¡ˆå‰å¹¾è¡Œ
    #   - ä¼°è¨ˆçŸ¥è­˜æ¢ç›®æ•¸é‡
    #   - æª¢æŸ¥æ ¼å¼æ˜¯å¦æ­£ç¢º
    pass
```

#### 4. GET `/api/v1/knowledge-import/jobs`

**åŠŸèƒ½**: åˆ—å‡ºåŒ¯å…¥æ­·å²è¨˜éŒ„

#### 5. DELETE `/api/v1/knowledge-import/jobs/{job_id}`

**åŠŸèƒ½**: åˆªé™¤ä½œæ¥­è¨˜éŒ„

---

## ğŸ¤– çŸ¥è­˜æå–é‚è¼¯åˆ†æ

### 1. LINE èŠå¤©è¨˜éŒ„æå–

**æª”æ¡ˆ**: `/Users/lenny/jgb/AIChatbot/scripts/knowledge_extraction/extract_knowledge_and_tests.py` (339 è¡Œ)

#### æ ¸å¿ƒæµç¨‹

```python
class LineKnowledgeExtractor:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = "gpt-4o-mini"

    def process_all_files(self, file_paths: List[str]):
        """è™•ç†æ‰€æœ‰ LINE èŠå¤©è¨˜éŒ„"""
        for file_path in file_paths:
            # 1. è§£æ LINE èŠå¤©è¨˜éŒ„
            messages = self.parse_line_chat(file_path)

            # 2. ä½¿ç”¨ LLM æå–å•ç­”å°å’Œæ¸¬è©¦æƒ…å¢ƒ
            qa_pairs, test_scenarios = self.extract_qa_pairs_and_tests(
                messages,
                source_file=os.path.basename(file_path)
            )

            # 3. å„²å­˜ç‚º Excel
            self.save_to_excel(qa_pairs, test_scenarios, output_dir)
```

#### LLM æå–æç¤ºè©

```python
system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å®¢æœçŸ¥è­˜åº«åˆ†æå¸«ã€‚åˆ†æ LINE å°è©±è¨˜éŒ„ï¼Œæå–ï¼š

1. **å•ç­”å°ï¼ˆQA Pairsï¼‰**ï¼šæå–å®¢æœå›ç­”çš„å•é¡Œå’Œç­”æ¡ˆ
   - å•é¡Œè¦é€šç”¨åŒ–ï¼ˆç§»é™¤å…·é«”ç§Ÿå®¢å§“åã€æˆ¿è™Ÿç­‰ï¼‰
   - ç­”æ¡ˆè¦å®Œæ•´ä¸”å¯¦ç”¨
   - è­˜åˆ¥å•é¡Œé¡å‹ï¼ˆå¸³å‹™/åˆç´„/æœå‹™/è¨­æ–½ï¼‰
   - åˆ¤æ–·å°è±¡ï¼ˆæˆ¿æ±/ç§Ÿå®¢/ç®¡ç†å¸«ï¼‰

2. **æ¸¬è©¦æƒ…å¢ƒï¼ˆTest Scenariosï¼‰**ï¼šæå–å¯ä»¥ä½œç‚ºæ¸¬è©¦çš„çœŸå¯¦å•é¡Œ
   - ä¿ç•™å•é¡Œçš„åŸå§‹è¡¨é”æ–¹å¼
   - è¨˜éŒ„é æœŸç­”æ¡ˆçš„é—œéµè¦é»
   - åˆ†é¡æ¸¬è©¦å ´æ™¯

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼š
{
  "qa_pairs": [
    {
      "title": "å•é¡Œæ¨™é¡Œ",
      "category": "å¸³å‹™å•é¡Œ|åˆç´„å•é¡Œ|æœå‹™å•é¡Œ|è¨­æ–½å•é¡Œ",
      "question_summary": "å•é¡Œæ‘˜è¦",
      "answer": "å®Œæ•´ç­”æ¡ˆ",
      "audience": "æˆ¿æ±|ç§Ÿå®¢|ç®¡ç†å¸«",
      "keywords": ["é—œéµå­—1", "é—œéµå­—2"]
    }
  ],
  "test_scenarios": [...]
}
"""
```

#### æ‰¹æ¬¡è™•ç†

```python
def extract_qa_pairs_and_tests(
    self,
    messages: List[Dict],
    source_file: str,
    batch_size: int = 50
):
    """å°‡è¨Šæ¯åˆ†æ‰¹è™•ç†ï¼Œé¿å…è¶…å‡º token é™åˆ¶"""
    for i in range(0, len(messages), batch_size):
        batch = messages[i:i+batch_size]
        batch_text = self._format_messages_for_llm(batch)

        # å‘¼å« LLM æå–
        extracted = self._call_llm_extract(batch_text, source_file)

        qa_pairs.extend(extracted['qa_pairs'])
        test_scenarios.extend(extracted['test_scenarios'])

        # é¿å… API rate limit
        time.sleep(1)
```

#### è¼¸å‡ºæ ¼å¼

**ç”Ÿæˆå…©å€‹ Excel æª”æ¡ˆ**:
1. `knowledge_base_extracted.xlsx` - æå–çš„çŸ¥è­˜åº«
2. `test_scenarios.xlsx` - æ¸¬è©¦æƒ…å¢ƒ

---

### 2. Excel åŒ¯å…¥èˆ‡å‘é‡ç”Ÿæˆ

**æª”æ¡ˆ**: `/Users/lenny/jgb/AIChatbot/scripts/knowledge_extraction/import_excel_to_kb.py` (357 è¡Œ)

#### æ ¸å¿ƒæµç¨‹

```python
class ExcelKnowledgeImporter:
    async def import_to_database(
        self,
        knowledge_list: List[Dict],
        vendor_id: int = None,
        batch_generate_questions: bool = True
    ):
        """åŒ¯å…¥çŸ¥è­˜åˆ°è³‡æ–™åº«"""

        for knowledge in knowledge_list:
            # 1. ç”Ÿæˆå•é¡Œæ‘˜è¦ï¼ˆä½¿ç”¨ LLMï¼‰
            question_summary = self.generate_question_summary(
                knowledge['answer'],
                knowledge['category']
            )

            # 2. æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆå»é‡ï¼‰
            exists = await self.conn.fetchval("""
                SELECT COUNT(*) FROM knowledge_base
                WHERE question_summary = $1 AND answer = $2
            """, question_summary, knowledge['answer'])

            if exists > 0:
                continue  # è·³éé‡è¤‡é …

            # 3. ç”Ÿæˆå‘é‡åµŒå…¥ â­ æ ¸å¿ƒæ­¥é©Ÿ
            embedding_response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=f"{question_summary} {knowledge['answer'][:200]}"
            )
            embedding = embedding_response.data[0].embedding

            # 4. æ’å…¥è³‡æ–™åº«
            await self.conn.execute("""
                INSERT INTO knowledge_base (
                    intent_id,
                    vendor_id,
                    title,
                    category,
                    question_summary,
                    answer,
                    audience,
                    keywords,
                    source_file,
                    source_date,
                    embedding,    â† å‘é‡æ¬„ä½
                    scope,
                    priority,
                    created_at,
                    updated_at
                ) VALUES (
                    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13,
                    CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
                )
            """, ...)
```

#### å‘é‡ç”Ÿæˆç´°ç¯€

**ä½¿ç”¨çš„ OpenAI æ¨¡å‹**:
- `text-embedding-3-small` (1536 ç¶­)

**åµŒå…¥æ–‡å­—æ ¼å¼**:
```python
input_text = f"{question_summary} {knowledge['answer'][:200]}"
# ç¯„ä¾‹: "å¦‚ä½•é€€ç§Ÿï¼Ÿ é€€ç§Ÿæµç¨‹å¦‚ä¸‹ï¼š1. æå‰ä¸€å€‹æœˆå‘ŠçŸ¥ 2. å¡«å¯«é€€ç§Ÿ..."
```

**å‘é‡å„²å­˜**:
- è³‡æ–™è¡¨: `knowledge_base`
- æ¬„ä½: `embedding` (type: `vector(1536)`)
- ç”¨é€”: èªæ„ç›¸ä¼¼åº¦æœå°‹

---

## ğŸ” å‘é‡æª¢ç´¢é‚è¼¯åˆ†æ

### æª”æ¡ˆä½ç½®
**`rag-orchestrator/services/rag_engine.py`** (413 è¡Œ)

### æ ¸å¿ƒæœå°‹é‚è¼¯

```python
class RAGEngine:
    async def search(
        self,
        query: str,
        limit: int = 5,
        similarity_threshold: float = 0.6,
        intent_ids: Optional[List[int]] = None,
        primary_intent_id: Optional[int] = None,
        allowed_audiences: Optional[List[str]] = None
    ) -> List[Dict]:
        """æœå°‹ç›¸é—œçŸ¥è­˜"""

        # 1. å°‡å•é¡Œè½‰æ›ç‚ºå‘é‡
        query_embedding = await self._get_embedding(query)

        # 2. å‘é‡ç›¸ä¼¼åº¦æœå°‹
        results = await conn.fetch("""
            SELECT
                id,
                title,
                answer as content,
                category,
                audience,
                keywords,
                1 - (embedding <=> $1::vector) as base_similarity
            FROM knowledge_base
            WHERE embedding IS NOT NULL
                AND (1 - (embedding <=> $1::vector)) >= $2
                AND (audience IS NULL OR audience = ANY($4::text[]))
            ORDER BY embedding <=> $1::vector
            LIMIT $3
        """, vector_str, similarity_threshold, limit, allowed_audiences)

        return search_results
```

### ç›¸ä¼¼åº¦è¨ˆç®—

**PostgreSQL å‘é‡æ“ä½œç¬¦**:
- `<=>` : é¤˜å¼¦è·é›¢ï¼ˆCosine Distanceï¼‰
- `1 - (embedding <=> query)` : é¤˜å¼¦ç›¸ä¼¼åº¦ï¼ˆç¯„åœ 0-1ï¼‰

**éæ¿¾æ¢ä»¶**:
1. `embedding IS NOT NULL` - å¿…é ˆæœ‰å‘é‡
2. `similarity >= threshold` - ç›¸ä¼¼åº¦è¶…éé–¾å€¼ï¼ˆé è¨­ 0.6ï¼‰
3. `audience = ANY(allowed_audiences)` - Business Scope éæ¿¾

### Embedding API å‘¼å«

```python
async def _get_embedding(self, text: str) -> Optional[List[float]]:
    """å‘¼å« Embedding API å°‡æ–‡å­—è½‰æ›ç‚ºå‘é‡"""
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(
            self.embedding_api_url,  # http://embedding-api:5000/api/v1/embeddings
            json={"text": text}
        )
        data = response.json()
        return data.get('embedding')
```

---

## ğŸ“Š è³‡æ–™åº« Schema

### knowledge_base è¡¨çµæ§‹

```sql
CREATE TABLE knowledge_base (
    id SERIAL PRIMARY KEY,
    intent_id INTEGER REFERENCES intents(id),
    vendor_id INTEGER REFERENCES vendors(id),
    title VARCHAR(255),
    category VARCHAR(100),
    question_summary TEXT,
    answer TEXT,
    audience VARCHAR(50),              -- æˆ¿æ±/ç§Ÿå®¢/ç®¡ç†å¸«
    keywords TEXT[],
    source_file VARCHAR(255),
    source_date DATE,
    embedding vector(1536),            â­ å‘é‡æ¬„ä½
    scope VARCHAR(50),                 -- global/vendor
    priority INTEGER DEFAULT 0,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

-- å‘é‡ç´¢å¼•ï¼ˆæå‡æª¢ç´¢æ•ˆèƒ½ï¼‰
CREATE INDEX idx_knowledge_embedding ON knowledge_base
USING ivfflat (embedding vector_cosine_ops);
```

### knowledge_import_jobs è¡¨ï¼ˆå»ºè­°æ–°å¢ï¼‰

```sql
CREATE TABLE knowledge_import_jobs (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    vendor_id INTEGER REFERENCES vendors(id),
    file_name VARCHAR(255),
    file_path VARCHAR(500),
    status VARCHAR(50),                -- processing/completed/failed
    import_mode VARCHAR(50),           -- append/replace/merge
    enable_deduplication BOOLEAN,

    -- é€²åº¦è¿½è¹¤
    total_items INTEGER,
    processed_items INTEGER,
    imported_count INTEGER,
    skipped_count INTEGER,
    error_count INTEGER,

    -- æ™‚é–“æˆ³
    created_at TIMESTAMP DEFAULT NOW(),
    started_at TIMESTAMP,
    completed_at TIMESTAMP,

    -- éŒ¯èª¤è³‡è¨Š
    error_message TEXT
);
```

---

## ğŸ”§ æ•´åˆæ–¹æ¡ˆå»ºè­°

### å•é¡Œåˆ†æ

**ç•¶å‰ç‹€æ…‹**:
1. âœ… å‰ç«¯ä»‹é¢å®Œæ•´ï¼ˆ4 æ­¥é©Ÿå‘å°ã€æª”æ¡ˆä¸Šå‚³ã€è¼ªè©¢æ©Ÿåˆ¶ï¼‰
2. âš ï¸ å¾Œç«¯ API æ˜¯éª¨æ¶å¯¦ä½œï¼ˆTODO è¨»è§£è¡¨ç¤ºéœ€æ•´åˆï¼‰
3. âœ… çŸ¥è­˜æå–è…³æœ¬å­˜åœ¨ä½†æ˜¯ç¨ç«‹çš„å‘½ä»¤è¡Œå·¥å…·
4. âŒ å‰å¾Œç«¯æœªæ•´åˆ

**æ ¸å¿ƒå•é¡Œ**:
- `knowledge_import.py:100` æœ‰ TODO è¨»è§£è¦æ•´åˆ `extract_knowledge_and_tests.py`
- ä½† `extract_knowledge_and_tests.py` æ˜¯è¨­è¨ˆç”¨æ–¼è™•ç† LINE èŠå¤©è¨˜éŒ„çš„è…³æœ¬
- å‰ç«¯ä¸Šå‚³çš„å¯èƒ½æ˜¯ Excelã€PDF æˆ– TXT æª”æ¡ˆï¼Œä¸ä¸€å®šæ˜¯ LINE æ ¼å¼

### å»ºè­°æ•´åˆæ–¹æ¡ˆ

#### æ–¹æ¡ˆ A: é‡æ§‹ç‚ºé€šç”¨åŒ¯å…¥æœå‹™

**æ­¥é©Ÿ**:

1. **å»ºç«‹çµ±ä¸€çš„çŸ¥è­˜åŒ¯å…¥æœå‹™**

```python
# rag-orchestrator/services/knowledge_import_service.py

class KnowledgeImportService:
    """çµ±ä¸€çš„çŸ¥è­˜åŒ¯å…¥æœå‹™"""

    async def process_import_job(
        self,
        job_id: str,
        file_path: str,
        file_type: str,  # 'excel' | 'pdf' | 'txt' | 'line_chat'
        vendor_id: Optional[int],
        import_mode: str,
        enable_deduplication: bool
    ):
        """è™•ç†çŸ¥è­˜åŒ¯å…¥ä½œæ¥­"""

        # 1. æ ¹æ“šæª”æ¡ˆé¡å‹é¸æ“‡è§£æå™¨
        if file_type == 'excel':
            parser = ExcelKnowledgeParser()
        elif file_type == 'line_chat':
            parser = LineKnowledgeParser()
        elif file_type == 'pdf':
            parser = PDFKnowledgeParser()
        else:
            parser = TextKnowledgeParser()

        # 2. è§£ææª”æ¡ˆ
        knowledge_list = await parser.parse(file_path)

        # 3. LLM è™•ç†ï¼ˆå•é¡Œç”Ÿæˆã€åˆ†é¡ç­‰ï¼‰
        processed = await self.process_with_llm(knowledge_list)

        # 4. ç”Ÿæˆå‘é‡
        embedded = await self.generate_embeddings(processed)

        # 5. å»é‡ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if enable_deduplication:
            embedded = await self.deduplicate(embedded)

        # 6. åŒ¯å…¥è³‡æ–™åº«
        result = await self.import_to_database(
            embedded,
            vendor_id=vendor_id,
            import_mode=import_mode
        )

        # 7. æ›´æ–°ä½œæ¥­ç‹€æ…‹
        await self.update_job_status(job_id, 'completed', result)
```

2. **å¯¦ä½œå„ç¨®æª”æ¡ˆè§£æå™¨**

```python
class ExcelKnowledgeParser:
    async def parse(self, file_path: str) -> List[Dict]:
        """è§£æ Excel æª”æ¡ˆ"""
        df = pd.read_excel(file_path)
        # è§£æé‚è¼¯...
        return knowledge_list

class LineKnowledgeParser:
    """é‡ç”¨ extract_knowledge_and_tests.py çš„é‚è¼¯"""
    async def parse(self, file_path: str) -> List[Dict]:
        extractor = LineKnowledgeExtractor()
        messages = extractor.parse_line_chat(file_path)
        qa_pairs, _ = extractor.extract_qa_pairs_and_tests(messages, file_path)
        return qa_pairs

class PDFKnowledgeParser:
    async def parse(self, file_path: str) -> List[Dict]:
        """è§£æ PDF æª”æ¡ˆï¼ˆä½¿ç”¨ PyPDF2 æˆ– pdfplumberï¼‰"""
        # PDF è§£æé‚è¼¯...
        pass
```

3. **æ›´æ–°å¾Œç«¯ API**

```python
# knowledge_import.py

@router.post("/upload")
async def upload_knowledge_file(
    file: UploadFile = File(...),
    vendor_id: Optional[int] = Form(None),
    import_mode: str = Form("append"),
    enable_deduplication: bool = Form(True),
    background_tasks: BackgroundTasks = BackgroundTasks()
):
    # 1. å„²å­˜æª”æ¡ˆ
    job_id = str(uuid.uuid4())
    file_path = await save_uploaded_file(file, job_id)

    # 2. åµæ¸¬æª”æ¡ˆé¡å‹
    file_type = detect_file_type(file.filename, file.content_type)

    # 3. å»ºç«‹ä½œæ¥­è¨˜éŒ„
    await create_import_job(
        job_id=job_id,
        vendor_id=vendor_id,
        file_name=file.filename,
        file_path=file_path,
        import_mode=import_mode
    )

    # 4. å•Ÿå‹•èƒŒæ™¯è™•ç†
    service = KnowledgeImportService(db_pool=request.app.state.db_pool)
    background_tasks.add_task(
        service.process_import_job,
        job_id=job_id,
        file_path=file_path,
        file_type=file_type,
        vendor_id=vendor_id,
        import_mode=import_mode,
        enable_deduplication=enable_deduplication
    )

    return {"job_id": job_id, "status": "processing"}
```

4. **å¯¦ä½œä½œæ¥­ç‹€æ…‹è¿½è¹¤**

```python
# ä½¿ç”¨ Redis æˆ– PostgreSQL å„²å­˜ä½œæ¥­ç‹€æ…‹

async def update_job_progress(job_id: str, current: int, total: int):
    """æ›´æ–°ä½œæ¥­é€²åº¦"""
    await redis.hset(f"import_job:{job_id}", {
        "current": current,
        "total": total,
        "percentage": int(current / total * 100),
        "updated_at": datetime.now().isoformat()
    })

async def get_job_status(job_id: str) -> Dict:
    """å–å¾—ä½œæ¥­ç‹€æ…‹ï¼ˆä¾›å‰ç«¯è¼ªè©¢ï¼‰"""
    job_data = await redis.hgetall(f"import_job:{job_id}")
    return job_data
```

#### æ–¹æ¡ˆ B: ç°¡åŒ–ç‰ˆ - åƒ…æ”¯æ´ Excel

**é©ç”¨å ´æ™¯**: å¦‚æœåªéœ€è¦æ”¯æ´ Excel æª”æ¡ˆåŒ¯å…¥

**æ­¥é©Ÿ**:
1. ç›´æ¥æ•´åˆ `import_excel_to_kb.py` çš„é‚è¼¯åˆ° `knowledge_import.py`
2. ç§»é™¤ LINE èŠå¤©è¨˜éŒ„ç›¸é—œåŠŸèƒ½
3. ç°¡åŒ–æª”æ¡ˆé¡å‹åˆ¤æ–·

---

## ğŸ¯ å®Œæ•´è³‡æ–™æµç¨‹

### æ¨™æº–åŒ¯å…¥æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ä½¿ç”¨è€…ä¸Šå‚³æª”æ¡ˆ                                              â”‚
â”‚    â†’ å‰ç«¯: KnowledgeImportView.vue                            â”‚
â”‚    â†’ File: customer_qa.xlsx (50 æ¢ QA)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ HTTP POST /knowledge-import/upload
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. å¾Œç«¯æ¥æ”¶æª”æ¡ˆä¸¦å»ºç«‹ä½œæ¥­                                       â”‚
â”‚    â†’ API: knowledge_import.py                                â”‚
â”‚    â†’ ç”Ÿæˆ job_id: "a1b2c3d4-..."                             â”‚
â”‚    â†’ å„²å­˜æª”æ¡ˆåˆ°è‡¨æ™‚ç›®éŒ„                                         â”‚
â”‚    â†’ è¿”å› job_id çµ¦å‰ç«¯                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ å•Ÿå‹•èƒŒæ™¯ä»»å‹™
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. èƒŒæ™¯è™•ç† - æª”æ¡ˆè§£æ                                         â”‚
â”‚    â†’ è®€å– Excel: 50 è¡Œè³‡æ–™                                    â”‚
â”‚    â†’ è§£ææ¬„ä½: å•é¡Œã€ç­”æ¡ˆã€åˆ†é¡ã€å°è±¡                           â”‚
â”‚    â†’ éæ¿¾ç„¡æ•ˆè³‡æ–™: å‰©é¤˜ 45 æ¢                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ æ›´æ–°é€²åº¦: 10%
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LLM è™•ç† - å•é¡Œç”Ÿæˆ                                         â”‚
â”‚    â†’ å°æ¯æ¢ç­”æ¡ˆç”Ÿæˆå•é¡Œæ‘˜è¦                                     â”‚
â”‚    â†’ OpenAI API: gpt-4o-mini                                 â”‚
â”‚    â†’ ç”Ÿæˆ 45 å€‹å•é¡Œæ‘˜è¦                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ æ›´æ–°é€²åº¦: 40%
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. å‘é‡ç”Ÿæˆ                                                   â”‚
â”‚    â†’ OpenAI Embeddings API                                   â”‚
â”‚    â†’ Model: text-embedding-3-small                           â”‚
â”‚    â†’ ç‚ºæ¯å€‹ QA ç”Ÿæˆ 1536 ç¶­å‘é‡                               â”‚
â”‚    â†’ ç”Ÿæˆ 45 å€‹å‘é‡                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ æ›´æ–°é€²åº¦: 70%
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. å»é‡æª¢æŸ¥ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰                                         â”‚
â”‚    â†’ æŸ¥è©¢è³‡æ–™åº«æ˜¯å¦å­˜åœ¨ç›¸åŒçš„ question + answer                 â”‚
â”‚    â†’ è·³é 5 æ¢é‡è¤‡é …                                          â”‚
â”‚    â†’ å‰©é¤˜ 40 æ¢å¾…åŒ¯å…¥                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ æ›´æ–°é€²åº¦: 85%
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. è³‡æ–™åº«åŒ¯å…¥                                                 â”‚
â”‚    â†’ INSERT INTO knowledge_base                              â”‚
â”‚    â†’ æ‰¹æ¬¡æ’å…¥ 40 æ¢çŸ¥è­˜                                        â”‚
â”‚    â†’ åŒ…å« title, category, answer, audience, keywords,       â”‚
â”‚             embedding, vendor_id                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ æ›´æ–°é€²åº¦: 100%
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. ä½œæ¥­å®Œæˆ                                                   â”‚
â”‚    â†’ æ›´æ–°ä½œæ¥­ç‹€æ…‹: completed                                  â”‚
â”‚    â†’ è¨˜éŒ„çµæœ:                                                â”‚
â”‚      - imported: 40                                          â”‚
â”‚      - skipped: 5 (é‡è¤‡)                                     â”‚
â”‚      - errors: 0                                             â”‚
â”‚    â†’ æ¸…ç†è‡¨æ™‚æª”æ¡ˆ                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ å‰ç«¯è¼ªè©¢å–å¾—çµæœ
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. å‰ç«¯é¡¯ç¤ºå®Œæˆçµæœ                                            â”‚
â”‚    â†’ Step 4: å®Œæˆé é¢                                         â”‚
â”‚    â†’ é¡¯ç¤ºåŒ¯å…¥çµ±è¨ˆ                                             â”‚
â”‚    â†’ æä¾›æ“ä½œæŒ‰éˆ•ï¼ˆé‡æ–°åŒ¯å…¥ã€æŸ¥çœ‹çŸ¥è­˜åº«ï¼‰                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è¼ªè©¢æ©Ÿåˆ¶æ™‚åºåœ–

```
å‰ç«¯                   å¾Œç«¯ API                èƒŒæ™¯ä»»å‹™
 â”‚                      â”‚                       â”‚
 â”‚  POST /upload        â”‚                       â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                       â”‚
 â”‚                      â”‚  å•Ÿå‹•èƒŒæ™¯ä»»å‹™           â”‚
 â”‚                      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
 â”‚  {job_id: "a1b2"}    â”‚                       â”‚
 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
 â”‚                      â”‚                       â”‚ é–‹å§‹è™•ç†...
 â”‚  GET /jobs/a1b2      â”‚                       â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  æŸ¥è©¢ Redis/DB        â”‚
 â”‚                      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
 â”‚  {status: "processing", progress: 10%}      â”‚
 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
 â”‚                      â”‚                       â”‚
 â”‚  (ç­‰å¾… 2 ç§’)          â”‚                       â”‚
 â”‚                      â”‚                       â”‚
 â”‚  GET /jobs/a1b2      â”‚                       â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                       â”‚
 â”‚  {status: "processing", progress: 40%}      â”‚
 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
 â”‚                      â”‚                       â”‚
 â”‚  (ç­‰å¾… 2 ç§’)          â”‚                       â”‚
 â”‚                      â”‚                       â”‚ è™•ç†å®Œæˆ
 â”‚  GET /jobs/a1b2      â”‚                       â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                       â”‚
 â”‚  {status: "completed", result: {...}}       â”‚
 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
 â”‚                      â”‚                       â”‚
 â”‚  åœæ­¢è¼ªè©¢             â”‚                       â”‚
 â”‚  é¡¯ç¤ºå®Œæˆé é¢         â”‚                       â”‚
```

---

## ğŸ”’ Business Scope æ•´åˆ

### Audience éæ¿¾æ©Ÿåˆ¶

**çŸ¥è­˜åŒ¯å…¥æ™‚**:
```python
# åŒ¯å…¥æ™‚æŒ‡å®šå°è±¡ï¼ˆaudienceï¼‰
knowledge = {
    "question_summary": "å¦‚ä½•é€€ç§Ÿï¼Ÿ",
    "answer": "é€€ç§Ÿæµç¨‹èªªæ˜...",
    "audience": "ç§Ÿå®¢",  # æˆ– "æˆ¿æ±", "ç®¡ç†å¸«", "general"
    ...
}
```

**æª¢ç´¢æ™‚**:
```python
# æ ¹æ“š user_role æ±ºå®š business_scope
user_role = "customer"  # æˆ– "staff"
business_scope = "external" if user_role == "customer" else "internal"

# æ ¹æ“š business_scope å–å¾—å…è¨±çš„ audiences
allowed_audiences = BUSINESS_SCOPE_AUDIENCE_MAPPING[business_scope]['allowed_audiences']
# external: ['ç§Ÿå®¢', 'æˆ¿æ±', 'tenant', 'general', ...]
# internal: ['ç®¡ç†å¸«', 'ç³»çµ±ç®¡ç†å“¡', 'general', ...]

# æª¢ç´¢æ™‚éæ¿¾
results = await rag_engine.search(
    query="å¦‚ä½•é€€ç§Ÿï¼Ÿ",
    allowed_audiences=allowed_audiences
)
```

---

## ğŸ“ˆ æ•ˆèƒ½è€ƒé‡

### 1. OpenAI API æˆæœ¬

**æ¯æ¬¡åŒ¯å…¥ 100 æ¢çŸ¥è­˜çš„æˆæœ¬ä¼°ç®—**:

| é …ç›® | æ¨¡å‹ | ç”¨é‡ | å–®åƒ¹ | æˆæœ¬ |
|------|------|------|------|------|
| å•é¡Œç”Ÿæˆ | gpt-4o-mini | 100 * 200 tokens | $0.15/1M input | $0.003 |
| å‘é‡ç”Ÿæˆ | text-embedding-3-small | 100 * 50 tokens | $0.02/1M tokens | $0.0001 |
| **ç¸½è¨ˆ** | | | | **$0.0031** |

**å„ªåŒ–å»ºè­°**:
- æ‰¹æ¬¡è™•ç†ï¼šä¸€æ¬¡è™•ç†å¤šå€‹é …ç›®
- å¿«å–æ©Ÿåˆ¶ï¼šç›¸åŒå…§å®¹ä¸é‡è¤‡ç”Ÿæˆå‘é‡
- å»é‡åœ¨å‰ï¼šå…ˆå»é‡å†ç”Ÿæˆå‘é‡ï¼Œé¿å…æµªè²»

### 2. è³‡æ–™åº«å‘é‡æª¢ç´¢æ•ˆèƒ½

**ç´¢å¼•å„ªåŒ–**:
```sql
-- ä½¿ç”¨ IVFFlat ç´¢å¼•ï¼ˆpgvector extensionï¼‰
CREATE INDEX idx_knowledge_embedding ON knowledge_base
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);  -- lists åƒæ•¸æ ¹æ“šè³‡æ–™é‡èª¿æ•´

-- å°æ–¼ 10,000 æ¢çŸ¥è­˜ï¼šlists = 100
-- å°æ–¼ 100,000 æ¢çŸ¥è­˜ï¼šlists = 200
-- å°æ–¼ 1,000,000 æ¢çŸ¥è­˜ï¼šlists = 500
```

**æŸ¥è©¢å„ªåŒ–**:
- è¨­å®šåˆç†çš„ `similarity_threshold`ï¼ˆé¿å…è¿”å›éå¤šçµæœï¼‰
- é™åˆ¶ `limit` æ•¸é‡ï¼ˆé è¨­ 5 æ¢ï¼‰
- ä½¿ç”¨æ„åœ–éæ¿¾æ¸›å°‘æª¢ç´¢ç¯„åœ

### 3. èƒŒæ™¯ä»»å‹™è™•ç†

**ç•¶å‰å¯¦ä½œ**: FastAPI BackgroundTasksï¼ˆé©ç”¨æ–¼è¼•é‡ä»»å‹™ï¼‰

**å»ºè­°å‡ç´š**:
- **Celery** - é©åˆå¤§é‡èƒŒæ™¯ä»»å‹™
- **RQ (Redis Queue)** - è¼•é‡ç´šä»»å‹™ä½‡åˆ—
- **AWS SQS + Lambda** - é›²ç«¯æ–¹æ¡ˆ

**ç¯„ä¾‹**: Celery æ•´åˆ

```python
# celery_app.py
from celery import Celery

celery_app = Celery(
    'knowledge_import',
    broker='redis://localhost:6379/0',
    backend='redis://localhost:6379/1'
)

@celery_app.task
def process_import_job(job_id, file_path, ...):
    """ä½¿ç”¨ Celery è™•ç†åŒ¯å…¥ä½œæ¥­"""
    service = KnowledgeImportService()
    return service.process_import_job(job_id, file_path, ...)
```

---

## ğŸ§ª æ¸¬è©¦å»ºè­°

### 1. å–®å…ƒæ¸¬è©¦

```python
# tests/test_knowledge_import.py

async def test_excel_parser():
    """æ¸¬è©¦ Excel è§£æå™¨"""
    parser = ExcelKnowledgeParser()
    result = await parser.parse("test_data/sample.xlsx")

    assert len(result) > 0
    assert 'question_summary' in result[0]
    assert 'answer' in result[0]

async def test_embedding_generation():
    """æ¸¬è©¦å‘é‡ç”Ÿæˆ"""
    service = KnowledgeImportService()
    text = "å¦‚ä½•é€€ç§Ÿï¼Ÿé€€ç§Ÿéœ€è¦æå‰ä¸€å€‹æœˆé€šçŸ¥..."

    embedding = await service.generate_embedding(text)

    assert len(embedding) == 1536
    assert all(isinstance(x, float) for x in embedding)

async def test_deduplication():
    """æ¸¬è©¦å»é‡åŠŸèƒ½"""
    service = KnowledgeImportService()

    # æ–°å¢ä¸€æ¢çŸ¥è­˜
    knowledge = {
        "question_summary": "æ¸¬è©¦å•é¡Œ",
        "answer": "æ¸¬è©¦ç­”æ¡ˆ"
    }
    await service.import_to_database([knowledge])

    # å˜—è©¦æ–°å¢ç›¸åŒçš„çŸ¥è­˜ï¼ˆæ‡‰è©²è¢«è·³éï¼‰
    result = await service.deduplicate([knowledge])
    assert len(result) == 0
```

### 2. æ•´åˆæ¸¬è©¦

```python
async def test_full_import_workflow():
    """æ¸¬è©¦å®Œæ•´åŒ¯å…¥æµç¨‹"""
    # 1. ä¸Šå‚³æª”æ¡ˆ
    response = await client.post(
        "/api/v1/knowledge-import/upload",
        files={"file": open("test_data/sample.xlsx", "rb")},
        data={"vendor_id": 1, "import_mode": "append"}
    )

    job_id = response.json()["job_id"]

    # 2. è¼ªè©¢ä½œæ¥­ç‹€æ…‹
    for _ in range(30):  # æœ€å¤šç­‰å¾… 60 ç§’
        response = await client.get(f"/api/v1/knowledge-import/jobs/{job_id}")
        status = response.json()["status"]

        if status == "completed":
            break

        await asyncio.sleep(2)

    # 3. é©—è­‰çµæœ
    assert status == "completed"
    result = response.json()["result"]
    assert result["imported"] > 0
```

### 3. æ•ˆèƒ½æ¸¬è©¦

```python
async def test_large_file_import():
    """æ¸¬è©¦å¤§æª”æ¡ˆåŒ¯å…¥æ•ˆèƒ½"""
    # ç”ŸæˆåŒ…å« 1000 æ¢çŸ¥è­˜çš„æ¸¬è©¦æª”æ¡ˆ
    test_file = generate_test_excel(num_rows=1000)

    start_time = time.time()

    response = await client.post(
        "/api/v1/knowledge-import/upload",
        files={"file": test_file}
    )

    # ç­‰å¾…å®Œæˆ
    job_id = response.json()["job_id"]
    await wait_for_job_completion(job_id)

    elapsed_time = time.time() - start_time

    # é©—è­‰æ•ˆèƒ½ï¼ˆæ‡‰åœ¨ 5 åˆ†é˜å…§å®Œæˆï¼‰
    assert elapsed_time < 300
```

---

## ğŸš¨ éŒ¯èª¤è™•ç†

### å¸¸è¦‹éŒ¯èª¤æƒ…å¢ƒ

#### 1. æª”æ¡ˆæ ¼å¼éŒ¯èª¤

```python
class InvalidFileFormatError(Exception):
    """æª”æ¡ˆæ ¼å¼éŒ¯èª¤"""
    pass

async def validate_file(file: UploadFile):
    """é©—è­‰æª”æ¡ˆæ ¼å¼"""
    # æª¢æŸ¥å‰¯æª”å
    if not file.filename.endswith(('.xlsx', '.xls', '.txt', '.pdf')):
        raise InvalidFileFormatError(
            f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {file.filename}. "
            "æ”¯æ´çš„æ ¼å¼: Excel (.xlsx, .xls), TXT (.txt), PDF (.pdf)"
        )

    # æª¢æŸ¥æª”æ¡ˆå¤§å°ï¼ˆ50MB é™åˆ¶ï¼‰
    if file.size > 50 * 1024 * 1024:
        raise InvalidFileFormatError("æª”æ¡ˆå¤§å°è¶…é 50MB é™åˆ¶")

    # æª¢æŸ¥æª”æ¡ˆå…§å®¹ï¼ˆç°¡å–®é©—è­‰ï¼‰
    content = await file.read(1024)
    await file.seek(0)  # é‡ç½®æª”æ¡ˆæŒ‡é‡

    if not content:
        raise InvalidFileFormatError("æª”æ¡ˆç‚ºç©º")
```

#### 2. OpenAI API éŒ¯èª¤

```python
async def generate_embedding_with_retry(text: str, max_retries: int = 3):
    """ç”Ÿæˆå‘é‡ï¼ˆå«é‡è©¦æ©Ÿåˆ¶ï¼‰"""
    for attempt in range(max_retries):
        try:
            response = openai.embeddings.create(
                model="text-embedding-3-small",
                input=text
            )
            return response.data[0].embedding

        except openai.RateLimitError:
            # Rate limit - ç­‰å¾…å¾Œé‡è©¦
            wait_time = 2 ** attempt  # æŒ‡æ•¸é€€é¿
            await asyncio.sleep(wait_time)

        except openai.APIError as e:
            # API éŒ¯èª¤
            if attempt == max_retries - 1:
                raise Exception(f"OpenAI API éŒ¯èª¤: {e}")
            await asyncio.sleep(1)

    raise Exception("ç”Ÿæˆå‘é‡å¤±æ•—ï¼šè¶…éæœ€å¤§é‡è©¦æ¬¡æ•¸")
```

#### 3. è³‡æ–™åº«éŒ¯èª¤

```python
async def import_knowledge_with_transaction(
    knowledge_list: List[Dict],
    conn: asyncpg.Connection
):
    """ä½¿ç”¨äº‹å‹™åŒ¯å…¥çŸ¥è­˜ï¼ˆç¢ºä¿åŸå­æ€§ï¼‰"""
    async with conn.transaction():
        try:
            for knowledge in knowledge_list:
                await conn.execute("""
                    INSERT INTO knowledge_base (...)
                    VALUES (...)
                """, ...)

        except asyncpg.UniqueViolationError:
            # è™•ç†é‡è¤‡éµéŒ¯èª¤
            print(f"çŸ¥è­˜å·²å­˜åœ¨ï¼Œè·³é: {knowledge['question_summary']}")

        except Exception as e:
            # å…¶ä»–éŒ¯èª¤ï¼šå›æ»¾äº‹å‹™
            print(f"åŒ¯å…¥å¤±æ•—ï¼Œå›æ»¾äº‹å‹™: {e}")
            raise
```

---

## ğŸ“ å¾…è¾¦äº‹é …èˆ‡æ”¹é€²å»ºè­°

### ğŸ”´ é«˜å„ªå…ˆç´šï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰

1. **å¯¦ä½œå®Œæ•´çš„çŸ¥è­˜åŒ¯å…¥æœå‹™**
   - [ ] å»ºç«‹ `KnowledgeImportService` é¡åˆ¥
   - [ ] æ•´åˆæª”æ¡ˆè§£æå™¨ï¼ˆExcel, PDF, TXTï¼‰
   - [ ] æ•´åˆå‘é‡ç”Ÿæˆé‚è¼¯
   - [ ] å¯¦ä½œå»é‡æ©Ÿåˆ¶
   - [ ] å¯¦ä½œé€²åº¦è¿½è¹¤

2. **å®Œæˆå¾Œç«¯ API**
   - [ ] å¯¦ä½œ `POST /upload` å®Œæ•´é‚è¼¯
   - [ ] å¯¦ä½œ `GET /jobs/{id}` ç‹€æ…‹æŸ¥è©¢
   - [ ] å¯¦ä½œ `POST /preview` æª”æ¡ˆé è¦½
   - [ ] å»ºç«‹ä½œæ¥­ç‹€æ…‹å„²å­˜ï¼ˆRedis æˆ– PostgreSQLï¼‰

3. **è³‡æ–™åº« Schema**
   - [ ] å»ºç«‹ `knowledge_import_jobs` è¡¨
   - [ ] å»ºç«‹å‘é‡ç´¢å¼•å„ªåŒ–æŸ¥è©¢æ•ˆèƒ½
   - [ ] å»ºç«‹å¿…è¦çš„å¤–éµç´„æŸ

### ğŸŸ¡ ä¸­å„ªå…ˆç´šï¼ˆä½¿ç”¨è€…é«”é©—ï¼‰

4. **å‰ç«¯å„ªåŒ–**
   - [ ] å¯¦ä½œæª”æ¡ˆé è¦½åŠŸèƒ½ï¼ˆStep 2ï¼‰
   - [ ] æ”¹é€²é€²åº¦é¡¯ç¤ºï¼ˆé¡¯ç¤ºç•¶å‰è™•ç†éšæ®µï¼‰
   - [ ] å¢åŠ éŒ¯èª¤è©³æƒ…å±•ç¤º
   - [ ] æ”¯æ´å–æ¶ˆåŒ¯å…¥ä½œæ¥­

5. **éŒ¯èª¤è™•ç†**
   - [ ] çµ±ä¸€éŒ¯èª¤å›æ‡‰æ ¼å¼
   - [ ] å¯¦ä½œé‡è©¦æ©Ÿåˆ¶
   - [ ] è¨˜éŒ„è©³ç´°éŒ¯èª¤æ—¥èªŒ
   - [ ] æä¾›éŒ¯èª¤ä¿®æ­£å»ºè­°

### ğŸŸ¢ ä½å„ªå…ˆç´šï¼ˆé€²éšåŠŸèƒ½ï¼‰

6. **æ•ˆèƒ½å„ªåŒ–**
   - [ ] å‡ç´šåˆ° Celery é€²è¡ŒèƒŒæ™¯è™•ç†
   - [ ] å¯¦ä½œæ‰¹æ¬¡è™•ç†å„ªåŒ–
   - [ ] å¢åŠ å‘é‡ç”Ÿæˆå¿«å–
   - [ ] è³‡æ–™åº«é€£æ¥æ± å„ªåŒ–

7. **åŠŸèƒ½æ“´å±•**
   - [ ] æ”¯æ´æ›´å¤šæª”æ¡ˆæ ¼å¼ï¼ˆJSON, CSV, Wordï¼‰
   - [ ] æ”¯æ´å¾ URL åŒ¯å…¥
   - [ ] æ”¯æ´ API åŒ¯å…¥ï¼ˆWebhookï¼‰
   - [ ] åŒ¯å…¥æ’ç¨‹åŠŸèƒ½
   - [ ] åŒ¯å…¥æ¨¡æ¿ä¸‹è¼‰

8. **ç›£æ§èˆ‡åˆ†æ**
   - [ ] åŒ¯å…¥çµ±è¨ˆå„€è¡¨æ¿
   - [ ] API æˆæœ¬è¿½è¹¤
   - [ ] æ•ˆèƒ½ç›£æ§
   - [ ] åŒ¯å…¥æ­·å²åˆ†æ

---

## ğŸ”— ç›¸é—œæ–‡ä»¶é€£çµ

### ç¨‹å¼ç¢¼æª”æ¡ˆ

- **å‰ç«¯**: `knowledge-admin/frontend/src/views/KnowledgeImportView.vue` (883 è¡Œ)
- **å¾Œç«¯ API**: `rag-orchestrator/routers/knowledge_import.py` (306 è¡Œ)
- **çŸ¥è­˜æå–**: `scripts/knowledge_extraction/extract_knowledge_and_tests.py` (339 è¡Œ)
- **Excel åŒ¯å…¥**: `scripts/knowledge_extraction/import_excel_to_kb.py` (357 è¡Œ)
- **RAG å¼•æ“**: `rag-orchestrator/services/rag_engine.py` (413 è¡Œ)
- **Business Scope å·¥å…·**: `rag-orchestrator/services/business_scope_utils.py`

### ç›¸é—œæ–‡ä»¶

- [Business Scope é‡æ§‹ç¸½çµ](./docs/BUSINESS_SCOPE_REFACTORING_SUMMARY.md)
- [Business Scope è©³ç´°èªªæ˜](./docs/architecture/BUSINESS_SCOPE_REFACTORING.md)
- [èªè­‰èˆ‡æ¥­å‹™ç¯„åœæ•´åˆ](./docs/architecture/AUTH_AND_BUSINESS_SCOPE.md)

---

## ğŸ“Š ç¸½çµ

### ç¾ç‹€è©•ä¼°

| æ¨¡çµ„ | ç‹€æ…‹ | å®Œæ•´åº¦ | å‚™è¨» |
|------|------|--------|------|
| å‰ç«¯ä»‹é¢ | âœ… å®Œæˆ | 100% | 4 æ­¥é©Ÿå‘å°å®Œæ•´å¯¦ä½œ |
| å¾Œç«¯ API éª¨æ¶ | âš ï¸ éƒ¨åˆ†å®Œæˆ | 40% | ç«¯é»å­˜åœ¨ä½†æ ¸å¿ƒé‚è¼¯å¾…å¯¦ä½œ |
| æª”æ¡ˆè§£æå™¨ | âš ï¸ éƒ¨åˆ†å®Œæˆ | 30% | LINE/Excel è§£æå™¨å­˜åœ¨ä½†æœªæ•´åˆ |
| å‘é‡ç”Ÿæˆ | âœ… å®Œæˆ | 100% | å·²æœ‰å®Œæ•´å¯¦ä½œç¯„ä¾‹ |
| è³‡æ–™åº«åŒ¯å…¥ | âœ… å®Œæˆ | 100% | å·²æœ‰å®Œæ•´å¯¦ä½œç¯„ä¾‹ |
| é€²åº¦è¿½è¹¤ | âŒ æœªå¯¦ä½œ | 0% | éœ€è¦å»ºç«‹ä½œæ¥­ç‹€æ…‹ç®¡ç†æ©Ÿåˆ¶ |
| éŒ¯èª¤è™•ç† | âš ï¸ åŸºæœ¬å¯¦ä½œ | 30% | éœ€è¦æ›´å®Œå–„çš„éŒ¯èª¤è™•ç† |

### æ ¸å¿ƒå•é¡Œ

1. **å‰å¾Œç«¯æœªæ•´åˆ**: å‰ç«¯å·²å®Œæˆï¼Œä½†å¾Œç«¯åªæœ‰éª¨æ¶ï¼Œå…©è€…æœªé€£æ¥
2. **çŸ¥è­˜æå–é‚è¼¯ç¨ç«‹**: `extract_knowledge_and_tests.py` æ˜¯ç¨ç«‹çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œæœªæ•´åˆåˆ° API
3. **ä½œæ¥­ç‹€æ…‹ç®¡ç†ç¼ºå¤±**: æ²’æœ‰å¯¦ä½œä½œæ¥­ç‹€æ…‹çš„æŒä¹…åŒ–å„²å­˜å’ŒæŸ¥è©¢æ©Ÿåˆ¶
4. **æª”æ¡ˆé¡å‹æ”¯æ´ä¸æ˜ç¢º**: å‰ç«¯æ”¯æ´å¤šç¨®æ ¼å¼ï¼Œä½†å¾Œç«¯åªæœ‰ LINE æ ¼å¼çš„è§£æå™¨

### å»ºè­°ä¸‹ä¸€æ­¥

**Phase 1: æ ¸å¿ƒæ•´åˆï¼ˆ1-2 é€±ï¼‰**
1. å»ºç«‹ `KnowledgeImportService` çµ±ä¸€æœå‹™
2. å¯¦ä½œ Excel æª”æ¡ˆè§£æå™¨
3. æ•´åˆå‘é‡ç”Ÿæˆé‚è¼¯
4. å¯¦ä½œä½œæ¥­ç‹€æ…‹ç®¡ç†ï¼ˆä½¿ç”¨ Redis æˆ– PostgreSQLï¼‰
5. é€£æ¥å‰å¾Œç«¯ï¼Œå®ŒæˆåŸºæœ¬åŒ¯å…¥æµç¨‹

**Phase 2: åŠŸèƒ½å®Œå–„ï¼ˆ1 é€±ï¼‰**
6. å¯¦ä½œå»é‡æ©Ÿåˆ¶
7. å®Œå–„éŒ¯èª¤è™•ç†
8. å¢åŠ æª”æ¡ˆé è¦½åŠŸèƒ½
9. å„ªåŒ–é€²åº¦é¡¯ç¤º

**Phase 3: æ•ˆèƒ½èˆ‡æ“´å±•ï¼ˆ1 é€±ï¼‰**
10. å‡ç´šåˆ° Celery æˆ–å…¶ä»–ä»»å‹™ä½‡åˆ—
11. å„ªåŒ–è³‡æ–™åº«å‘é‡ç´¢å¼•
12. å¢åŠ æ›´å¤šæª”æ¡ˆæ ¼å¼æ”¯æ´
13. å¯¦ä½œç›£æ§èˆ‡çµ±è¨ˆ

---

**æ–‡æª”ç‰ˆæœ¬**: v1.0
**æœ€å¾Œæ›´æ–°**: 2025-10-12
**ä½œè€…**: Claude Code
**ç‹€æ…‹**: âœ… å®Œæ•´èª¿æŸ¥å®Œæˆ

