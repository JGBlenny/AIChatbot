#!/usr/bin/env python3
"""
LLM Provider åŸºæœ¬åŠŸèƒ½æ¸¬è©¦
é©—è­‰ Provider æŠ½è±¡å±¤æ˜¯å¦æ­£å¸¸é‹ä½œ
"""
import os
import sys

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(project_root, 'rag-orchestrator'))

from services.llm_provider import (
    get_llm_provider,
    OpenAIProvider,
    OpenRouterProvider,
    OllamaProvider,
    chat_completion
)


def test_openai_provider():
    """æ¸¬è©¦ OpenAI Provider"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 1: OpenAI Provider")
    print("=" * 60)

    try:
        # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        if not os.getenv("OPENAI_API_KEY"):
            print("âš ï¸  æœªè¨­å®š OPENAI_API_KEYï¼Œè·³éæ¸¬è©¦")
            return False

        # åˆå§‹åŒ– Provider
        provider = OpenAIProvider()
        print(f"âœ… Provider åˆå§‹åŒ–æˆåŠŸ: {provider.provider_name}")

        # æ¸¬è©¦ chat_completion
        messages = [
            {"role": "user", "content": "è«‹ç”¨ä¸€å¥è©±èªªæ˜ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’"}
        ]
        result = provider.chat_completion(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.5,
            max_tokens=100
        )

        print(f"\nğŸ“ æ¸¬è©¦çµæœ:")
        print(f"   å›æ‡‰: {result['content'][:80]}...")
        print(f"   Provider: {result['provider']}")
        print(f"   Model: {result['model']}")
        print(f"   Usage: {result['usage']}")

        print("\nâœ… OpenAI Provider æ¸¬è©¦é€šé")
        return True

    except Exception as e:
        print(f"\nâŒ OpenAI Provider æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_openrouter_provider():
    """æ¸¬è©¦ OpenRouter Provider"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 2: OpenRouter Provider")
    print("=" * 60)

    try:
        # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
        if not os.getenv("OPENROUTER_API_KEY"):
            print("âš ï¸  æœªè¨­å®š OPENROUTER_API_KEYï¼Œè·³éæ¸¬è©¦")
            return None

        # åˆå§‹åŒ– Provider
        provider = OpenRouterProvider()
        print(f"âœ… Provider åˆå§‹åŒ–æˆåŠŸ: {provider.provider_name}")

        # æ¸¬è©¦ chat_completion
        messages = [
            {"role": "user", "content": "Say hello in Traditional Chinese"}
        ]
        result = provider.chat_completion(
            model="anthropic/claude-3.5-sonnet",
            messages=messages,
            temperature=0.7,
            max_tokens=50
        )

        print(f"\nğŸ“ æ¸¬è©¦çµæœ:")
        print(f"   å›æ‡‰: {result['content']}")
        print(f"   Provider: {result['provider']}")
        print(f"   Model: {result['model']}")

        print("\nâœ… OpenRouter Provider æ¸¬è©¦é€šé")
        return True

    except Exception as e:
        print(f"\nâš ï¸  OpenRouter Provider æ¸¬è©¦å¤±æ•—ï¼ˆå¯èƒ½æœªé…ç½®ï¼‰: {e}")
        return None


def test_ollama_provider():
    """æ¸¬è©¦ Ollama Provider"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 3: Ollama Provider")
    print("=" * 60)

    try:
        # åˆå§‹åŒ– Provider
        provider = OllamaProvider()
        print(f"âœ… Provider åˆå§‹åŒ–æˆåŠŸ: {provider.provider_name}")
        print(f"   API URL: {provider.base_url}")

        # æ¸¬è©¦ chat_completion
        messages = [
            {"role": "user", "content": "ä½ å¥½ï¼Œè«‹ç”¨ä¸­æ–‡å›ç­”"}
        ]
        result = provider.chat_completion(
            model="llama2",
            messages=messages,
            temperature=0.7,
            max_tokens=50
        )

        print(f"\nğŸ“ æ¸¬è©¦çµæœ:")
        print(f"   å›æ‡‰: {result['content'][:100]}...")
        print(f"   Provider: {result['provider']}")
        print(f"   Model: {result['model']}")

        print("\nâœ… Ollama Provider æ¸¬è©¦é€šé")
        return True

    except Exception as e:
        print(f"\nâš ï¸  Ollama Provider æ¸¬è©¦å¤±æ•—ï¼ˆå¯èƒ½æœå‹™æœªé‹è¡Œï¼‰: {e}")
        return None


def test_factory_function():
    """æ¸¬è©¦ Factory å‡½æ•¸"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 4: Factory å‡½æ•¸ (get_llm_provider)")
    print("=" * 60)

    try:
        # è®€å–ç’°å¢ƒè®Šæ•¸æ±ºå®šä½¿ç”¨å“ªå€‹ Provider
        provider_type = os.getenv("LLM_PROVIDER", "openai")
        print(f"ç’°å¢ƒè®Šæ•¸ LLM_PROVIDER: {provider_type}")

        # ä½¿ç”¨ Factory å‡½æ•¸
        provider = get_llm_provider(reset=True)
        print(f"âœ… Factory å‡½æ•¸è¿”å›: {provider.provider_name}")

        # æ¸¬è©¦ä¾¿åˆ©å‡½æ•¸
        result = chat_completion(
            model=os.getenv("INTENT_CLASSIFIER_MODEL", "gpt-3.5-turbo"),
            messages=[{"role": "user", "content": "ä½ å¥½"}],
            temperature=0.5,
            max_tokens=30
        )

        print(f"\nğŸ“ ä¾¿åˆ©å‡½æ•¸æ¸¬è©¦çµæœ:")
        print(f"   å›æ‡‰: {result['content']}")
        print(f"   Provider: {result['provider']}")

        print("\nâœ… Factory å‡½æ•¸æ¸¬è©¦é€šé")
        return True

    except Exception as e:
        print(f"\nâŒ Factory å‡½æ•¸æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_provider_switching():
    """æ¸¬è©¦ Provider åˆ‡æ›"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ 5: Provider å‹•æ…‹åˆ‡æ›")
    print("=" * 60)

    results = {}

    # æ¸¬è©¦ä¸åŒçš„ Provider
    providers_to_test = []

    if os.getenv("OPENAI_API_KEY"):
        providers_to_test.append("openai")

    if os.getenv("OPENROUTER_API_KEY"):
        providers_to_test.append("openrouter")

    # Ollama ç¸½æ˜¯å¯ä»¥å˜—è©¦ï¼ˆå³ä½¿å¤±æ•—ä¹Ÿç„¡å¦¨ï¼‰
    providers_to_test.append("ollama")

    for provider_type in providers_to_test:
        try:
            print(f"\nåˆ‡æ›åˆ° Provider: {provider_type}")
            provider = get_llm_provider(provider_type=provider_type, reset=True)
            print(f"âœ… æˆåŠŸåˆ‡æ›: {provider.provider_name}")
            results[provider_type] = True
        except Exception as e:
            print(f"âš ï¸  {provider_type} ç„¡æ³•ä½¿ç”¨: {e}")
            results[provider_type] = False

    print(f"\nğŸ“Š åˆ‡æ›æ¸¬è©¦çµæœ:")
    for ptype, success in results.items():
        status = "âœ…" if success else "âš ï¸"
        print(f"   {status} {ptype}")

    print("\nâœ… Provider åˆ‡æ›æ¸¬è©¦å®Œæˆ")
    return True


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("=" * 60)
    print("LLM Provider åŸºæœ¬åŠŸèƒ½æ¸¬è©¦")
    print("=" * 60)

    # é¡¯ç¤ºç•¶å‰ç’°å¢ƒè®Šæ•¸
    print("\nğŸ“‹ ç’°å¢ƒè®Šæ•¸é…ç½®:")
    print(f"   LLM_PROVIDER: {os.getenv('LLM_PROVIDER', '(æœªè¨­å®š,é»˜èª openai)')}")
    print(f"   OPENAI_API_KEY: {'âœ… å·²è¨­å®š' if os.getenv('OPENAI_API_KEY') else 'âŒ æœªè¨­å®š'}")
    print(f"   OPENROUTER_API_KEY: {'âœ… å·²è¨­å®š' if os.getenv('OPENROUTER_API_KEY') else 'âŒ æœªè¨­å®š'}")
    print(f"   OLLAMA_API_URL: {os.getenv('OLLAMA_API_URL', 'http://localhost:11434')}")

    results = {}

    # åŸ·è¡Œæ¸¬è©¦
    results['openai'] = test_openai_provider()
    results['openrouter'] = test_openrouter_provider()
    results['ollama'] = test_ollama_provider()
    results['factory'] = test_factory_function()
    results['switching'] = test_provider_switching()

    # ç¸½çµ
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ç¸½çµ")
    print("=" * 60)

    for test_name, result in results.items():
        if result is True:
            status = "âœ… é€šé"
        elif result is None:
            status = "âš ï¸  è·³éï¼ˆæœªé…ç½®ï¼‰"
        else:
            status = "âŒ å¤±æ•—"

        print(f"   {test_name:20s}: {status}")

    # è¨ˆç®—é€šéç‡
    passed = sum(1 for r in results.values() if r is True)
    total = len(results)
    skipped = sum(1 for r in results.values() if r is None)

    print(f"\né€šé: {passed}/{total-skipped}")

    if passed == total - skipped:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—æˆ–è·³é")
        return 1


if __name__ == "__main__":
    sys.exit(main())
