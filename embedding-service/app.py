"""
Embedding API Service
çµ±ä¸€çš„å‘é‡ç”Ÿæˆæœå‹™ï¼Œæ”¯æ´å¿«å–
"""
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
from openai import OpenAI
import redis
import hashlib
import json
import os

app = FastAPI(
    title="Embedding API Service",
    description="çµ±ä¸€çš„å‘é‡ç”Ÿæˆæœå‹™",
    version="1.0.0"
)

# ç’°å¢ƒè®Šæ•¸
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
EMBEDDING_MODEL = "text-embedding-3-small"
CACHE_TTL = 86400  # 24 å°æ™‚

# OpenAI å®¢æˆ¶ç«¯
client = OpenAI(api_key=OPENAI_API_KEY)

# Redis å®¢æˆ¶ç«¯
try:
    redis_client = redis.Redis(
        host=REDIS_HOST,
        port=REDIS_PORT,
        decode_responses=False
    )
    redis_client.ping()
    print(f"âœ… Redis å·²é€£ç·š: {REDIS_HOST}:{REDIS_PORT}")
except Exception as e:
    print(f"âš ï¸  Redis é€£ç·šå¤±æ•—: {e}")
    redis_client = None

# è³‡æ–™æ¨¡å‹
class EmbeddingRequest(BaseModel):
    text: str
    model: str = EMBEDDING_MODEL

class EmbeddingResponse(BaseModel):
    embedding: List[float]
    model: str
    dimensions: int
    cached: bool

@app.get("/")
async def root():
    return {
        "name": "Embedding API Service",
        "version": "1.0.0",
        "model": EMBEDDING_MODEL
    }

@app.get("/api/v1/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    redis_status = "connected" if redis_client and redis_client.ping() else "disconnected"
    return {
        "status": "healthy",
        "redis": redis_status,
        "model": EMBEDDING_MODEL
    }

@app.post("/api/v1/embeddings", response_model=EmbeddingResponse)
async def create_embedding(request: EmbeddingRequest):
    """
    ç”Ÿæˆæ–‡å­—å‘é‡

    - **text**: è¦è½‰æ›çš„æ–‡å­—
    - **model**: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆé è¨­: text-embedding-3-smallï¼‰
    """
    try:
        # ç”Ÿæˆå¿«å– key
        cache_key = f"embedding:{request.model}:{hashlib.md5(request.text.encode()).hexdigest()}"

        # æª¢æŸ¥å¿«å–
        if redis_client:
            try:
                cached_embedding = redis_client.get(cache_key)
                if cached_embedding:
                    embedding = json.loads(cached_embedding)
                    return EmbeddingResponse(
                        embedding=embedding,
                        model=request.model,
                        dimensions=len(embedding),
                        cached=True
                    )
            except Exception as e:
                print(f"Redis è®€å–å¤±æ•—: {e}")

        # å‘¼å« OpenAI API
        response = client.embeddings.create(
            model=request.model,
            input=request.text
        )

        embedding = response.data[0].embedding

        # å„²å­˜åˆ°å¿«å–
        if redis_client:
            try:
                redis_client.setex(
                    cache_key,
                    CACHE_TTL,
                    json.dumps(embedding)
                )
            except Exception as e:
                print(f"Redis å¯«å…¥å¤±æ•—: {e}")

        return EmbeddingResponse(
            embedding=embedding,
            model=request.model,
            dimensions=len(embedding),
            cached=False
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå‘é‡å¤±æ•—: {str(e)}")

@app.get("/api/v1/stats")
async def get_stats():
    """å–å¾—çµ±è¨ˆè³‡è¨Š"""
    cache_size = 0
    if redis_client:
        try:
            cache_keys = redis_client.keys("embedding:*")
            cache_size = len(cache_keys)
        except:
            pass

    return {
        "cache_size": cache_size,
        "model": EMBEDDING_MODEL
    }

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å•Ÿå‹• Embedding API Service...")
    print(f"ğŸ“Š API æ–‡ä»¶: http://localhost:5000/docs")
    print(f"ğŸ”‘ æ¨¡å‹: {EMBEDDING_MODEL}")
    uvicorn.run(app, host="0.0.0.0", port=5000)
