#!/usr/bin/env python3
"""é©—è­‰ Primary Embedding çš„çµ„æˆå•é¡Œ"""

import asyncio
import psycopg2
import httpx

def get_db_connection():
    return psycopg2.connect(
        host="localhost",
        port=5432,
        database="aichatbot_admin",
        user="aichatbot",
        password="aichatbot_password"
    )

async def get_embedding(text: str):
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(
            "http://localhost:5001/api/v1/embeddings",
            json={"text": text}
        )
        data = response.json()
        return data.get("embedding")

async def test_embedding_hypothesis():
    """æ¸¬è©¦ï¼šå¦‚æœ item_name å–®ç¨ä½œç‚º embeddingï¼Œç›¸ä¼¼åº¦æœƒå¦‚ä½•ï¼Ÿ"""

    question = "åƒåœ¾è¦æ€éº¼ä¸Ÿï¼Ÿ"

    print("="*100)
    print("ğŸ”¬ é©—è­‰å‡è¨­ï¼šitem_name è¢« group_name ç¨€é‡‹äº†")
    print("="*100)

    # ç²å–å•é¡Œå‘é‡
    question_embedding = await get_embedding(question)

    # ç²å–å„ç¨®æ–‡æœ¬çš„å‘é‡ä¸¦è¨ˆç®—ç›¸ä¼¼åº¦
    test_texts = {
        "ç•¶å‰ Primary (group+item)": "ç§Ÿç´„æ¢æ¬¾èˆ‡è¦å®šï¼šè©³ç´°è§£é‡‹ç§Ÿç´„çš„åŸºæœ¬æ¢æ¬¾ã€ç§Ÿé‡‘æ”¯ä»˜æ–¹å¼ã€æŠ¼é‡‘ã€ç§ŸæœŸç­‰åŠé€²è¡Œè©å½™å®šç¾©ã€‚ï¼šåƒåœ¾æ”¶å–è¦ç¯„:",
        "å‡è¨­ Primary (åªæœ‰ item_name)": "åƒåœ¾æ”¶å–è¦ç¯„",
        "ç•¶å‰ Fallback (content)": "å¤šæ•¸æ¡ˆå ´æä¾›åƒåœ¾ä»£æ”¶æœå‹™ï¼Œä»£æ”¶é …ç›®ç‚ºä¸€èˆ¬å®¶ç”¨åƒåœ¾åŠè³‡æºå›æ”¶ã€‚ä¸æ”¶å–å…§å®¹ç‚º:1.å®¶å…·ã€å®¶é›»ã€æ˜“ç¢ç‰©ã€æ£‰è¢«ã€æ•é ­è¢«å¥—ã€åŒ…åŒ…çš®ä»¶ã€é‹å­ã€å»ºæå»¢æ–™ç­‰åŠå…¶ä»–æ³•å®šä¸å¾—å›æ”¶ä¹‹ç‰©å“ã€‚2. éæ—¥å¸¸å®¶ç”¨ä¹‹å»¢æ£„ç‰©ï¼Œå¦‚ï¼šæˆ¿å®¢é·å…¥ã€é·å‡ºå¾Œæ‰€ç”¢ç”Ÿä¹‹å¤§å‹è¢‹è£æˆ–å„é¡éå¸¸æ…‹æ€§åƒåœ¾ã€‚å¦‚é•ååƒåœ¾ä»£æ”¶è¦ç¯„ï¼Œæœƒæœ‰é•ç´„é‡‘ç”¢ç”Ÿã€‚",
        "å°æ¯”ï¼šé¦¬æ¡¶å µå¡ item_name": "é¦¬æ¡¶å µå¡",
        "å°æ¯”ï¼šé¦¬æ¡¶å µå¡ content": "å®£å°è«‹å‹¿ä¸Ÿä»»ä½•ç‰©å“è‡³é¦¬æ¡¶å…§ï¼ŒåŒ…æ‹¬è¡›ç”Ÿç´™ã€è¡›ç”Ÿæ£‰ã€è²“ç ‚ã€ä¿éšªå¥—ç­‰ç­‰ã€‚å…ˆè«‹æˆ¿å®¢å˜—è©¦è‡ªå·±ç–é€šã€‚å¦‚ç„¡æ³•ç–é€šæˆ–ä¸æ˜¯å–®ç´”å µå¡ï¼Œæœƒæœ‰æ»¿æº¢ä¹‹æƒ…å½¢ï¼Œè½‰äº¤å°ˆæ¥­äººå“¡è™•ç†ã€‚"
    }

    print(f"\nâ“ ç”¨æˆ¶å•é¡Œï¼šã€Œ{question}ã€\n")
    print(f"{'æ–‡æœ¬é¡å‹':<40} {'é•·åº¦':>6} {'ç›¸ä¼¼åº¦':>10} {'æ’å':>6}")
    print("-"*100)

    results = []
    for text_type, text in test_texts.items():
        text_embedding = await get_embedding(text)

        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        import numpy as np
        similarity = 1 - np.dot(question_embedding, text_embedding) / (
            np.linalg.norm(question_embedding) * np.linalg.norm(text_embedding)
        )
        # å¯¦éš›ä¸Šæ‡‰è©²ç”¨ cosine distanceï¼Œé€™è£¡ç°¡åŒ–ç‚º 1 - cosine_similarity
        # ä½†ç”±æ–¼æˆ‘å€‘æ˜¯ç”¨ APIï¼Œç›´æ¥è¨ˆç®—é»ç©
        dot_product = sum(a * b for a, b in zip(question_embedding, text_embedding))
        magnitude_q = sum(a * a for a in question_embedding) ** 0.5
        magnitude_t = sum(b * b for b in text_embedding) ** 0.5
        cosine_sim = dot_product / (magnitude_q * magnitude_t)
        similarity = cosine_sim  # OpenAI embeddings å·²ç¶“æ­£è¦åŒ–ï¼Œæ‰€ä»¥ç›´æ¥ç”¨é»ç©

        results.append((text_type, len(text), similarity))

    # æ’åºä¸¦é¡¯ç¤º
    results.sort(key=lambda x: x[2], reverse=True)

    for i, (text_type, length, similarity) in enumerate(results, 1):
        marker = ""
        if "å‡è¨­" in text_type:
            marker = " â­â­â­"
        elif "ç•¶å‰ Primary" in text_type:
            marker = " â† ç•¶å‰ä½¿ç”¨"
        elif "é¦¬æ¡¶å µå¡ content" in text_type:
            marker = " â† ç›®å‰è´çš„"

        print(f"{text_type:<40} {length:>6} {similarity:>10.4f} {i:>6}{marker}")

    print("\n" + "="*100)
    print("ğŸ’¡ åˆ†æçµæœ")
    print("="*100)

    # æ‰¾å‡ºé—œéµæ•¸æ“š
    current_primary = next(r for r in results if "ç•¶å‰ Primary" in r[0])
    hypothetical_primary = next(r for r in results if "å‡è¨­ Primary" in r[0])
    current_fallback = next(r for r in results if "ç•¶å‰ Fallback" in r[0])
    toilet_content = next(r for r in results if "é¦¬æ¡¶å µå¡ content" in r[0])

    print(f"\nã€ç•¶å‰ç‹€æ³ã€‘")
    print(f"  åƒåœ¾è¦ç¯„ Primary (group+item): {current_primary[2]:.4f}")
    print(f"  åƒåœ¾è¦ç¯„ Fallback (content):  {current_fallback[2]:.4f}")
    print(f"  GREATEST(å…©è€…):              {max(current_primary[2], current_fallback[2]):.4f}")
    print(f"  é¦¬æ¡¶å µå¡ Fallback:            {toilet_content[2]:.4f} â† ç›®å‰æ’ç¬¬ä¸€")

    print(f"\nã€å¦‚æœæ”¹ç”¨ item_nameã€‘")
    print(f"  åƒåœ¾è¦ç¯„ Primary (åªæœ‰item):  {hypothetical_primary[2]:.4f} â­")
    print(f"  åƒåœ¾è¦ç¯„ Fallback (content):  {current_fallback[2]:.4f}")
    print(f"  GREATEST(å…©è€…):              {max(hypothetical_primary[2], current_fallback[2]):.4f} â­")

    # æ¯”è¼ƒçµæœ
    improvement = max(hypothetical_primary[2], current_fallback[2]) - max(current_primary[2], current_fallback[2])

    print(f"\nã€æ¯”è¼ƒã€‘")
    if max(hypothetical_primary[2], current_fallback[2]) > toilet_content[2]:
        print(f"  âœ… æ”¹ç”¨ item_name å¾Œï¼šåƒåœ¾è¦ç¯„æœƒæ’ç¬¬ä¸€ï¼")
        print(f"  âœ… æå‡å¹…åº¦: +{improvement:.4f}")
        print(f"  âœ… æœƒæ­£ç¢ºåŒ¹é…ã€Œåƒåœ¾æ”¶å–è¦ç¯„ã€è€Œéã€Œé¦¬æ¡¶å µå¡ã€")
    else:
        print(f"  âŒ å³ä½¿æ”¹ç”¨ item_nameï¼šé‚„æ˜¯é¦¬æ¡¶å µå¡æ’ç¬¬ä¸€")
        print(f"  æå‡å¹…åº¦: +{improvement:.4f} (ä¸å¤ )")

if __name__ == "__main__":
    asyncio.run(test_embedding_hypothesis())
